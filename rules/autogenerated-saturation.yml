# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./rules-jsonnet/saturation.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: Saturation Rules (autogenerated)
  interval: 1m
  rules:
  - record: gitlab_component_saturation:ratio
    labels:
      component: cgroup_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"} -
              container_memory_cache{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"} -
              container_memory_swap{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"}
            )
            /
            container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: cloudsql_cpu
      stage: main
      tier: inf
      type: monitoring
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_cpu_utilization{}[5m])
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: cloudsql_disk
      stage: main
      tier: inf
      type: monitoring
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_disk_utilization{}[5m])
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: cloudsql_memory
      stage: main
      tier: inf
      type: monitoring
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_memory_utilization{}[5m])
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - avg by (environment, tier, type, stage) (
              rate(node_cpu_seconds_total{mode="idle", type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_inodes
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - (
              node_filesystem_files_free{fstype=~"(ext.|xfs)", type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}
              /
              node_filesystem_files{fstype=~"(ext.|xfs)", type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_iops
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_reads_completed_total{device!="sda", type=~"gitaly|patroni|patroni-ci"}[20m])
            /
            node_disk_max_read_iops{device!="sda", type=~"gitaly|patroni|patroni-ci"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_throughput
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_read_bytes_total{device!="sda", type=~"gitaly|patroni|patroni-ci"}[20m])
            /
            node_disk_max_read_bytes_seconds{device!="sda", type=~"gitaly|patroni|patroni-ci"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_iops
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_writes_completed_total{device!="sda", type=~"gitaly|patroni|patroni-ci"}[20m])
            /
            node_disk_max_write_iops{device!="sda", type=~"gitaly|patroni|patroni-ci"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_throughput
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_written_bytes_total{device!="sda", type=~"gitaly|patroni|patroni-ci"}[20m])
            /
            node_disk_max_write_bytes_seconds{device!="sda", type=~"gitaly|patroni|patroni-ci"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg by (environment, tier, type, stage) (
              avg_over_time(elasticsearch_process_cpu_percent{type=~"logging|search"}[1m]) / 100
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_disk_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, host) (
              (elasticsearch_filesystem_data_size_bytes{type=~"logging|search"} - elasticsearch_filesystem_data_free_bytes{type=~"logging|search"})
            )
            /
            sum by (environment, tier, type, stage, host) (
              elasticsearch_filesystem_data_size_bytes{type=~"logging|search"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_jvm_heap_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            elasticsearch_jvm_memory_used_bytes{area="heap", type=~"logging|search"}
            /
            elasticsearch_jvm_memory_max_bytes{area="heap", type=~"logging|search"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg_over_time(elasticsearch_process_cpu_percent{type=~"logging|search"}[5m]) / 100
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_disk_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              (
                elasticsearch_filesystem_data_size_bytes{type=~"logging|search"}
                -
                elasticsearch_filesystem_data_free_bytes{type=~"logging|search"}
              )
              /
              elasticsearch_filesystem_data_size_bytes{type=~"logging|search"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_thread_pools
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(elasticsearch_thread_pool_active_count{exported_type!="snapshot", type=~"logging|search"}[5m])
              /
              (avg_over_time(elasticsearch_thread_pool_threads_count{exported_type!="snapshot", type=~"logging|search"}[5m]) > 0)
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: gcp_quota_limit
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              gcp_quota_usage{type="monitoring"}
            /
              gcp_quota_limit{type="monitoring"}
            ) > 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: gitaly_active_node_available_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - (
              sum by (environment, tier, type, stage, shard) (
                node_filesystem_avail_bytes{type="gitaly", device="/dev/sdb",shard=~"default|praefect"}
                and
                (instance:node_filesystem_avail:ratio{type="gitaly", device="/dev/sdb",shard=~"default|praefect"} > 0.2)
              )
              /
              sum by (environment, tier, type, stage, shard)(
                node_filesystem_size_bytes{type="gitaly", device="/dev/sdb",shard=~"default|praefect"}
              )
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: gitaly_total_disk_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - (
              sum by (environment, tier, type, stage, shard) (
                node_filesystem_avail_bytes{type="gitaly", device="/dev/sdb"}
              )
              /
              sum by (environment, tier, type, stage, shard) (
                node_filesystem_size_bytes{type="gitaly", device="/dev/sdb"}
              )
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_container_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, pod, container) (
              rate(container_cpu_usage_seconds_total:labeled{container!="", container!="POD", type=~"web|api|camoproxy|consul|external-dns|git|kas|kube|logging|mailroom|monitoring|nginx|plantuml|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|websockets|woodhouse"}[5m])
            )
            /
            sum by(environment, tier, type, stage, pod, container) (
              container_spec_cpu_quota:labeled{container!="", container!="POD", type=~"web|api|camoproxy|consul|external-dns|git|kas|kube|logging|mailroom|monitoring|nginx|plantuml|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|websockets|woodhouse"}
              /
              container_spec_cpu_period:labeled{container!="", container!="POD", type=~"web|api|camoproxy|consul|external-dns|git|kas|kube|logging|mailroom|monitoring|nginx|plantuml|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|websockets|woodhouse"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_container_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            container_memory_working_set_bytes:labeled{container!="", container!="POD", type=~"web|api|camoproxy|consul|external-dns|git|kas|kube|logging|mailroom|monitoring|nginx|plantuml|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|websockets|woodhouse"}
            /
            (container_spec_memory_limit_bytes:labeled{container!="", container!="POD", type=~"web|api|camoproxy|consul|external-dns|git|kas|kube|logging|mailroom|monitoring|nginx|plantuml|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|websockets|woodhouse"} > 0)
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_horizontalpodautoscaler_desired_replicas
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            kube_horizontalpodautoscaler_status_desired_replicas:labeled{type=~"web|api|camoproxy|consul|external-dns|git|kas|kube|logging|mailroom|monitoring|nginx|plantuml|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|websockets|woodhouse", shard!~"database-throttled|elasticsearch|gitaly-throttled|imports|urgent-authorized-projects|urgent-other"}
            /
            kube_horizontalpodautoscaler_spec_max_replicas:labeled{type=~"web|api|camoproxy|consul|external-dns|git|kas|kube|logging|mailroom|monitoring|nginx|plantuml|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|websockets|woodhouse", shard!~"database-throttled|elasticsearch|gitaly-throttled|imports|urgent-authorized-projects|urgent-other"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_disk_space
      stage: main
      tier: inf
      type: kube
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            kubelet_volume_stats_used_bytes
            /
            kubelet_volume_stats_capacity_bytes
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_inodes
      stage: main
      tier: inf
      type: kube
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            kubelet_volume_stats_inodes_used
            /
            kubelet_volume_stats_inodes
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_pool_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - avg by (environment, tier, type, stage) (
              rate(node_cpu_seconds_total:labeled{mode="idle", type=~"api|consul|git|kube|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sidekiq|vault|web-pages|web|websockets"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            instance:node_memory_utilization:ratio{type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"} or instance:node_memory_utilisation:ratio{type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: memory_redis_cache
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            instance:node_memory_utilization:ratio{type="redis-cache"} or instance:node_memory_utilisation:ratio{type="redis-cache"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: nat_gateway_port_allocation
      stage: main
      tier: inf
      type: nat
    expr: "max by(environment) (\n  clamp_min(\n    clamp_max(\n      sum without(nat_ip)
      (\n        stackdriver_nat_gateway_router_googleapis_com_nat_allocated_ports{\n
      \         job=\"stackdriver\",\n          project_id=\"gitlab-production\",\n
      \         \n        }\n      )\n      /\n      ( 64512 * 43 )\n      or\n      sum
      without(nat_ip) (\n        stackdriver_nat_gateway_router_googleapis_com_nat_allocated_ports{\n
      \         job=\"stackdriver\",\n          project_id=\"gitlab-staging-1\",\n
      \         \n        }\n      )\n      /\n      ( 64512 * 16 )\n      ,\n      1)\n
      \ ,\n  0)\n)\n"
  - record: gitlab_component_saturation:ratio
    labels:
      component: nat_host_port_allocation
      stage: main
      tier: inf
      type: nat
    expr: "max by(environment) (\n  clamp_min(\n    clamp_max(\n      sum without(ip_protocol)
      (\n        max_over_time(\n          stackdriver_gce_instance_compute_googleapis_com_nat_port_usage{\n
      \           job=\"stackdriver\",\n            project_id=~\"gitlab-production|gitlab-staging-1\",\n
      \           \n          }[5m]\n        )\n      )\n      /\n      sum without
      (nat_ip) (\n        max_over_time(\n          stackdriver_gce_instance_compute_googleapis_com_nat_allocated_ports{\n
      \           job=\"stackdriver\",\n            project_id=~\"gitlab-production|gitlab-staging-1\",\n
      \           \n          }[5m]\n        )\n      )\n      ,\n      1)\n  ,\n
      \ 0)\n)\n"
  - record: gitlab_component_saturation:ratio
    labels:
      component: nf_conntrack_entries
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max_over_time(node_nf_conntrack_entries{type=~"patroni|ci-runners|consul|customersdot|frontend|gitaly|jaeger|monitoring|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}[1m])
            /
            node_nf_conntrack_entries_limit{type=~"patroni|ci-runners|consul|customersdot|frontend|gitaly|jaeger|monitoring|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: node_schedstat_waiting
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg without (cpu) (rate(node_schedstat_waiting_seconds_total{type=~"patroni|ci-runners|consul|customersdot|frontend|gitaly|jaeger|monitoring|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}[1h]))
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: open_fds
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              process_open_fds{type=~"api|camoproxy|ci-runners|consul|customersdot|external-dns|frontend|google-cloud-storage|git|gitaly|jaeger|kas|kube|logging|mailroom|monitoring|nginx|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|plantuml|praefect|pvs|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|search|sentry|sidekiq|vault|web-pages|web|websockets|woodhouse"}
              /
              process_max_fds{type=~"api|camoproxy|ci-runners|consul|customersdot|external-dns|frontend|google-cloud-storage|git|gitaly|jaeger|kas|kube|logging|mailroom|monitoring|nginx|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|plantuml|praefect|pvs|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|search|sentry|sidekiq|vault|web-pages|web|websockets|woodhouse"}
            )
            or
            (
              ruby_file_descriptors{type=~"api|camoproxy|ci-runners|consul|customersdot|external-dns|frontend|google-cloud-storage|git|gitaly|jaeger|kas|kube|logging|mailroom|monitoring|nginx|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|plantuml|praefect|pvs|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|search|sentry|sidekiq|vault|web-pages|web|websockets|woodhouse"}
              /
              ruby_process_max_fds{type=~"api|camoproxy|ci-runners|consul|customersdot|external-dns|frontend|google-cloud-storage|git|gitaly|jaeger|kas|kube|logging|mailroom|monitoring|nginx|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|plantuml|praefect|pvs|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|search|sentry|sidekiq|vault|web-pages|web|websockets|woodhouse"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_primary
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without (state) (
              pg_stat_activity_count{datname=~"gitlabhq_production|gitlabhq_registry", state!="idle", type=~"patroni|patroni-registry|patroni-ci"} unless on(instance) (pg_replication_is_replica == 1)
            )
            / on (environment, tier, type, stage, fqdn)
            pg_settings_max_connections{type=~"patroni|patroni-registry|patroni-ci"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_replica
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without (state) (
              pg_stat_activity_count{datname=~"gitlabhq_production|gitlabhq_registry", state!="idle", type=~"patroni|patroni-registry|patroni-ci|postgres-archive"} and on(instance) (pg_replication_is_replica == 1)
            )
            / on (environment, tier, type, stage, fqdn)
            pg_settings_max_connections{type=~"patroni|patroni-registry|patroni-ci|postgres-archive"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_btree_bloat
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_bloat_size{job="gitlab-monitor-database-bloat", type=~"patroni|patroni-registry|patroni-ci|postgres-archive"}[58m]))
            /
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_real_size{job="gitlab-monitor-database-bloat", type=~"patroni|patroni-registry|patroni-ci|postgres-archive"}[58m]))
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_int4_id
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max by (environment, tier, type, stage, table_name) (
              pg_integer_capacity_current{type=~"patroni|patroni-ci"}
              /
              pg_integer_capacity_maximum{type=~"patroni|patroni-ci"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_table_bloat
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_bloat_size{job="gitlab-monitor-database-bloat", type=~"patroni|patroni-registry|patroni-ci|postgres-archive"}[58m]))
            /
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_real_size{job="gitlab-monitor-database-bloat", type=~"patroni|patroni-registry|patroni-ci|postgres-archive"}[58m]))
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_txid_vacuum_to_wraparound
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              sum by (environment, tier, type, stage) (
                increase(fluentd_pg_auto_vacuum_elapsed_seconds_total{type=~"patroni|patroni-registry|patroni-ci"}[1d])
              )
              / on(environment, type) group_left() (
                pg_settings_autovacuum_max_workers and
                on (instance) pg_replication_is_replica == 0
              )
            )
            /
            (
              (2^31 - 10^6)
              /
              (
                avg by (environment, tier, type, stage) (
                  deriv(pg_txid_current{type=~"patroni|patroni-registry|patroni-ci"}[1d]) and
                  on (instance) pg_replication_is_replica == 0
                )
              )
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_xid_wraparound
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              max without (series) (
                label_replace(pg_database_wraparound_age_datfrozenxid{type=~"patroni|patroni-registry|patroni-ci|sentry"}, "series", "datfrozenxid", "", "")
                or
                label_replace(pg_database_wraparound_age_datminmxid{type=~"patroni|patroni-registry|patroni-ci|sentry"}, "series", "datminmxid", "", "")
              )
              and on (instance, job) (pg_replication_is_replica{type=~"patroni|patroni-registry|patroni-ci|sentry"} == 0)
            )
            /
            (2^31 - 10^6)
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_primary_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"pgbouncer|pgbouncer-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"pgbouncer|pgbouncer-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"pgbouncer|pgbouncer-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"pgbouncer|pgbouncer-ci"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", type=~"pgbouncer|pgbouncer-ci"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_replica_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"patroni|patroni-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"patroni|patroni-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"patroni|patroni-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", type=~"patroni|patroni-ci"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", type=~"patroni|patroni-ci"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_client_conn_primary
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg_over_time(pgbouncer_used_clients{type=~"pgbouncer|pgbouncer-registry|pgbouncer-ci"}[5m])
            /
            15000
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_client_conn_replicas
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg_over_time(pgbouncer_used_clients{type=~"patroni|patroni-registry|patroni-ci"}[5m])
            /
            30000
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_single_core
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without(cpu, mode) (
              rate(
                namedprocess_namegroup_cpu_seconds_total{groupname=~"pgbouncer.*", type=~"pgbouncer|patroni"}[5m]
              )
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_primary_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"pgbouncer|pgbouncer-registry|pgbouncer-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"pgbouncer|pgbouncer-registry|pgbouncer-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"pgbouncer|pgbouncer-registry|pgbouncer-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"pgbouncer|pgbouncer-registry|pgbouncer-ci"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name=~"gitlabhq_registry|gitlabhq_production", type=~"pgbouncer|pgbouncer-registry|pgbouncer-ci"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_replica_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"patroni|patroni-registry|patroni-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"patroni|patroni-registry|patroni-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"patroni|patroni-registry|patroni-ci"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", type=~"patroni|patroni-registry|patroni-ci"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name=~"gitlabhq_registry|gitlabhq_production", type=~"patroni|patroni-registry|patroni-ci"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: private_runners
      stage: main
      tier: runners
      type: ci-runners
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state) (
              max_over_time(gitlab_runner_jobs{job="runners-manager",shard="private"}[1m])
            )
            /
            gitlab_runner_limit{job="runners-manager",shard="private"} > 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pvs_cloudrun_container_instances
      stage: main
      tier: inf
      type: pvs
    expr: "max by(environment) (\n  clamp_min(\n    clamp_max(\n      sum by (environment,
      state) (\n        stackdriver_cloud_run_revision_run_googleapis_com_container_instance_count{\n
      \         configuration_name=\"pipeline-validation-service\",\n          \n
      \       }\n      )\n      /\n      100\n      ,\n      1)\n  ,\n  0)\n)\n"
  - record: gitlab_component_saturation:ratio
    labels:
      component: rails_db_connection_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(gitlab_database_connection_pool_busy{class="ActiveRecord::Base", type=~"web|api|git|sidekiq|websockets"}[5m])
              +
              avg_over_time(gitlab_database_connection_pool_dead{class="ActiveRecord::Base", type=~"web|api|git|sidekiq|websockets"}[5m])
            )
            /
            gitlab_database_connection_pool_size{class="ActiveRecord::Base", type=~"web|api|git|sidekiq|websockets"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_clients
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max_over_time(redis_connected_clients{type=~"redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis"}[1m])
            /
            redis_config_maxclients{type=~"redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max by (environment, tier, type, stage, fqdn) (
              label_replace(redis_memory_used_rss_bytes{type=~"redis-cache|redis-sidekiq|redis-ratelimiting|redis-sessions|redis-registry-cache|redis"}, "memtype", "rss","","")
              or
              label_replace(redis_memory_used_bytes{type=~"redis-cache|redis-sidekiq|redis-ratelimiting|redis-sessions|redis-registry-cache|redis"}, "memtype", "used","","")
            )
            /
            avg by (environment, tier, type, stage, fqdn) (
              node_memory_MemTotal_bytes{type=~"redis-cache|redis-sidekiq|redis-ratelimiting|redis-sessions|redis-registry-cache|redis"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_memory_cache
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              max by (environment, tier, type, stage, fqdn) (
                redis_memory_used_bytes{type="redis-cache"}
              )
              /
              avg by (environment, tier, type, stage, fqdn) (
                redis_memory_max_bytes{type="redis-cache"}
              )
            ) and on (fqdn) redis_memory_max_bytes{type="redis-cache"} != 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_memory_sessions
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              max by (environment, tier, type, stage, fqdn) (
                redis_memory_used_bytes{type="redis-sessions"}
              )
              /
              avg by (environment, tier, type, stage, fqdn) (
                redis_memory_max_bytes{type="redis-sessions"}
              )
            ) and on (fqdn) redis_memory_max_bytes{type="redis-sessions"} != 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_memory_tracechunks
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max by (environment, tier, type, stage, fqdn) (
              label_replace(redis_memory_used_rss_bytes{type="redis-tracechunks"}, "memtype", "rss","","")
              or
              label_replace(redis_memory_used_bytes{type="redis-tracechunks"}, "memtype", "used","","")
            )
            /
            avg by (environment, tier, type, stage, fqdn) (
              node_memory_MemTotal_bytes{type="redis-tracechunks"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_primary_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, fqdn) (
              rate(
                namedprocess_namegroup_thread_cpu_seconds_total{type=~"redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis", groupname="redis-server", threadname="redis-server"}[1m])
            )
            and on (fqdn) redis_instance_info{role="master"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_secondary_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              rate(redis_cpu_user_seconds_total{type=~"redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis"}[1m])
              +
              rate(redis_cpu_sys_seconds_total{type=~"redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis"}[1m])
            )
            and on (instance) redis_instance_info{role!="master"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: ruby_thread_contention
    expr: |
      quantile by(environment, tier, type, stage) (
        0.99,
        clamp_min(
          clamp_max(
            rate(ruby_process_cpu_seconds_total{type=~"web|sidekiq|api|git|websockets"}[10m])
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: shard_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - avg by (environment, tier, type, stage, shard) (
              rate(node_cpu_seconds_total{mode="idle", type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: shared_runners
      stage: main
      tier: runners
      type: ci-runners
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state, runner) (
              max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared"}[1m])
            )
            /
            gitlab_runner_concurrent{job="runners-manager",shard="shared"} > 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: shared_runners_gitlab
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state) (
              max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared-gitlab-org"}[1m])
            )
            /
            gitlab_runner_limit{job="runners-manager",shard="shared-gitlab-org"} > 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: sidekiq_shard_workers
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, shard) (
              avg_over_time(sidekiq_running_jobs{shard!~"database-throttled|elasticsearch|gitaly-throttled|urgent-authorized-projects", type="sidekiq"}[5m])
            )
            /
            sum by (environment, tier, type, stage, shard) (
              avg_over_time(sidekiq_concurrency{shard!~"database-throttled|elasticsearch|gitaly-throttled|urgent-authorized-projects", type="sidekiq"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: single_node_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", type=~"gitaly|ci-runners|consul|customersdot|frontend|jaeger|monitoring|patroni|patroni-registry|patroni-ci|postgres-archive|pgbouncer|pgbouncer-registry|pgbouncer-ci|praefect|redis-cache|redis-sidekiq|redis-tracechunks|redis-ratelimiting|redis-sessions|redis-registry-cache|redis|registry|sentry|web-pages"}[5m]))
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: single_node_puma_workers
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by(environment, tier, type, stage, fqdn) (avg_over_time(instance:puma_active_connections:sum{type=~"web|api|git|sidekiq|websockets"}[1m]))
            /
            sum by(environment, tier, type, stage, fqdn) (instance:puma_max_threads:sum{type=~"web|api|git|sidekiq|websockets"})
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: workhorse_image_scaling
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg_over_time(gitlab_workhorse_image_resize_processes{type="web"}[5m])
              /
            gitlab_workhorse_image_resize_max_processes{type="web"}
            ,
            1)
        ,
        0)
      )
- name: Resource Saturation Rules (autogenerated)
  interval: 1m
  rules:
  - record: gitlab_component_resource_saturation:ratio
    labels:
      component: sidekiq_shard_workers
    expr: |
      max by(environment, tier, type, stage, shard) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, shard) (
              avg_over_time(sidekiq_running_jobs{shard!~"database-throttled|elasticsearch|gitaly-throttled|urgent-authorized-projects", type="sidekiq"}[5m])
            )
            /
            sum by (environment, tier, type, stage, shard) (
              avg_over_time(sidekiq_concurrency{shard!~"database-throttled|elasticsearch|gitaly-throttled|urgent-authorized-projects", type="sidekiq"}[5m])
            )
            ,
            1)
        ,
        0)
      )
- name: GitLab Component Saturation Max SLOs
  interval: 5m
  rules:
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: cgroup_memory
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: cgroup_memory
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: cloudsql_cpu
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: cloudsql_cpu
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: cloudsql_disk
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: cloudsql_disk
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: cloudsql_memory
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: cloudsql_memory
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: cpu
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: cpu
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_inodes
    expr: "0.75"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_inodes
    expr: "0.8"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_space
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_space
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_iops
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_iops
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_throughput
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_throughput
    expr: "0.8"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_iops
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_iops
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_throughput
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_throughput
    expr: "0.8"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_cpu
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_cpu
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_disk_space
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_disk_space
    expr: "0.85"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_jvm_heap_memory
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_jvm_heap_memory
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_cpu
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_cpu
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_disk_space
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_disk_space
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_thread_pools
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_thread_pools
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: gcp_quota_limit
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: gcp_quota_limit
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: gitaly_active_node_available_space
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: gitaly_active_node_available_space
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: gitaly_total_disk_space
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: gitaly_total_disk_space
    expr: "0.85"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_container_cpu
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_container_cpu
    expr: "0.99"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_container_memory
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_container_memory
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_horizontalpodautoscaler_desired_replicas
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_horizontalpodautoscaler_desired_replicas
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_disk_space
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_disk_space
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_inodes
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_inodes
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_pool_cpu
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_pool_cpu
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: memory
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: memory
    expr: "0.98"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: memory_redis_cache
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: memory_redis_cache
    expr: "0.98"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: nat_gateway_port_allocation
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: nat_gateway_port_allocation
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: nat_host_port_allocation
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: nat_host_port_allocation
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: nf_conntrack_entries
    expr: "0.95"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: nf_conntrack_entries
    expr: "0.98"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: node_schedstat_waiting
    expr: "0.1"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: node_schedstat_waiting
    expr: "0.15"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: open_fds
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: open_fds
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_primary
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_primary
    expr: "0.8"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_replica
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_replica
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_btree_bloat
    expr: "0.3"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_btree_bloat
    expr: "0.4"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_int4_id
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_int4_id
    expr: "0.8"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_table_bloat
    expr: "0.3"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_table_bloat
    expr: "0.4"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_txid_vacuum_to_wraparound
    expr: "0.2"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_txid_vacuum_to_wraparound
    expr: "0.33"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_xid_wraparound
    expr: "0.6"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_xid_wraparound
    expr: "0.7"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_primary_pool
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_primary_pool
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_replica_pool
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_replica_pool
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_client_conn_primary
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_client_conn_primary
    expr: "0.85"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_client_conn_replicas
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_client_conn_replicas
    expr: "0.85"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_single_core
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_single_core
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_primary_pool
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_primary_pool
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_replica_pool
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_replica_pool
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: private_runners
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: private_runners
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pvs_cloudrun_container_instances
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pvs_cloudrun_container_instances
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: rails_db_connection_pool
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: rails_db_connection_pool
    expr: "0.99"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_clients
    expr: "0.8"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_clients
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_memory
    expr: "0.65"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_memory
    expr: "0.7"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_memory_cache
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_memory_cache
    expr: "0.75"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_memory_sessions
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_memory_sessions
    expr: "0.75"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_memory_tracechunks
    expr: "0.4"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_memory_tracechunks
    expr: "0.5"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_primary_cpu
    expr: "0.7"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_primary_cpu
    expr: "0.8"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_secondary_cpu
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_secondary_cpu
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: ruby_thread_contention
    expr: "0.75"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: ruby_thread_contention
    expr: "0.85"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: shard_cpu
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: shard_cpu
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: shared_runners
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: shared_runners
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: shared_runners_gitlab
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: shared_runners_gitlab
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: sidekiq_shard_workers
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: sidekiq_shard_workers
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: single_node_cpu
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: single_node_cpu
    expr: "0.95"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: single_node_puma_workers
    expr: "0.85"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: single_node_puma_workers
    expr: "0.9"
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: workhorse_image_scaling
    expr: "0.9"
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: workhorse_image_scaling
    expr: "0.95"
- name: GitLab Component Saturation Metadata
  interval: 5m
  rules:
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: cgroup_memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: cloudsql_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: cloudsql_disk
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: cloudsql_memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_inodes
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_space
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_sustained_read_iops
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_sustained_read_throughput
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_sustained_write_iops
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_sustained_write_throughput
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: elastic_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: elastic_disk_space
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: exclude
      component: elastic_jvm_heap_memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: elastic_single_node_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: elastic_single_node_disk_space
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: elastic_thread_pools
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: gcp_quota_limit
      horiz_scaling: "no"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: gitaly_active_node_available_space
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: gitaly_total_disk_space
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_container_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_container_memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_horizontalpodautoscaler_desired_replicas
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_persistent_volume_claim_disk_space
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_persistent_volume_claim_inodes
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_pool_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: exclude
      component: memory_redis_cache
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: nat_gateway_port_allocation
      horiz_scaling: "no"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: nat_host_port_allocation
      horiz_scaling: "no"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: nf_conntrack_entries
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: node_schedstat_waiting
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: open_fds
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pg_active_db_connections_primary
      horiz_scaling: "no"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pg_active_db_connections_replica
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pg_btree_bloat
      horiz_scaling: "no"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pg_int4_id
      horiz_scaling: "no"
      quantile: max
      severity: s1
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pg_table_bloat
      horiz_scaling: "no"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pg_txid_vacuum_to_wraparound
      horiz_scaling: "no"
      quantile: max
      severity: s1
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pg_xid_wraparound
      horiz_scaling: "no"
      quantile: max
      severity: s1
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pgbouncer_async_primary_pool
      horiz_scaling: "no"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pgbouncer_async_replica_pool
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pgbouncer_client_conn_primary
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pgbouncer_client_conn_replicas
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pgbouncer_single_core
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pgbouncer_sync_primary_pool
      horiz_scaling: "no"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pgbouncer_sync_replica_pool
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: private_runners
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: pvs_cloudrun_container_instances
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: rails_db_connection_pool
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: redis_clients
      horiz_scaling: "no"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: redis_memory
      horiz_scaling: "no"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: redis_memory_cache
      horiz_scaling: "no"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: redis_memory_sessions
      horiz_scaling: "no"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: redis_memory_tracechunks
      horiz_scaling: "no"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: redis_primary_cpu
      horiz_scaling: "no"
      quantile: max
      severity: s1
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: redis_secondary_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: ruby_thread_contention
      horiz_scaling: "yes"
      quantile: "0.99"
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: shard_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: shared_runners
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: shared_runners_gitlab
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: sidekiq_shard_workers
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: single_node_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: single_node_puma_workers
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    expr: "1"
  - record: gitlab_component_saturation_info
    labels:
      capacity_planning_strategy: quantile95_1h
      component: workhorse_image_scaling
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    expr: "1"
- name: GitLab Component Saturation Statistics
  interval: 5m
  rules:
  - record: gitlab_component_saturation:ratio_quantile95_1w
    expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{}[1w])
  - record: gitlab_component_saturation:ratio_quantile99_1w
    expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{}[1w])
  - record: gitlab_component_saturation:ratio_quantile95_1h
    expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{}[1h])
  - record: gitlab_component_saturation:ratio_quantile99_1h
    expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{}[1h])
  - record: gitlab_component_saturation:ratio_avg_1h
    expr: avg_over_time(gitlab_component_saturation:ratio{}[1h])
- name: GitLab Saturation Alerts
  interval: 1m
  rules:
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Cgroup Memory Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cgroup Memory Utilization per Node resource:

        Cgroup memory utilization per node.

        Some services, notably Gitaly, are configured to run within a cgroup with a memory limit lower than the memory limit for the node. This ensures that a traffic spike to Gitaly does not affect other services on the node.

        If this resource is becoming saturated, this may indicate traffic spikes to Gitaly, abuse or possibly resource leaks in the application. Gitaly or other git processes may be killed by the OOM killer when this resource is saturated.
      grafana_dashboard_id: alerts-sat_cgroup_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cgroup_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2265664609"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_cache{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_swap{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="cgroup_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cgroup_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The CloudSQL CPU Utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the CloudSQL CPU Utilization resource:

        CloudSQL CPU utilization.

        See https://cloud.google.com/monitoring/api/metrics_gcp#gcp-cloudsql for more details
      grafana_dashboard_id: alerts-sat_cloudsql_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cloudsql_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3017284519"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, database_id) (
          clamp_min(
            clamp_max(
              avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_cpu_utilization{environment="{{ $labels.environment }}"}[5m])
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="cloudsql_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cloudsql_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The CloudSQL Disk Utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the CloudSQL Disk Utilization resource:

        CloudSQL Disk utilization.

        See https://cloud.google.com/monitoring/api/metrics_gcp#gcp-cloudsql for more details
      grafana_dashboard_id: alerts-sat_cloudsql_disk
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cloudsql_disk?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2351208402"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, database_id) (
          clamp_min(
            clamp_max(
              avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_disk_utilization{environment="{{ $labels.environment }}"}[5m])
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="cloudsql_disk"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cloudsql_disk"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The CloudSQL Memory Utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the CloudSQL Memory Utilization resource:

        CloudSQL Memory utilization.

        See https://cloud.google.com/monitoring/api/metrics_gcp#gcp-cloudsql for more details
      grafana_dashboard_id: alerts-sat_cloudsql_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cloudsql_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "395749012"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, database_id) (
          clamp_min(
            clamp_max(
              avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_memory_utilization{environment="{{ $labels.environment }}"}[5m])
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="cloudsql_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cloudsql_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Average Service CPU Utilization resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average Service CPU Utilization resource:

        This resource measures average CPU utilization across an all cores in a service fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling.
      grafana_dashboard_id: alerts-sat_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1465724101"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              1 - avg by (environment, tier, type, stage) (
                rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: The Disk inode Utilization per Device per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk inode Utilization per Device per Node resource:

        Disk inode utilization per device per node.

        If this is too high, its possible that a directory is filling up with files. Consider logging in an checking temp directories for large numbers of files
      grafana_dashboard_id: alerts-sat_disk_inodes
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_inodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "39965907"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              1 - (
                node_filesystem_files_free{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                node_filesystem_files{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="disk_inodes"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_inodes"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: The Disk Space Utilization per Device per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Space Utilization per Device per Node resource:

        Disk space utilization per device per node.
      grafana_dashboard_id: alerts-sat_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2661375984"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              (
                1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: The Disk Sustained Read IOPS Utilization per Node resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Read IOPS Utilization per Node resource:

        Disk sustained read IOPS utilization per node.
      grafana_dashboard_id: alerts-sat_disk_sus_read_iops
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_read_iops?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3942129027"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_reads_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_read_iops"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_read_iops"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: The Disk Sustained Read Throughput Utilization per Node resource of the
        {{ $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Read Throughput Utilization per Node resource:

        Disk sustained read throughput utilization per node.
      grafana_dashboard_id: alerts-sat_disk_sus_read_throughput
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_read_throughput?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3120931940"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_read_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_read_throughput"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_read_throughput"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: The Disk Sustained Write IOPS Utilization per Node resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Write IOPS Utilization per Node resource:

        Gitaly runs on Google Cloud's Persistent Disk product. This has a published sustained maximum write IOPS value. This value can be exceeded for brief periods.

        If a single node is consistently reaching saturation, it may indicate a noisy-neighbour repository, possible abuse or it may indicate that the node needs rebalancing.

        More information can be found at https://cloud.google.com/compute/docs/disks/performance.
      grafana_dashboard_id: alerts-sat_disk_sus_write_iops
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_write_iops?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1520756669"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_writes_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_write_iops"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_write_iops"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: The Disk Sustained Write Throughput Utilization per Node resource of
        the {{ $labels.type }} service ({{ $labels.stage }} stage) has a saturation
        exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Write Throughput Utilization per Node resource:

        Gitaly runs on Google Cloud's Persistent Disk product. This has a published sustained maximum write throughput value. This value can be exceeded for brief periods.

        If a single node is consistently reaching saturation, it may indicate a noisy-neighbour repository, possible abuse or it may indicate that the node needs rebalancing.

        More information can be found at https://cloud.google.com/compute/docs/disks/performance.
      grafana_dashboard_id: alerts-sat_disk_sus_write_throughput
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_write_throughput?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "374696527"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_written_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_write_throughput"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_write_throughput"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Average CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU utilization per Node.

        This resource measures all CPU across a fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling. The metrics are coming from elasticsearch_exporter.
      grafana_dashboard_id: alerts-sat_elastic_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_elastic_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "804418020"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              avg by (environment, tier, type, stage) (
                avg_over_time(elasticsearch_process_cpu_percent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m]) / 100
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Disk Utilization Overall resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Utilization Overall resource:

        Disk utilization per device per node.
      grafana_dashboard_id: alerts-sat_elastic_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_elastic_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2419103084"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, host) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, host) (
                (elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} - elasticsearch_filesystem_data_free_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"})
              )
              /
              sum by (environment, tier, type, stage, host) (
                elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="elastic_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The JVM Heap Utilization per Node resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the JVM Heap Utilization per Node resource:

        JVM heap memory utilization per node.
      grafana_dashboard_id: alerts-sat_elastic_jvm_heap_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_elastic_jvm_heap_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2329310959"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name) (
          clamp_min(
            clamp_max(
              elasticsearch_jvm_memory_used_bytes{area="heap", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              /
              elasticsearch_jvm_memory_max_bytes{area="heap", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_jvm_heap_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_jvm_heap_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Average CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU per Node.

        This resource measures all CPU across a fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling. The metrics are coming from elasticsearch_exporter.
      grafana_dashboard_id: alerts-sat_elastic_single_node_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_elastic_single_node_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2230690360"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name) (
          clamp_min(
            clamp_max(
              avg_over_time(elasticsearch_process_cpu_percent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) / 100
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_single_node_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_single_node_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Disk Utilization per Device per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Utilization per Device per Node resource:

        Disk utilization per device per node.
      grafana_dashboard_id: alerts-sat_elastic_node_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_elastic_node_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "658552830"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name) (
          clamp_min(
            clamp_max(
              (
                (
                  elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                  -
                  elasticsearch_filesystem_data_free_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                )
                /
                elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_single_node_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_single_node_disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Thread pool utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Thread pool utilization resource:

        Utilization of each thread pool on each node.

        Descriptions of the threadpool types can be found at https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html.
      grafana_dashboard_id: alerts-sat_elastic_thread_pools
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_elastic_thread_pools?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "525964640"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name, exported_type) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(elasticsearch_thread_pool_active_count{exported_type!="snapshot", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                /
                (avg_over_time(elasticsearch_thread_pool_threads_count{exported_type!="snapshot", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) > 0)
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_thread_pools"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_thread_pools"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: The GCP Quota utilization per environment resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the GCP Quota utilization per environment resource:

        GCP Quota utilization / limit ratio

        Saturation on a quota may cause problems with creating infrastructure resources on GCP.

        To fix, we can request a quota increase for the specific resource to the GCP support team.
      grafana_dashboard_id: alerts-gcp_quota_limit
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-gcp_quota_limit?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2585628061"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, metric, quotaregion) (
          clamp_min(
            clamp_max(
              (
                gcp_quota_usage{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              /
                gcp_quota_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ) > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="gcp_quota_limit"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gcp_quota_limit"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Gitaly Active Node Available Space resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Gitaly Active Node Available Space resource:

        Available space on active gitaly nodes

        Active nodes are Gitaly nodes that are currently receiving new repositories

        We allow new Gitaly nodes to receive traffic until their disk is about 80% full. After which we mark the weight of the node as 0 in the [Gitaly shard weights assigner](https://gitlab.com/gitlab-com/gl-infra/gitaly-shard-weights-assigner/-/blob/master/assigner.rb#L9).

        To make sure we always have enough shards receiving new repositories, we want to have at least 10% of the total storage to be available for new projects. When this resource gets saturated, we could be creating to many projects on a limited set of nodes, which could cause these nodes to be busier than usual.

        When this alert fires, consider adding new gitaly nodes when the gitaly_total_disk_space component is also close to saturation. Or [rebalance](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/gitaly/storage-rebalancing.md) some Gitaly nodes moving some projects off to empty nodes so they can also receive new traffic.
      grafana_dashboard_id: alerts-sat_gitaly_active_available_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_gitaly_active_available_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3803311012"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, shard) (
          clamp_min(
            clamp_max(
              1 - (
                sum by (environment, tier, type, stage, shard) (
                  node_filesystem_avail_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", device="/dev/sdb",shard=~"default|praefect"}
                  and
                  (instance:node_filesystem_avail:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", device="/dev/sdb",shard=~"default|praefect"} > 0.2)
                )
                /
                sum by (environment, tier, type, stage, shard)(
                  node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", device="/dev/sdb",shard=~"default|praefect"}
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="gitaly_active_node_available_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gitaly_active_node_available_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Gitaly Total Disk Utilization resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Gitaly Total Disk Utilization resource:

        Gitaly Total Disk Utilization.

        This saturation metric monitors the total available capacity across the entire Gitaly fleet. By ensuring that we keep sufficient headroom on the saturation resource, we are able to spread load across the fleet.

        When this alert fires, consider adding new Gitaly nodes. The [Gitaly Capacity Planner](https://dashboards.gitlab.net/d/alerts-gitaly_capacity_planner/alerts-gitaly-capacity-planner?orgId=1) dashboard can help determine how many new nodes will be needed.
      grafana_dashboard_id: alerts-sat_gitaly_total_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_gitaly_total_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "998219612"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, shard) (
          clamp_min(
            clamp_max(
              1 - (
                sum by (environment, tier, type, stage, shard) (
                  node_filesystem_avail_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", device="/dev/sdb"}
                )
                /
                sum by (environment, tier, type, stage, shard) (
                  node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", device="/dev/sdb"}
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="gitaly_total_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gitaly_total_disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: The Kube Container CPU Utilization resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Container CPU Utilization resource:

        Kubernetes containers are allocated a share of CPU. When this is exhausted, the container may be thottled.
      grafana_dashboard_id: alerts-sat_kube_container_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_container_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2713861591"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, pod, container) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, pod, container) (
                rate(container_cpu_usage_seconds_total:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              /
              sum by(environment, tier, type, stage, pod, container) (
                container_spec_cpu_quota:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                container_spec_cpu_period:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="kube_container_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_container_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: The Kube Container Memory Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Container Memory Utilization resource:

        Records the total memory utilization for containers for this service, as a percentage of the memory limit as configured through Kubernetes.
      grafana_dashboard_id: alerts-sat_kube_container_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_container_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "172578411"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              container_memory_working_set_bytes:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              /
              (container_spec_memory_limit_bytes:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} > 0)
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="kube_container_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_container_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: The Horizontal Pod Autoscaler Desired Replicas resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Horizontal Pod Autoscaler Desired Replicas resource:

        The [Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) automatically scales the number of Pods in a deployment based on metrics.

        The Horizontal Pod Autoscaler has a configured upper maximum. When this limit is reached, the HPA will not increase the number of pods and other resource saturation (eg, CPU, memory) may occur.
      grafana_dashboard_id: alerts-sat_kube_horizontalpodautoscaler
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_horizontalpodautoscaler?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "351198712"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, horizontalpodautoscaler, shard) (
          clamp_min(
            clamp_max(
              kube_horizontalpodautoscaler_status_desired_replicas:labeled{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", shard!~"database-throttled|elasticsearch|gitaly-throttled|imports|urgent-authorized-projects|urgent-other"}
              /
              kube_horizontalpodautoscaler_spec_max_replicas:labeled{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", shard!~"database-throttled|elasticsearch|gitaly-throttled|imports|urgent-authorized-projects|urgent-other"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/kube/kubernetes.md#hpascalecapability
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="kube_horizontalpodautoscaler_desired_replicas"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_horizontalpodautoscaler_desired_replicas"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Kube Persistent Volume Claim Space Utilisation resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Persistent Volume Claim Space Utilisation resource:

        disk space utilization on persistent volume claims.
      grafana_dashboard_id: alerts-sat_kube_pvc_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pvc_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4167694322"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, cluster, namespace, persistentvolumeclaim) (
          clamp_min(
            clamp_max(
              kubelet_volume_stats_used_bytes
              /
              kubelet_volume_stats_capacity_bytes
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Kube Persistent Volume Claim inode Utilisation resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Persistent Volume Claim inode Utilisation resource:

        inode utilization on persistent volume claims.
      grafana_dashboard_id: alerts-sat_kube_pvc_inodes
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pvc_inodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3153876074"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, persistentvolumeclaim) (
          clamp_min(
            clamp_max(
              kubelet_volume_stats_inodes_used
              /
              kubelet_volume_stats_inodes
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_inodes"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_inodes"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Average Node Pool CPU Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average Node Pool CPU Utilization resource:

        This resource measures average CPU utilization across an all cores in the node pool for a service fleet.

        If it is becoming saturated, it may indicate that the fleet needs horizontal scaling.
      grafana_dashboard_id: alerts-sat_kube_pool_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pool_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1839360107"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              1 - avg by (environment, tier, type, stage) (
                rate(node_cpu_seconds_total:labeled{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="kube_pool_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_pool_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Memory Utilization per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Memory Utilization per Node resource:

        Memory utilization per device per node.
      grafana_dashboard_id: alerts-sat_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1955556769"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              instance:node_memory_utilization:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} or instance:node_memory_utilisation:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Memory Utilization per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Memory Utilization per Node resource:

        Memory utilization per device per node.


        redis-cache has a separate saturation point for this to exclude it from capacity planning calculations.
      grafana_dashboard_id: alerts-sat_memory_redis_cache
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_memory_redis_cache?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2178235391"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              instance:node_memory_utilization:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} or instance:node_memory_utilisation:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="memory_redis_cache"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="memory_redis_cache"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Cloud NAT Gateway Port Allocation resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cloud NAT Gateway Port Allocation resource:

        Each NAT IP address on a Cloud NAT gateway offers 64,512 TCP source ports and 64,512 UDP source ports.

        When these are exhausted, processes may experience connection problems to external destinations. In the application these may manifest as SMTP connection drops or webhook delivery failures. In Kubernetes, nodes may fail while attempting to download images from external repositories.

        More details in the Cloud NAT documentation: https://cloud.google.com/nat/docs/ports-and-addresses
      grafana_dashboard_id: alerts-sat_nat_gw_port_allocation
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_nat_gw_port_allocation?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1436589381"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, gateway_name, project_id) (
          clamp_min(
            clamp_max(
              sum without(nat_ip) (
                stackdriver_nat_gateway_router_googleapis_com_nat_allocated_ports{
                  job="stackdriver",
                  project_id="gitlab-production",
                  environment="{{ $labels.environment }}"
                }
              )
              /
              ( 64512 * 43 )
              or
              sum without(nat_ip) (
                stackdriver_nat_gateway_router_googleapis_com_nat_allocated_ports{
                  job="stackdriver",
                  project_id="gitlab-staging-1",
                  environment="{{ $labels.environment }}"
                }
              )
              /
              ( 64512 * 16 )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="nat_gateway_port_allocation"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="nat_gateway_port_allocation"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: The Cloud NAT Host Port Allocation resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cloud NAT Host Port Allocation resource:

        Cloud NAT will allocate a set of NAT ports to each host in a cluster. When these are all allocated, Cloud NAT may be unable to allocate any more.

        When this happens, processes may experience connection problems to external destinations. In the application these may manifest as SMTP connection drops or webhook delivery failures. In Kubernetes, nodes may fail while attempting to download images from external repositories.

        More details in the Cloud NAT documentation: https://cloud.google.com/nat/docs/ports-and-addresses.

        Note: when reviewing the detail chart for this saturation point, the instance_id can be resolved using `gcloud compute instances list --project gitlab-production --filter "id=$instance_id"`.
      grafana_dashboard_id: alerts-sat_nat_host_port_allocation
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_nat_host_port_allocation?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2254997722"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, instance_id, nat_gateway_name, zone) (
          clamp_min(
            clamp_max(
              sum without(ip_protocol) (
                max_over_time(
                  stackdriver_gce_instance_compute_googleapis_com_nat_port_usage{
                    job="stackdriver",
                    project_id=~"gitlab-production|gitlab-staging-1",
                    environment="{{ $labels.environment }}"
                  }[5m]
                )
              )
              /
              sum without (nat_ip) (
                max_over_time(
                  stackdriver_gce_instance_compute_googleapis_com_nat_allocated_ports{
                    job="stackdriver",
                    project_id=~"gitlab-production|gitlab-staging-1",
                    environment="{{ $labels.environment }}"
                  }[5m]
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="nat_host_port_allocation"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="nat_host_port_allocation"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The conntrack Entries per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the conntrack Entries per Node resource:

        Netfilter connection tracking table utilization per node.

        When saturated, new connection attempts (incoming SYN packets) are dropped with no reply, leaving clients to slowly retry (and typically fail again) over the next several seconds.  When packets are being dropped due to this condition, kernel will log the event as: "nf_conntrack: table full, dropping packet".
      grafana_dashboard_id: alerts-sat_conntrack
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_conntrack?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "503581002"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              max_over_time(node_nf_conntrack_entries{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              /
              node_nf_conntrack_entries_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="nf_conntrack_entries"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="nf_conntrack_entries"}
  - alert: component_saturation_slo_out_of_bounds
    for: 90m
    annotations:
      title: The Node Scheduler Waiting Time resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Node Scheduler Waiting Time resource:

        Measures the amount of scheduler waiting time that processes are waiting to be scheduled, according to [`CPU Scheduling Metrics`](https://www.robustperception.io/cpu-scheduling-metrics-from-the-node-exporter).

        A high value indicates that a node has more processes to be run than CPU time available to handle them, and may lead to degraded responsiveness and performance from the application.

        Additionally, it may indicate that the fleet is under-provisioned.
      grafana_dashboard_id: alerts-sat_node_schedstat_waiting
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_node_schedstat_waiting?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1415313189"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, shard) (
          clamp_min(
            clamp_max(
              avg without (cpu) (rate(node_schedstat_waiting_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1h]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="node_schedstat_waiting"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="node_schedstat_waiting"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Open file descriptor utilization per instance resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Open file descriptor utilization per instance resource:

        Open file descriptor utilization per instance.

        Saturation on file descriptor limits may indicate a resource-descriptor leak in the application.

        As a temporary fix, you may want to consider restarting the affected process.
      grafana_dashboard_id: alerts-sat_open_fds
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_open_fds?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1001792825"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, job, instance) (
          clamp_min(
            clamp_max(
              (
                process_open_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              or
              (
                ruby_file_descriptors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                ruby_process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="open_fds"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="open_fds"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Active Primary DB Connection Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Active Primary DB Connection Utilization resource:

        Active db connection utilization on the primary node.

        Postgres is configured to use a maximum number of connections. When this resource is saturated, connections may queue.
      grafana_dashboard_id: alerts-sat_active_db_conns_primary
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_active_db_conns_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1954311497"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum without (state) (
                pg_stat_activity_count{datname=~"gitlabhq_production|gitlabhq_registry", state!="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} unless on(instance) (pg_replication_is_replica == 1)
              )
              / on (environment, tier, type, stage, fqdn)
              pg_settings_max_connections{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pg_active_db_connections_primary"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_active_db_connections_primary"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Active Secondary DB Connection Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Active Secondary DB Connection Utilization resource:

        Active db connection utilization per replica node

        Postgres is configured to use a maximum number of connections. When this resource is saturated, connections may queue.
      grafana_dashboard_id: alerts-sat_active_db_conns_replica
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_active_db_conns_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3266646533"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum without (state) (
                pg_stat_activity_count{datname=~"gitlabhq_production|gitlabhq_registry", state!="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} and on(instance) (pg_replication_is_replica == 1)
              )
              / on (environment, tier, type, stage, fqdn)
              pg_settings_max_connections{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pg_active_db_connections_replica"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_active_db_connections_replica"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Postgres btree bloat resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage) has a saturation exceeding SLO and is close to its
        capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres btree bloat resource:

        This measures the total bloat in Postgres Btree indexes, as a percentage of total index size.

        The larger this measure, the more pages will unnecessarily be retrieved during index scans.
      grafana_dashboard_id: alerts-sat_pg_btree_bloat
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_btree_bloat?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2387842464"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_bloat_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              /
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_real_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pg_btree_bloat"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_btree_bloat"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Postgres int4 ID capacity resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres int4 ID capacity resource:

        This measures used int4 primary key capacity in selected postgres tables. It is critically important that we do not reach saturation on this as GitLab will stop to work at this point.
      grafana_dashboard_id: alerts-sat_pg_int4_id
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_int4_id?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3254820333"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, table_name) (
          clamp_min(
            clamp_max(
              max by (environment, tier, type, stage, table_name) (
                pg_integer_capacity_current{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                pg_integer_capacity_maximum{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
    expr: |
      gitlab_component_saturation:ratio{component="pg_int4_id"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_int4_id"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Postgres Table Bloat resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage) has a saturation exceeding SLO and is close to its
        capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Table Bloat resource:

        This measures the total bloat in Postgres Table pages, as a percentage of total size. This includes bloat in TOAST tables, and excludes extra space reserved due to fillfactor.
      grafana_dashboard_id: alerts-sat_pg_table_bloat
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_table_bloat?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "773890326"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_bloat_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              /
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_real_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="pg_table_bloat"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_table_bloat"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Total autovacuum time to TXID wraparound horizon resource of the
        {{ $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Total autovacuum time to TXID wraparound horizon resource:

        This saturation metric measures the capacity of the Postgres primary instance to perform autovacuum operations on all tables.

        It measures the total time spent in vacuum operations, over a 24 hour period divided the maximum number of autovacuum processes to give the total vacuum activity, in seconds. This value is divided by the TXID wraparound horizon for the database to produce a percentage.

        This value will approach 100% as two situation occur:

        1. The amount of time spent performing autovacuum operations goes up, due to high dead-tuple generation in the database. 1. The write transaction volume goes up, decreasing the wraparound horizon.

        If the total time spent vacuuming approached the wraparound time horizon, this would mean that the database would be at risk of being unable to complete a vacuum of all tables within the wraparound time horizon. This would put the database at risk of XID wraparound and immediate shutdown.
      grafana_dashboard_id: alerts-sat_pg_txid_vac_wraparound
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_txid_vac_wraparound?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4019870218"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              (
                sum by (environment, tier, type, stage) (
                  increase(fluentd_pg_auto_vacuum_elapsed_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1d])
                )
                / on(environment, type) group_left() (
                  pg_settings_autovacuum_max_workers and
                  on (instance) pg_replication_is_replica == 0
                )
              )
              /
              (
                (2^31 - 10^6)
                /
                (
                  avg by (environment, tier, type, stage) (
                    deriv(pg_txid_current{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1d]) and
                    on (instance) pg_replication_is_replica == 0
                  )
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
    expr: |
      gitlab_component_saturation:ratio{component="pg_txid_vacuum_to_wraparound"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_txid_vacuum_to_wraparound"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Transaction ID Wraparound resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Transaction ID Wraparound resource:

        Risk of DB shutdown in the near future, approaching transaction ID wraparound.

        This is a critical situation.

        This saturation metric measures how close the database is to Transaction ID wraparound.

        When wraparound occurs, the database will automatically shutdown to prevent data loss, causing a full outage.

        Recovery would require entering single-user mode to run vacuum, taking the site down for a potentially multi-hour maintenance session.

        To avoid reaching the db shutdown threshold, consider the following short-term actions:

        1. Escalate to the SRE Datastores team, and then,

        2. Find and terminate any very old transactions. The runbook for this alert has details.  Do this first.  It is the most critical step and may be all that is necessary to let autovacuum do its job.

        3. Run a manual vacuum on tables with oldest relfrozenxid.  Manual vacuums run faster than autovacuum.

        4. Add autovacuum workers or reduce autovacuum cost delay, if autovacuum is chronically unable to keep up with the transaction rate.

        Long running transaction dashboard: https://dashboards.gitlab.net/d/alerts-long_running_transactions/alerts-long-running-transactions?orgId=1
      grafana_dashboard_id: alerts-sat_pg_xid_wraparound
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_xid_wraparound?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3666116359"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, datname) (
          clamp_min(
            clamp_max(
              (
                max without (series) (
                  label_replace(pg_database_wraparound_age_datfrozenxid{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "series", "datfrozenxid", "", "")
                  or
                  label_replace(pg_database_wraparound_age_datminmxid{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "series", "datminmxid", "", "")
                )
                and on (instance, job) (pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0)
              )
              /
              (2^31 - 10^6)
              ,
              1)
          ,
          0)
        )
      runbook: docs/patroni/pg_xid_wraparound_alert.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
    expr: |
      gitlab_component_saturation:ratio{component="pg_xid_wraparound"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_xid_wraparound"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: The Postgres Async (Sidekiq) primary Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage)
        has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Async (Sidekiq) primary Connection Pool Utilization per Node resource:

        pgbouncer async connection pool utilization per database node, for primary database connections.

        Sidekiq maintains it's own pgbouncer connection pool. When this resource is saturated, database operations may queue, leading to additional latency in background processing.
      grafana_dashboard_id: alerts-sat_pgbouncer_async_pool_primary
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_async_pool_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1228921753"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_async_primary_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_async_primary_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: The Postgres Async (Sidekiq) replica Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage)
        has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Async (Sidekiq) replica Connection Pool Utilization per Node resource:

        pgbouncer async connection pool utilization per database node, for replica database connections.

        Sidekiq maintains it's own pgbouncer connection pool. When this resource is saturated, database operations may queue, leading to additional latency in background processing.
      grafana_dashboard_id: alerts-sat_pgbouncer_async_pool_replica
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_async_pool_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4069682945"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_async_replica_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_async_replica_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The PGBouncer Client Connections per Process (Primary) resource of the
        {{ $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the PGBouncer Client Connections per Process (Primary) resource:

        Client connections per pgbouncer process for Primary connections.

        pgbouncer is configured to use a `max_client_conn` setting. This limits the total number of client connections per pgbouncer.

        When this limit is reached, client connections may be refused, and `max_client_conn` errors may appear in the pgbouncer logs.

        This could affect users as Rails clients are left unable to connect to the database. Another potential knock-on effect is that Rails clients could fail their readiness checks for extended periods during a deployment, leading to saturation of the older nodes.
      grafana_dashboard_id: alerts-sat_pgb_client_conn_primary
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgb_client_conn_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1712365426"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg_over_time(pgbouncer_used_clients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              /
              15000
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_client_conn_primary"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_client_conn_primary"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The PGBouncer Client Connections per Process (Replicas) resource of the
        {{ $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the PGBouncer Client Connections per Process (Replicas) resource:

        Client connections per pgbouncer process for Replicas connections.

        pgbouncer is configured to use a `max_client_conn` setting. This limits the total number of client connections per pgbouncer.

        When this limit is reached, client connections may be refused, and `max_client_conn` errors may appear in the pgbouncer logs.

        This could affect users as Rails clients are left unable to connect to the database. Another potential knock-on effect is that Rails clients could fail their readiness checks for extended periods during a deployment, leading to saturation of the older nodes.
      grafana_dashboard_id: alerts-sat_pgb_client_conn_replicas
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgb_client_conn_replicas?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3093058894"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg_over_time(pgbouncer_used_clients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              /
              30000
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_client_conn_replicas"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_client_conn_replicas"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The PGBouncer Single Core per Node resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the PGBouncer Single Core per Node resource:

        PGBouncer single core CPU utilization per node.

        PGBouncer is a single threaded application. Under high volumes this resource may become saturated, and additional pgbouncer nodes may need to be provisioned.
      grafana_dashboard_id: alerts-sat_pgbouncer_single_core
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_single_core?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1214397558"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, groupname) (
          clamp_min(
            clamp_max(
              sum without(cpu, mode) (
                rate(
                  namedprocess_namegroup_cpu_seconds_total{groupname=~"pgbouncer.*", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_single_core"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_single_core"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: The Postgres Sync (Web/API/Git) primary Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage)
        has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Sync (Web/API/Git) primary Connection Pool Utilization per Node resource:

        pgbouncer sync connection pool Saturation per database node, for primary database connections.

        Web/api/git applications use a separate connection pool to sidekiq.

        When this resource is saturated, web/api database operations may queue, leading to rails worker saturation and 503 errors in the web.
      grafana_dashboard_id: alerts-sat_pgb_sync_pool_primary
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgb_sync_pool_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4055772849"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_sync_primary_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_sync_primary_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: The Postgres Sync (Web/API/Git) replica Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage)
        has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Sync (Web/API/Git) replica Connection Pool Utilization per Node resource:

        pgbouncer sync connection pool Saturation per database node, for replica database connections.

        Web/api/git applications use a separate connection pool to sidekiq.

        When this resource is saturated, web/api database operations may queue, leading to rails worker saturation and 503 errors in the web.
      grafana_dashboard_id: alerts-sat_pgb_sync_pool_replica
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgb_sync_pool_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2061891964"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user=~"gitlab|gitlab-registry", database=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name=~"gitlabhq_registry|gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_sync_replica_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_sync_replica_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Private Runners utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Private Runners utilization resource:

        Private runners utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_private_runners
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_private_runners?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "204635596"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state) (
                max_over_time(gitlab_runner_jobs{job="runners-manager",shard="private"}[1m])
              )
              /
              gitlab_runner_limit{job="runners-manager",shard="private"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="private_runners"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="private_runners"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Cloud Run Container Instance Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cloud Run Container Instance Utilization resource:

        Cloud Run is configured with a maximum number of container instances. When this is saturated, Google Cloud Run will no longer scale up.

        More information available at https://cloud.google.com/run/docs/configuring/max-instances.
      grafana_dashboard_id: alerts-sat_pvs_cloudrun_ctr_instances
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pvs_cloudrun_ctr_instances?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "754592114"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, state) (
          clamp_min(
            clamp_max(
              sum by (environment, state) (
                stackdriver_cloud_run_revision_run_googleapis_com_container_instance_count{
                  configuration_name="pipeline-validation-service",
                  environment="{{ $labels.environment }}"
                }
              )
              /
              100
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pvs_cloudrun_container_instances"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pvs_cloudrun_container_instances"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: The Rails DB Connection Pool Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Rails DB Connection Pool Utilization resource:

        Rails uses connection pools for its database connections. As each node may have multiple connection pools, this is by node and by database host.

        Read more about this resource in our [documentation](https://docs.gitlab.com/ee/development/database/client_side_connection_pool.html#client-side-connection-pool).

        If this resource is saturated, it may indicate that our connection pools are not correctly sized, perhaps because an unexpected application thread is using a database connection.
      grafana_dashboard_id: alerts-sat_rails_db_connection_pool
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_rails_db_connection_pool?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "391047339"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, instance, host, port) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(gitlab_database_connection_pool_busy{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                +
                avg_over_time(gitlab_database_connection_pool_dead{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              /
              gitlab_database_connection_pool_size{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="rails_db_connection_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="rails_db_connection_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Redis Client Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Client Utilization per Node resource:

        Redis client utilization per node.

        A redis server has a maximum number of clients that can connect. When this resource is saturated, new clients may fail to connect.

        More details at https://redis.io/topics/clients#maximum-number-of-clients
      grafana_dashboard_id: alerts-sat_redis_clients
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_clients?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "127397613"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max_over_time(redis_connected_clients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              /
              redis_config_maxclients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="redis_clients"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_clients"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Redis Memory Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Memory Utilization per Node resource:

        Redis memory utilization per node.

        As Redis memory saturates node memory, the likelyhood of OOM kills, possibly to the Redis process, become more likely.

        For caches, consider lowering the `maxmemory` setting in Redis. For non-caching Redis instances, this has been caused in the past by credential stuffing, leading to large numbers of web sessions.

        This threshold is kept deliberately low, since Redis RDB snapshots could consume a significant amount of memory, especially when the rate of change in Redis is high, leading to copy-on-write consuming more memory than when the rate-of-change is low.
      grafana_dashboard_id: alerts-sat_redis_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1855027052"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max by (environment, tier, type, stage, fqdn) (
                label_replace(redis_memory_used_rss_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "rss","","")
                or
                label_replace(redis_memory_used_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "used","","")
              )
              /
              avg by (environment, tier, type, stage, fqdn) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="redis_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Redis Memory Utilization of Max Memory resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Memory Utilization of Max Memory resource:

        Redis maxmemory utilization per node

        On the cache Redis we have maxmemory and an eviction policy as a safety-valve, but do not want or expect to reach that limit under normal circumstances; if we start evicting we will experience performance problems , so we want to be alerted some time before that happens.
      grafana_dashboard_id: alerts-sat_redis_memory_cache
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_memory_cache?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "19142171"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                max by (environment, tier, type, stage, fqdn) (
                  redis_memory_used_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                )
                /
                avg by (environment, tier, type, stage, fqdn) (
                  redis_memory_max_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                )
              ) and on (fqdn) redis_memory_max_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} != 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="redis_memory_cache"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_memory_cache"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Redis Memory Utilization of Max Memory resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Memory Utilization of Max Memory resource:

        Redis maxmemory utilization per node

        On the sessions Redis we have maxmemory and an eviction policy as a safety-valve, but do not want or expect to reach that limit under normal circumstances; if we start evicting we will start logging out users slightly early (although only the longest inactive sessions), so we want to be alerted some time before that happens.
      grafana_dashboard_id: alerts-sat_redis_memory_sessions
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_memory_sessions?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4256988953"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                max by (environment, tier, type, stage, fqdn) (
                  redis_memory_used_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                )
                /
                avg by (environment, tier, type, stage, fqdn) (
                  redis_memory_max_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                )
              ) and on (fqdn) redis_memory_max_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} != 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="redis_memory_sessions"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_memory_sessions"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Redis Memory Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Memory Utilization per Node resource:

        Redis memory utilization per node.

        As Redis memory saturates node memory, the likelyhood of OOM kills, possibly to the Redis process, become more likely.

        Trace chunks should be extremely transient (written to redis, then offloaded to objectstorage nearly immediately) so any uncontrolled growth in memory saturation implies a potentially significant problem.  Short term mitigation is usually to upsize the instances to have more memory while the underlying problem is identified, but low thresholds give us more time to investigate first

        This threshold is kept deliberately very low; because we use C2 instances we are generally overprovisioned for RAM, and because of the transient nature of the data here, it is advantageous to know early if there is any non-trivial storage occurring
      grafana_dashboard_id: alerts-sat_redis_memory_tracechunks
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_memory_tracechunks?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3185191014"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max by (environment, tier, type, stage, fqdn) (
                label_replace(redis_memory_used_rss_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "rss","","")
                or
                label_replace(redis_memory_used_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "used","","")
              )
              /
              avg by (environment, tier, type, stage, fqdn) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="redis_memory_tracechunks"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_memory_tracechunks"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Redis Primary CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Primary CPU Utilization per Node resource:

        Redis Primary CPU Utilization per Node.

        The core server of redis is single-threaded; this thread is only able to scale to full use of a single CPU on a given server. When the primary Redis thread is saturated, major slowdowns should be expected across the application, so avoid if at all possible.
      grafana_dashboard_id: alerts-sat_redis_primary_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_primary_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4143300761"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, fqdn) (
                rate(
                  namedprocess_namegroup_thread_cpu_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", groupname="redis-server", threadname="redis-server"}[1m])
              )
              and on (fqdn) redis_instance_info{role="master"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
    expr: |
      gitlab_component_saturation:ratio{component="redis_primary_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_primary_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Redis Secondary CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Secondary CPU Utilization per Node resource:

        Redis Secondary CPU Utilization per Node.

        Redis is single-threaded. A single Redis server is only able to scale as far as a single CPU on a single host. CPU saturation on a secondary is not as serious as critical as saturation on a primary, but could lead to replication delays.
      grafana_dashboard_id: alerts-sat_redis_secondary_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_secondary_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "577905942"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                rate(redis_cpu_user_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
                +
                rate(redis_cpu_sys_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              )
              and on (instance) redis_instance_info{role!="master"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="redis_secondary_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_secondary_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Ruby Thread Contention resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Ruby Thread Contention resource:

        Ruby (technically Ruby MRI), like some other scripting languages, uses a Global VM lock (GVL) also known as a Global Interpreter Lock (GIL) to ensure that multiple threads can execute safely. Ruby code is only allowed to execute in one thread in a process at a time. When calling out to c extensions, the thread can cede the lock to other thread while it continues to execute.

        This means that when CPU-bound workloads run in a multithreaded environment such as Puma or Sidekiq, contention with other Ruby worker threads running in the same process can occur, effectively slowing thoses threads down as they await GVL entry.

        Often the best fix for this situation is to add more workers by scaling up the fleet.
      grafana_dashboard_id: alerts-sat_ruby_thread_contention
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_ruby_thread_contention?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2359646072"
      grafana_variables: environment,type,stage
      promql_query: |
        quantile by(environment, tier, type, stage, fqdn, pod) (
          0.99,
          clamp_min(
            clamp_max(
              rate(ruby_process_cpu_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m])
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="ruby_thread_contention"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="ruby_thread_contention"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Average CPU Utilization per Shard resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Shard resource:

        This resource measures average CPU utilization across an all cores in a shard of a service fleet. If it is becoming saturated, it may indicate that the shard needs horizontal or vertical scaling.
      grafana_dashboard_id: alerts-sat_shard_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_shard_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1472933476"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, shard) (
          clamp_min(
            clamp_max(
              1 - avg by (environment, tier, type, stage, shard) (
                rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="shard_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shard_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Shared Runner utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Shared Runner utilization resource:

        Shared runner utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_shared_runners
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_shared_runners?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2853615952"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state, runner) (
                max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared"}[1m])
              )
              /
              gitlab_runner_concurrent{job="runners-manager",shard="shared"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="shared_runners"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shared_runners"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Shared Runner GitLab Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Shared Runner GitLab Utilization resource:

        Shared runners utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_shared_runners_gitlab
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_shared_runners_gitlab?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3295582630"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state) (
                max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared-gitlab-org"}[1m])
              )
              /
              gitlab_runner_limit{job="runners-manager",shard="shared-gitlab-org"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="shared_runners_gitlab"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shared_runners_gitlab"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: The Sidekiq Worker Utilization per shard resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Sidekiq Worker Utilization per shard resource:

        Sidekiq worker utilization per shard.

        This metric represents the percentage of available threads*workers that are actively processing jobs.

        When this metric is saturated, new Sidekiq jobs will queue. Depending on whether or not the jobs are latency sensitive, this could impact user experience.
      grafana_dashboard_id: alerts-sat_sidekiq_shard_workers
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_sidekiq_shard_workers?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "836813313"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, shard) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, shard) (
                avg_over_time(sidekiq_running_jobs{shard!~"database-throttled|elasticsearch|gitaly-throttled|urgent-authorized-projects", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              /
              sum by (environment, tier, type, stage, shard) (
                avg_over_time(sidekiq_concurrency{shard!~"database-throttled|elasticsearch|gitaly-throttled|urgent-authorized-projects", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="sidekiq_shard_workers"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="sidekiq_shard_workers"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: The Average CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU utilization per Node.

        If average CPU is saturated, it may indicate that a fleet is in need to horizontal or vertical scaling. It may also indicate imbalances in load in a fleet.
      grafana_dashboard_id: alerts-sat_single_node_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_single_node_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3372411356"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="single_node_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="single_node_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: The Puma Worker Saturation per Node resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Puma Worker Saturation per Node resource:

        Puma thread utilization per node.

        Puma uses a fixed size thread pool to handle HTTP requests. This metric shows how many threads are busy handling requests. When this resource is saturated, we will see puma queuing taking place. Leading to slowdowns across the application.

        Puma saturation is usually caused by latency problems in downstream services: usually Gitaly or Postgres, but possibly also Redis. Puma saturation can also be caused by traffic spikes.
      grafana_dashboard_id: alerts-sat_single_node_puma_workers
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_single_node_puma_workers?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2677029523"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by(environment, tier, type, stage, fqdn) (avg_over_time(instance:puma_active_connections:sum{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m]))
              /
              sum by(environment, tier, type, stage, fqdn) (instance:puma_max_threads:sum{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"})
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="single_node_puma_workers"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="single_node_puma_workers"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: The Workhorse Image Scaler Exhaustion per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Workhorse Image Scaler Exhaustion per Node resource:

        Workhorse can scale images on-the-fly as requested. Since the actual work will be performed by dedicated processes, we currently define a hard cap for how many such requests are allowed to be in the system concurrently.

        If this resource is fully saturated, Workhorse will start ignoring image scaling requests and serve the original image instead, which will ensure continued operation, but comes at the cost of additional client latency and GCS egress traffic.
      grafana_dashboard_id: alerts-sat_wh_image_scaling
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_wh_image_scaling?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3379320113"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg_over_time(gitlab_workhorse_image_resize_processes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                /
              gitlab_workhorse_image_resize_max_processes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="workhorse_image_scaling"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="workhorse_image_scaling"}
