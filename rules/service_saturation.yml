groups:
- name: GitLab Saturation Ratios
  interval: 1m
  rules:
  # type: *, component: cpu
  # this measures average CPU across all the cores for the entire fleet for the given service
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'cpu'
    expr: >
      avg(1 - rate(node_cpu_seconds_total{mode="idle", type!="", type!~"console-node|deploy-node"}[1m])) by (type, tier, stage, environment)

  # type: *, component: single_node_cpu
  # this measures the maximum cpu availability across all the codes on a single server
  # this can be helpful if CPU is not even distributed across the fleet.
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'single_node_cpu'
    expr: >
      max(
        avg(1 - rate(node_cpu_seconds_total{mode="idle", type!="", type!~"console-node|deploy-node"}[1m])) by (fqdn, type, tier, stage, environment)
      ) without (fqdn)

  - record: gitlab_component_saturation:ratio
    labels:
      component: 'disk_space'
    expr: >
      max(
        (
          (
            node_filesystem_size_bytes{type!="", tier!="", fstype=~"ext.|xfs"}
            -
            node_filesystem_free_bytes{type!="", tier!="", fstype=~"ext.|xfs"}
          )
          /
          node_filesystem_size_bytes{type!="", tier!="", fstype=~"ext.|xfs"}
        )
      ) by (type, tier, stage, environment)

  - record: gitlab_component_saturation:ratio
    labels:
      component: 'memory'
    expr: >
      max by (type, tier, stage, environment) (
        instance:node_memory_utilization:ratio{type!=""}
      )

  # type: web/api/git, component: workers
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'workers'
    expr: >
      clamp_max(
        sum(avg_over_time(unicorn_active_connections{job=~"gitlab-(rails|unicorn)"}[1m])) by (type, tier, stage, environment)
        /
        sum(max(unicorn_workers) without (pid)) by (type, tier, stage, environment),
        1
      )

  # type: web/api/git, component: single_node_unicorn_workers
  # Single node workers is a similar metric to the normal unicorn `worker` metric,
  # except that it only measures a single host. This reason for this is that once HAProxy has routed
  # a request to a single host it is (for now) trapped on that host until its complete.
  # There are cases where a single host will receive an unbalanced amount of traffic. In this case,
  # unicorn saturation could occur on that host without happening across the fleet in general.
  # An example of this was https://gitlab.com/gitlab-com/gl-infra/infrastructure/issues/7916
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'single_node_unicorn_workers'
    expr: >
      clamp_max(
        max(
          sum(avg_over_time(unicorn_active_connections{job=~"gitlab-(rails|unicorn)"}[1m])) by (fqdn, type, tier, stage, environment)
          /
          sum(max(unicorn_workers) without (pid)) by (fqdn, type, tier, stage, environment)
        ) without(fqdn),
        1
      )



  # type: redis/redis cache, component: single_threaded_cpu
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'single_threaded_cpu'
    expr: >
      clamp_max(
        max by (type, tier, stage, environment) (
          instance:redis_cpu_usage:rate1m
        ),
        1
      )

  # type: pgbouncer,patroni, component: pgbouncer_single_core
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'pgbouncer_single_core'
    expr: >
      max(
        sum(
          rate(
            namedprocess_namegroup_cpu_seconds_total{groupname=~"pgbouncer.*", type=~"pgbouncer|patroni"}[1m]
          )
        ) by (groupname, fqdn, type, tier, stage, environment)
      ) by (type, tier, stage, environment)

  # type: pgbouncer, component: server_connections_pools
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'connection_pool'
    expr: >
      clamp_max(
        max(
          max_over_time(pgbouncer_pools_server_active_connections{user="gitlab"}[1m]) /
          (
            (
              pgbouncer_pools_server_idle_connections{user="gitlab"} +
              pgbouncer_pools_server_active_connections{user="gitlab"} +
              pgbouncer_pools_server_testing_connections{user="gitlab"} +
              pgbouncer_pools_server_used_connections{user="gitlab"} +
              pgbouncer_pools_server_login_connections{user="gitlab"}
            )
            > 0
          )
      ) by (type, tier, stage, environment), 1)

  # type: postgres-delayed, postgres-archive, patroni
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'active_db_connections'
    expr: >
      clamp_max(
        max(
          sum without(state) (pg_stat_activity_count{datname="gitlabhq_production", state!="idle"})
          /
          (sum without(state) (pg_stat_activity_count{datname="gitlabhq_production"}) > 0)
      ) by (type, tier, stage, environment), 1)

  # type: redis, redis-cache, component: redis_clients
  # Records the saturation of redis client connections against a redis fleet
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'redis_clients'
    expr: >
      max(
        max_over_time(redis_connected_clients[1m])
        /
        redis_config_maxclients
      ) by (environment, tier, type, stage)

  # type: *
  # cadvisor cgroup memory saturation limits
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'cgroup_memory'
    expr: >
      max(
        (
          container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service"} -
          container_memory_cache{id="/system.slice/gitlab-runsvdir.service"} -
          container_memory_swap{id="/system.slice/gitlab-runsvdir.service"}
        )
        /
        container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service"}
      ) by (environment, tier, type, stage)

  # type: gitaly
  # Disk read IOPS saturation based on GCP estimate of 1200MB/s limit
  # This value can be found in the GCP console, here https://console.cloud.google.com/compute/disksDetail/zones/us-east1-d/disks/file-35-stor-gprd-data?project=gitlab-production
  # For now, we hard-code the device as `sdb`
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'disk_sustained_read_iops'
    expr: >
      max(
        rate(node_disk_reads_completed_total{type="gitaly", device="sdb"}[1m]) / (60000)
      ) by (environment, tier, type, stage)

  # type: gitaly
  # Disk write IOPS saturation based on GCP estimate of 400MB/s limit
  # This value can be found in the GCP console, here https://console.cloud.google.com/compute/disksDetail/zones/us-east1-d/disks/file-35-stor-gprd-data?project=gitlab-production
  # For now, we hard-code the device as `sdb`
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'disk_sustained_write_iops'
    expr: >
      max(
        rate(node_disk_writes_completed_total{type="gitaly", device="sdb"}[1m]) / (30000)
      ) by (environment, tier, type, stage)

  # type: gitaly
  # Disk read throughput saturation based on GCP estimate of 1200MB/s limit
  # This value can be found in the GCP console, here https://console.cloud.google.com/compute/disksDetail/zones/us-east1-d/disks/file-35-stor-gprd-data?project=gitlab-production
  # For now, we hard-code the device as `sdb`
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'disk_sustained_read_throughput'
    expr: >
      max(
        rate(node_disk_read_bytes_total{type="gitaly", device="sdb"}[1m]) / (1200 * 1024 * 1024)
      ) by (environment, tier, type, stage)

  # type: gitaly
  # Disk write throughput saturation based on GCP estimate of 400MB/s limit
  # This value can be found in the GCP console, here https://console.cloud.google.com/compute/disksDetail/zones/us-east1-d/disks/file-35-stor-gprd-data?project=gitlab-production
  # For now, we hard-code the device as `sdb`
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'disk_sustained_write_throughput'
    expr: >
      max(
        rate(node_disk_written_bytes_total{type="gitaly", device="sdb"}[1m]) / (400 * 1024 * 1024)
      ) by (environment, tier, type, stage)

  # Aggregate over all components within a service using max
  - record: gitlab_service_saturation:ratio
    expr: >
      max by (environment, tier, type, stage) (gitlab_component_saturation:ratio)

  # Open file descriptors
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'open_fds'
    expr: >
      max(
        max_over_time(process_open_fds[1m])
        /
        max_over_time(process_max_fds[1m])
      ) by (environment, type, tier, stage)
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'open_fds'
    expr: >
      max(
        max_over_time(ruby_file_descriptors[1m])
        /
        max_over_time(ruby_process_max_fds[1m])
      ) by (environment, type, tier, stage)

  # type: monitoring
  #
  # PromQL engine
  - record: gitlab_component_saturation:ratio
    labels:
      component: 'queries'
    expr: > 
      max by (environment, tier, type, stage) (
        avg_over_time(prometheus_engine_queries[1m])
        /
        avg_over_time(prometheus_engine_queries_concurrent_max[1m])
      )

# Unlike other service metrics, we record the stats for each component independently
- name: GitLab Saturation Ratios Stats
  interval: 5m
  rules:

  # ----------------------------------------------
  # Linear Interpolation
  # ----------------------------------------------

  # Average values for each component, over a week
  - record: gitlab_component_saturation:ratio:avg_over_time_1w
    expr: >
      avg_over_time(gitlab_component_saturation:ratio[1w])

  # Stddev for each component, over a week
  - record: gitlab_component_saturation:ratio:stddev_over_time_1w
    expr: >
      stddev_over_time(gitlab_component_saturation:ratio[1w])

  # Using linear week-on-week growth, what prediction to we have for 2w from now?
  - record: gitlab_component_saturation:ratio:predict_linear_2w
    expr: >
      predict_linear(gitlab_component_saturation:ratio:avg_over_time_1w[1w], 86400 * 14)

  # Using linear week-on-week growth, what prediction to we have for 30d from now?
  - record: gitlab_component_saturation:ratio:predict_linear_30d
    expr: >
      predict_linear(gitlab_component_saturation:ratio:avg_over_time_1w[1w], 86400 * 30)
