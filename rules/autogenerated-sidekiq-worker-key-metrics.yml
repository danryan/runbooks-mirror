# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./rules-jsonnet/sidekiq-worker-key-metrics.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: Sidekiq Per Worker Alerting
  interval: 1m
  rules:
  - alert: sidekiq_background_job_error_ratio_burn_rate_slo_out_of_bounds
    for: 2m
    annotations:
      title: The `{{ $labels.queue }}` queue, `{{ $labels.stage }}` stage, has an error rate outside of
        SLO
      description: |
        The `{{ $labels.queue }}` queue, `{{ $labels.stage }}` stage, has an error rate outside of SLO.

        Currently the metric value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-queue-detail/sidekiq-queue-detail
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/sidekiq-queue-detail/sidekiq-queue-detail?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-queue={{ $labels.queue }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '98088'
      grafana_variables: environment,stage,queue
      promql_template_1: >-
        gitlab_background_jobs:execution:error:ratio_1h{environment="$environment", type="$type", stage="$stage",
        component="$component"}
      runbook: docs/sidekiq/service-sidekiq.md
    labels:
      alert_type: symptom
      experimental: 'yes'
      metric: gitlab_background_jobs:execution:error:ratio_1h
      period: 2m
      rules_domain: general
      severity: s4
      slo_alert: 'yes'
    expr: |
      (
        (
          gitlab_background_jobs:execution:error:ratio_1h > (14.4 * 0.01)
        and
          gitlab_background_jobs:execution:error:ratio_5m > (14.4 * 0.01)
        )
        or
        (
          gitlab_background_jobs:execution:error:ratio_6h > (6 * 0.01)
        and
          gitlab_background_jobs:execution:error:ratio_30m > (6 * 0.01)
        )
      )
      and
      (
        gitlab_background_jobs:execution:ops:rate_6h > 0.1
      )
  - alert: sidekiq_background_job_execution_apdex_ratio_burn_rate_slo_out_of_bounds
    for: 2m
    annotations:
      title: The `{{ $labels.queue }}` queue, `{{ $labels.stage }}` stage, has a execution latency outside
        of SLO
      description: |
        The `{{ $labels.queue }}` queue, `{{ $labels.stage }}` stage, has a execution latency outside of SLO.

        Currently the metric value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-queue-detail/sidekiq-queue-detail
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/sidekiq-queue-detail/sidekiq-queue-detail?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-queue={{ $labels.queue }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '43432'
      grafana_variables: environment,stage,queue
      promql_template_1: >-
        gitlab_background_jobs:execution:apdex:ratio_1h{environment="$environment", type="$type", stage="$stage",
        component="$component"}
      runbook: docs/sidekiq/service-sidekiq.md
    labels:
      alert_type: symptom
      experimental: 'yes'
      metric: gitlab_background_jobs:execution:apdex:ratio_1h
      period: 2m
      rules_domain: general
      severity: s4
      slo_alert: 'yes'
    expr: |
      (
        (
          (1 - gitlab_background_jobs:execution:apdex:ratio_1h) > (14.4 * 0.01)
          and
          (1 - gitlab_background_jobs:execution:apdex:ratio_5m) > (14.4 * 0.01)
        )
        or
        (
          (1 - gitlab_background_jobs:execution:apdex:ratio_6h) > (6 * 0.01)
          and
          (1 - gitlab_background_jobs:execution:apdex:ratio_30m) > (6 * 0.01)
        )
      )
      and
      (
        gitlab_background_jobs:execution:ops:rate_6h > 0.1
      )
  - alert: sidekiq_background_job_queue_apdex_ratio_burn_rate_slo_out_of_bounds
    for: 2m
    annotations:
      title: The `{{ $labels.queue }}` queue, `{{ $labels.stage }}` stage, has a queue latency outside
        of SLO
      description: |
        The `{{ $labels.queue }}` queue, `{{ $labels.stage }}` stage, has a queue latency outside of SLO.

        Currently the metric value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-queue-detail/sidekiq-queue-detail
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/sidekiq-queue-detail/sidekiq-queue-detail?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-queue={{ $labels.queue }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '28392'
      grafana_variables: environment,stage,queue
      promql_template_1: >-
        gitlab_background_jobs:queue:apdex:ratio_1h{environment="$environment", type="$type", stage="$stage",
        component="$component"}
      runbook: docs/sidekiq/service-sidekiq.md
    labels:
      alert_type: symptom
      experimental: 'yes'
      metric: gitlab_background_jobs:queue:apdex:ratio_1h
      period: 2m
      rules_domain: general
      severity: s4
      slo_alert: 'yes'
    expr: |
      (
        (
          (1 - gitlab_background_jobs:queue:apdex:ratio_1h) > (14.4 * 0.01)
          and
          (1 - gitlab_background_jobs:queue:apdex:ratio_5m) > (14.4 * 0.01)
        )
        or
        (
          (1 - gitlab_background_jobs:queue:apdex:ratio_6h) > (6 * 0.01)
          and
          (1 - gitlab_background_jobs:queue:apdex:ratio_30m) > (6 * 0.01)
        )
      )
      and
      (
        gitlab_background_jobs:execution:ops:rate_6h > 0.1
      )
  - alert: sidekiq_throttled_jobs_enqueued_without_dequeuing
    for: 2m
    annotations:
      title: Sidekiq jobs are being enqueued without being dequeued
      description: |
        The `{{ $labels.queue }}` queue appears to have jobs being enqueued without
        those jobs being executed.

        This could be the result of a Sidekiq server configuration issue, where
        no Sidekiq servers are configured to dequeue the specific queue.
      grafana_dashboard_id: sidekiq-queue-detail/sidekiq-queue-detail
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/sidekiq-queue-detail/sidekiq-queue-detail?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-queue={{ $labels.queue }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '80616'
      grafana_variables: environment,stage,queue
      promql_template_1: >-
        sidekiq_enqueued_jobs_total{environment="$environment", type="$type", stage="$stage", component="$component"}
      runbook: docs/sidekiq/service-sidekiq.md
    labels:
      alert_type: cause
      metric: sidekiq_enqueued_jobs_total
      period: 2m
      rules_domain: general
      severity: s4
      stage: main
      tier: sv
      type: sidekiq
    expr: |
      (
        sum by (environment, queue, feature_category) (rate(sidekiq_enqueued_jobs_total{urgency="throttled"}[10m] offset 10m)) > 0
      )
      unless
      (
        sum by (environment, queue, feature_category) (rate(sidekiq_jobs_completion_seconds_count{urgency="throttled"}[20m])) > 0
        or
        sum by (environment, queue, feature_category) (rate(sidekiq_jobs_failed_total{urgency="throttled"}[20m])) > 0
        or
        sum by (environment, queue, feature_category) (rate(sidekiq_jobs_retried_total{urgency="throttled"}[20m])) > 0
        or
        sum by (environment, queue, feature_category) (avg_over_time(sidekiq_running_jobs{urgency="throttled"}[20m])) > 0
      )
  - alert: ignored_sidekiq_queues_receiving_work
    for: 2m
    annotations:
      title: Sidekiq jobs are being enqueued to an ignored queue that will never be dequeued
      description: |
        The `{{ $labels.queue }}` queue is receiving work, but this queue has been
        explicitly ignored in the `gprd` environment, to help reduce load on
        our redis-sidekiq cluster.

        This is a temporary measure.

        It appears that the `{{ $labels.queue }}` queue is receiving work.
        Since no sidekiq workers are listening to the queue, this work will be
        ignored.

        Recommended course of action: Communicate with the team responsible for
        the {{ $labels.feature_category }} feature category, and find out whether
        the work to the queue is intentional. If it is, update the ignore list on
        https://ops.gitlab.net/gitlab-cookbooks/chef-repo/-/blob/master/tools/sidekiq-config/sidekiq-queue-configurations.libsonnet
        and the corresponding list used for this alert, in
        https://gitlab.com/gitlab-com/runbooks/blob/master/rules-jsonnet/temp-ignored-gprd-queue-list.libsonnet
        removing the ignored queue from both.

        Also, review https://ops.gitlab.net/gitlab-cookbooks/chef-repo/-/merge_requests/2948
      grafana_dashboard_id: sidekiq-queue-detail/sidekiq-queue-detail
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/sidekiq-queue-detail/sidekiq-queue-detail?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-queue={{ $labels.queue }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '80616'
      grafana_variables: environment,stage,queue
      promql_template_1: sidekiq_enqueued_jobs_total{environment="$environment", queue="$queue"}
      runbook: docs/sidekiq/service-sidekiq.md
    labels:
      alert_type: cause
      metric: sidekiq_enqueued_jobs_total
      pager: pagerduty
      period: 2m
      rules_domain: general
      severity: s1
      stage: main
      tier: sv
      type: sidekiq
    expr: >
      sum by (environment, queue, feature_category) (rate(sidekiq_enqueued_jobs_total{environment="gprd",
      queue=~"chaos:chaos_cpu_spin|chaos:chaos_db_spin|chaos:chaos_kill|chaos:chaos_leak_mem|chaos:chaos_sleep|cronjob:geo_container_repository_sync_dispatch|cronjob:geo_file_download_dispatch|cronjob:geo_metrics_update|cronjob:geo_migrated_local_files_clean_up|cronjob:geo_prune_event_log|cronjob:geo_repository_sync|cronjob:geo_repository_verification_primary_batch|cronjob:geo_repository_verification_secondary_scheduler|cronjob:geo_repository_verification_secondary_shard|cronjob:geo_scheduler_per_shard_scheduler|cronjob:geo_scheduler_primary_per_shard_scheduler|cronjob:geo_scheduler_secondary_per_shard_scheduler|cronjob:geo_secondary_registry_consistency|default|geo:geo_batch_project_registry|geo:geo_batch_project_registry_scheduler|geo:geo_container_repository_sync|geo:geo_design_repository_shard_sync|geo:geo_design_repository_sync|geo:geo_event|geo:geo_file_download|geo:geo_file_registry_removal|geo:geo_file_removal|geo:geo_hashed_storage_attachments_migration|geo:geo_hashed_storage_migration|geo:geo_project_sync|geo:geo_rename_repository|geo:geo_repositories_clean_up|geo:geo_repository_cleanup|geo:geo_repository_destroy|geo:geo_repository_shard_sync|geo:geo_repository_verification_primary_shard|geo:geo_repository_verification_primary_single|geo:geo_repository_verification_secondary_single|geo:geo_scheduler_primary_scheduler|geo:geo_scheduler_scheduler|geo:geo_scheduler_secondary_scheduler|geo:geo_secondary_repository_backfill|hashed_storage:hashed_storage_migrator|hashed_storage:hashed_storage_project_migrate|hashed_storage:hashed_storage_project_rollback|hashed_storage:hashed_storage_rollbacker|ldap_group_sync"}[5m]))
      > 0
