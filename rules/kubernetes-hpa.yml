groups:
  - name: kubernetes-hpa.rules
    rules:

      - alert: HPAScalingAbility
        annotations:
          title: HPA Unable to scale
          description: '{{ $labels.hpa}} is suffering from a problem preventing scaling from occurring'
          runbook: docs/uncategorized/kubernetes.md
        expr: kube_hpa_status_condition{condition="false", status="AbleToScale"} == 1
        for: 30m
        labels:
          severity: s3
          alert_type: cause

      - alert: HPAMetricsAvailability
        annotations:
          title: HPA Unable to scale
          description: '{{ $labels.hpa}} is not able to collect metrics'
          runbook: docs/uncategorized/kubernetes.md
        expr: kube_hpa_status_condition{condition="false", status="ScalingActive"} == 1
        for: 30m
        labels:
          severity: s3
          alert_type: cause

      - alert: HPAScaleCapability
        annotations:
          title: HPA unable to scale up
          description: '{{$labels.hpa}} in {{$labels.env}} has hit the maximum number of desired Pods'
          runbook: docs/uncategorized/kubernetes.md#hpascalecapability
        # We don't care that the sidekiq-export Deployment reaches it's max
        # See: https://gitlab.com/gitlab-com/gl-infra/delivery/-/issues/733
        # Sidekiq elasticsearch is set to run at a max of 2 pods for throttling so
        # it is also excluded here. This will hopefully be improved with
        # https://gitlab.com/gitlab-com/gl-infra/delivery/-/issues/846
        expr: |
          sum(kube_hpa_status_desired_replicas{hpa!~"gitlab-sidekiq-(memory-bound|elasticsearch)-v1"})
            by (hpa, env)
            >=
          sum(kube_hpa_spec_max_replicas) by (hpa, env)
        for: 30m
        labels:
          pager: pagerduty
          severity: s2
          alert_type: cause
