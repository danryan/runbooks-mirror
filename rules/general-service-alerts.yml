##
## DEPRECRATED: these rules are being migrated to Thanos, as part of
## https://gitlab.com/gitlab-com/gl-infra/infrastructure/-/issues/9689
##Â 
## At present, we are unable to trust the alerts in Thanos as we don't yet
## have monitoring or alerting around this component.
## Until we do, we will run replica alerts in Thanos and Prometheus
## after which we will remove this file.
##
groups:
  - name: slo_alerts.rules
    rules:
      # ------------------------------------------------------------------------------
      # Latency alerts
      # ------------------------------------------------------------------------------

      # Warn: Latency SLO not being met, default alert_trigger_duration (short, 5m)
      # Note: we ignore `cny` stage for this alert, since if both cny and main stage are firing, we
      # only care about the main stage alert Alternatively, we have the bad canary alerts
      # specifically for canary stage
      # DEPRECATED in favour of multiwindow, multiburn-rate alerts
      - alert: service_apdex_slo_out_of_bounds_lower_5m
        expr: |
          (
            avg(gitlab_service_apdex:ratio{stage!="cny"}) by (environment, tier, type, stage)
            < ignoring(environment, stage) group_left
            avg(slo:min:gitlab_service_apdex:ratio{alert_trigger_duration!="long"}) by (tier, type)
          )
          unless on(tier, type)
          (
            slo:min:events:gitlab_service_apdex:ratio
          )
        for: 5m
        labels:
          rules_domain: general
          metric: gitlab_service_apdex:ratio
          severity: s2
          slo_alert: 'yes'
          period: 5m
          bound: lower
          pager: pagerduty
          alert_type: symptom
          deprecated: 'yes'
        annotations:
          description: >
            The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) is not meeting its latency SLOs

            The service is taking longer to respond to requests than usual. This could be caused by
            user abuse, application changes in upstream services that lead to higher request rates or slower
            requested, or slowdown in downstream services. Check operation rates in upstream and downstream
            services, error rates and check ELK for abuse.
          runbook: "docs/{{ $labels.type }}/service-{{ $labels.type }}.md"
          title: "The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) has a apdex score (latency) below SLO"
          grafana_dashboard_id: "general-service/service-platform-metrics"
          grafana_panel_id: "7"
          grafana_variables: "environment,type,stage"
          grafana_min_zoom_hours: "6"
          link1_title: "Definition"
          link1_url: "https://gitlab.com/gitlab-com/runbooks/blob/master/docs/uncategorized/definition-service-apdex.md"
          promql_template_1: 'gitlab_service_apdex:ratio{environment="$environment", type="$type", stage="$stage"}'
          promql_template_2: 'gitlab_component_apdex:ratio{environment="$environment", type="$type", stage="$stage"}'

      # Warn: Latency SLO not being met, long alert_trigger_duration (15m)
      # Note: we ignore `cny` stage for this alert, since if both cny and main stage are firing, we
      # only care about the main stage alert Alternatively, we have the bad canary alerts
      # specifically for canary stage
      # DEPRECATED in favour of multiwindow, multiburn-rate alerts
      - alert: service_apdex_slo_out_of_bounds_lower_15m
        expr: |
          (
            avg(gitlab_service_apdex:ratio{stage!="cny"}) by (environment, tier, type, stage)
            < ignoring(environment, stage) group_left
            avg(slo:min:gitlab_service_apdex:ratio{alert_trigger_duration="long"}) by (tier, type)
          )
          unless on(tier, type)
          (
            slo:min:events:gitlab_service_apdex:ratio
          )
        for: 15m
        labels:
          rules_domain: general
          metric: gitlab_service_apdex:ratio
          severity: s2
          slo_alert: 'yes'
          period: 15m
          bound: lower
          pager: pagerduty
          alert_type: symptom
          deprecated: 'yes'
        annotations:
          description: >
            The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) is not meeting its latency SLOs

            The service is taking longer to respond to requests than usual. This could be caused by
            user abuse, application changes in upstream services that lead to higher request rates or slower
            requested, or slowdown in downstream services. Check operation rates in upstream and downstream
            services, error rates and check ELK for abuse.
          runbook: "docs/{{ $labels.type }}/service-{{ $labels.type }}.md"
          title: "The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) has a apdex score (latency) below SLO"
          grafana_dashboard_id: "general-service/service-platform-metrics"
          grafana_panel_id: "7"
          grafana_variables: "environment,type,stage"
          grafana_min_zoom_hours: "6"
          link1_title: "Definition"
          link1_url: "https://gitlab.com/gitlab-com/runbooks/blob/master/docs/uncategorized/definition-service-apdex.md"
          promql_template_1: 'gitlab_service_apdex:ratio{environment="$environment", type="$type", stage="$stage"}'
          promql_template_2: 'gitlab_component_apdex:ratio{environment="$environment", type="$type", stage="$stage"}'

      # ------------------------------------------------------------------------------
      # Error Rate alerts
      # ------------------------------------------------------------------------------

      # Warn: Error ratio SLO not being met, default alert_trigger_duration (short, 5m)
      # Note: we ignore `cny` stage for this alert, since if both cny and main stage are firing, we
      # only care about the main stage alert Alternatively, we have the bad canary alerts
      # specifically for canary stage
      # DEPRECATED in favour of multiwindow, multiburn-rate alerts
      - alert: service_error_ratio_slo_out_of_bounds_upper_5m
        expr: |
          (
            avg(gitlab_service_errors:ratio{stage!="cny"}) by (environment, tier, type, stage)
            > ignoring(environment, stage) group_left
            avg(slo:max:gitlab_service_errors:ratio{alert_trigger_duration!="long"}) by (tier, type)
          )
          unless on(tier, type)
          (
            slo:max:events:gitlab_service_errors:ratio
          )
        for: 5m
        labels:
          rules_domain: general
          metric: gitlab_service_errors:ratio
          severity: s2
          slo_alert: 'yes'
          period: 5m
          bound: upper
          alert_type: symptom
          pager: pagerduty
          deprecated: 'yes'
        annotations:
          description: >
            The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) has an error-ratio higher than SLOs

            A high proportion of requests to the `{{ $labels.type }}` service are resulting in errors.
            This ratio is higher than the defined SLO for the service.
          runbook: "docs/{{ $labels.type }}/service-{{ $labels.type }}.md"
          title: "The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) has an error-ratio exceeding SLO"
          grafana_dashboard_id: "general-service/service-platform-metrics"
          grafana_panel_id: "8"
          grafana_variables: "environment,type,stage"
          grafana_min_zoom_hours: "6"
          link1_title: "Definition"
          link1_url: "https://gitlab.com/gitlab-com/runbooks/blob/master/docs/uncategorized/definition-service-error-rate.md"
          promql_template_1: 'gitlab_service_errors:ratio{environment="$environment", type="$type", stage="$stage"}'
          promql_template_2: 'gitlab_component_errors:ratio{environment="$environment", type="$type", stage="$stage"}'

      # Warn: Error ratio SLO not being met, long alert_trigger_duration (15m)
      # Note: we ignore `cny` stage for this alert, since if both cny and main stage are firing, we
      # only care about the main stage alert Alternatively, we have the bad canary alerts
      # specifically for canary stage
      # DEPRECATED in favour of multiwindow, multiburn-rate alerts
      - alert: service_error_ratio_slo_out_of_bounds_upper_15m
        expr: |
          (
            avg(gitlab_service_errors:ratio{stage!="cny"}) by (environment, tier, type, stage)
            > ignoring(environment, stage) group_left
            avg(slo:max:gitlab_service_errors:ratio{alert_trigger_duration="long"}) by (tier, type)
          )
          unless on(tier, type)
          (
            slo:max:events:gitlab_service_errors:ratio
          )
        for: 15m
        labels:
          rules_domain: general
          metric: gitlab_service_errors:ratio
          severity: s2
          slo_alert: 'yes'
          period: 15m
          bound: upper
          alert_type: symptom
          pager: pagerduty
          deprecated: 'yes'
        annotations:
          description: >
            The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) has an error-ratio higher than SLOs

            A high proportion of requests to the `{{ $labels.type }}` service are resulting in errors.
            This ratio is higher than the defined SLO for the service.
          runbook: "docs/{{ $labels.type }}/service-{{ $labels.type }}.md"
          title: "The `{{ $labels.type }}` service (`{{ $labels.stage }}` stage) has an error-ratio exceeding SLO"
          grafana_dashboard_id: "general-service/service-platform-metrics"
          grafana_panel_id: "8"
          grafana_variables: "environment,type,stage"
          grafana_min_zoom_hours: "6"
          link1_title: "Definition"
          link1_url: "https://gitlab.com/gitlab-com/runbooks/blob/master/docs/uncategorized/definition-service-error-rate.md"
          promql_template_1: 'gitlab_service_errors:ratio{environment="$environment", type="$type", stage="$stage"}'
          promql_template_2: 'gitlab_component_errors:ratio{environment="$environment", type="$type", stage="$stage"}'

      # ------------------------------------------------------------------------------
      # Multiwindow/Multiburn Error Rate Monitoring for COMPONENTS.
      # ------------------------------------------------------------------------------

      # The error rate SLO target for a component is not being met.
      - alert: component_error_ratio_burn_rate_slo_out_of_bounds_upper
        expr: |
          (
            gitlab_component_errors:ratio_1h > on(tier, type) group_left() (14.4*(avg(slo:max:events:gitlab_service_errors:ratio) by (tier, type)))
          and
            gitlab_component_errors:ratio_5m > on(tier, type) group_left()  (14.4*(avg(slo:max:events:gitlab_service_errors:ratio) by (tier, type)))
          )
          or
          (
            gitlab_component_errors:ratio_6h > on(tier, type) group_left() (6*(avg(slo:max:events:gitlab_service_errors:ratio) by (tier, type)))
          and
            gitlab_component_errors:ratio_30m > on(tier, type) group_left() (6*(avg(slo:max:events:gitlab_service_errors:ratio) by (tier, type)))
          )
        for: 2m
        labels:
          rules_domain: general
          metric: gitlab_component_errors:ratio_1h
          severity: s2
          slo_alert: 'yes'
          period: 2m
          bound: upper
          alert_type: symptom
          pager: pagerduty
        annotations:
          title: "The `{{ $labels.type }}` service, `{{ $labels.component }}` component, `{{ $labels.stage }}` stage, has an error burn-rate exceeding SLO"
          description: >
            The `{{ $labels.type }}` service, `{{ $labels.component }}` component, `{{ $labels.stage }}` stage has an error burn-rate outside of SLO

            The error-burn rate for this service is outside of SLO over multiple windows.
            Currently the error-rate is {{ $value | humanizePercentage }}%.
          runbook: "docs/{{ $labels.type }}/service-{{ $labels.type }}.md"
          grafana_dashboard_id: "alerts-component_multiburn_error/alerts-component-multi-window-multi-burn-rate-out-of-slo"
          grafana_panel_id: "4"
          grafana_variables: "environment,type,stage,component"
          grafana_min_zoom_hours: "6"
          link1_title: "Definition"
          link1_url: "https://gitlab.com/gitlab-com/runbooks/blob/master/docs/uncategorized/definition-service-error-rate.md"
          promql_template_1: 'gitlab_component_errors:ratio_5m{environment="$environment", type="$type", stage="$stage", component="$component"}'

      ################################################
      # Bad canary: we are experiencing errors or latency issues in
      # canary, but not in production. This probably indicates that
      # we have a dud canary
      #
      # When traffic volume to the canary is below 1% of the
      # traffic to the main production stage, the bad-canary
      # alerts will not fire. This avoids low-traffic
      # random noise alerts.
      #
      ################################################
      # DEPRECATED in favour of multiwindow, multiburn-rate alerts

      - alert: service_cny_apdex_slo_out_of_bounds_lower_5m
        expr: |
          (
            (
              (
                avg(gitlab_service_apdex:ratio{stage="cny"}) by (environment, tier, type)
                < ignoring(environment, stage) group_left
                  avg(slo:min:gitlab_service_apdex:ratio) by (tier, type)
              )
              unless ignoring(stage)
              (
                avg(gitlab_service_apdex:ratio{stage="main"}) by (environment, tier, type)
                < ignoring(environment, stage) group_left
                  avg(slo:min:gitlab_service_apdex:ratio) by (tier, type)
              )
            )
            and on(environment, tier, type)
            (
              (
                gitlab_service_ops:rate{stage="cny"}
                / ignoring(stage)
                gitlab_service_ops:rate{stage="main"}
              ) >= 0.01
            )
          )
          unless on(tier, type)
          (
            slo:min:events:gitlab_service_apdex:ratio
          )
        for: 5m
        labels:
          rules_domain: general
          canary_warning: 'yes'
          metric: gitlab_service_apdex:ratio
          severity: s2
          slo_alert: 'yes'
          period: 5m
          bound: lower
          pager: pagerduty
          alert_type: symptom
          deprecated: 'yes'
        annotations:
          description: >
            The `cny` stage of  the `{{ $labels.type }}` service has a apdex score
            (latency) below SLO, but the main stage does not.

            While there are other reasons, such as high traffic to the canary stage, experiencing a
            high error rate in `cny`, without any corresponding errors in `main` stage could indicate
            a malfunctioning canary deploy.

            Consider investigating further. If there is no evidence of another cause, please
            consider stopping the deployment process while the problem is investigated.

            This could indicate that the canary deployment is not functioning correctly. Please consider
            stopping the deployment process while the problem is investigated.
          runbook: "docs/{{ $labels.type }}/service-{{ $labels.type }}.md"
          title: "Bad canary? The `cny` stage of  the `{{ $labels.type }}` service has a apdex score (latency) below SLO, but the main stage does not."
          grafana_dashboard_id: "general-service-stages/general-service-platform-metrics-stages"
          grafana_panel_id: "2"
          grafana_variables: "environment,type"
          grafana_min_zoom_hours: "6"
          link1_title: "Definition"
          link1_url: "https://gitlab.com/gitlab-com/runbooks/blob/master/docs/uncategorized/definition-service-apdex.md"
          promql_template_1: 'gitlab_service_apdex:ratio{environment="$environment", type="$type", stage="$stage"}'
          promql_template_2: 'gitlab_component_apdex:ratio{environment="$environment", type="$type", stage="$stage"}'

      - alert: service_cny_error_ratio_slo_out_of_bounds_upper_5m
        expr: |
          (
            (
              (
                avg(gitlab_service_errors:ratio{stage="cny"}) by (environment, tier, type, stage)
                > ignoring(environment, stage) group_left
                avg(slo:max:gitlab_service_errors:ratio) by (tier, type)
              )
              unless ignoring(stage)
              (
                avg(gitlab_service_errors:ratio{stage="main"}) by (environment, tier, type, stage)
                > ignoring(environment, stage) group_left
                avg(slo:max:gitlab_service_errors:ratio) by (tier, type)
              )
            )
            and on(environment, tier, type)
            (
              (
                gitlab_service_ops:rate{stage="cny"}
                / ignoring(stage)
                gitlab_service_ops:rate{stage="main"}
              ) >= 0.01
            )
          )
          unless on(tier, type)
          (
            slo:max:events:gitlab_service_errors:ratio
          )
        for: 5m
        labels:
          rules_domain: general
          canary_warning: 'yes'
          metric: gitlab_service_errors:ratio
          severity: s2
          slo_alert: 'yes'
          period: 5m
          bound: upper
          pager: pagerduty
          alert_type: symptom
          deprecated: 'yes'
        annotations:
          description: >
            The `cny` stage of  the `{{ $labels.type }}` service has an error-ratio
            exceeding SLO, but the main stage does not.

            While there are other reasons, such as high traffic to the canary stage, experiencing a
            high error rate in `cny`, without any corresponding errors in `main` stage could indicate
            a malfunctioning canary deploy.

            Consider investigating further. If there is no evidence of another cause, please
            consider stopping the deployment process while the problem is investigated.
          runbook: "docs/{{ $labels.type }}/service-{{ $labels.type }}.md"
          title: "Bad canary? The `cny` stage of  the `{{ $labels.type }}` service has an error-ratio exceeding SLO, but the main stage does not."
          grafana_dashboard_id: "general-service-stages/general-service-platform-metrics-stages"
          grafana_panel_id: "3"
          grafana_variables: "environment,type"
          grafana_min_zoom_hours: "6"
          link1_title: "Definition"
          link1_url: "https://gitlab.com/gitlab-com/runbooks/blob/master/docs/uncategorized/definition-service-error-rate.md"
          promql_template_1: 'gitlab_service_errors:ratio{environment="$environment", type="$type", stage="$stage"}'
          promql_template_2: 'gitlab_component_errors:ratio{environment="$environment", type="$type", stage="$stage"}'

