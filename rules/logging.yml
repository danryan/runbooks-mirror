groups:
- name: logging.rules
  rules:
    - alert: TooManyPubsubbeatErrors
      expr: rate(pubsubbeat_errors_total[5m]) > 0.1
      for: 5m
      labels:
        severity: s4
        alert_type: cause
      annotations:
        title: Pubsubbeat is logging errors
        description: >
          Warnings could be a result of pubsubbeat being unable to connect to
          Elasticsearch. Consider checking /var/log/pubsubbeat/current on the affected
          host and see what's the cause of the errors.
    - alert: DroppedLogs
      expr: >
        (rate(pubsubbeat_libbeat_output_events{type="dropped"}[5m]))
        / ignoring (type) group_left
        sum without (type) (rate(pubsubbeat_libbeat_output_events[5m]))
        > 0.005
      for: 1m
      labels:
        severity: s4
        alert_type: cause
      annotations:
        title: Cluster is refusing to process logs sent to it by pubsubbeat
        description: >
          pubsubbeat internal metric is reporting logs being dropped by the cluster.
          Consider checking /var/log/pubsubbeat/current on the affected
          host and see what's the cause of the errors. One potential source of the problem are conflicting mappings in the index.

    - alert: PubSubSendRateFalling
      expr: |
        deriv(
          sum without (fqdn,instance,plugin_id,stage) (
            rate(fluentd_output_status_emit_count{type="cloud_pubsub"}[15m])
          )[15m:]
        ) < -2
      for: 5m
      labels:
        severity: s3
        alert_type: cause
      annotations:
        description: >
          Logs send rate is lower than usual.
        runbook: docs/logging/troubleshooting/README.md
        title: Logs send rate is unusually low

    - alert: LoggingVisibilityDiminished
      expr: |
        sum by (subscription_id) (
          avg_over_time(stackdriver_pubsub_subscription_pubsub_googleapis_com_subscription_oldest_unacked_message_age[30m])
        ) > 60
      for: 5m
      labels:
        severity: s4
        alert_type: cause
      annotations:
        description: >
          PubSub messages are queuing up.  Messages in {{ $labels.subscription_id }} have been
          un-acked for {{ $value | humanizeDuration }} in the queue for the last 5 minutes.
          This will lead to Elastic lagging behind with the log data.
        runbook: docs/logging/troubleshooting/README.md
        title: PubSub queuing high

    - alert: LoggingKibanaUnavailable
      expr: |
        sum by (response_code_class) (
          stackdriver_https_lb_rule_loadbalancing_googleapis_com_https_request_count{env="ops",backend_name="ops-prod-proxy-us-east1-c",response_code_class="500"}
        ) > 0
      for: 5m
      labels:
        severity: s4
        alert_type: symptom
      annotations:
        description: >
          log.gprd.gitlab.net is responding with 5xx errors. These errors are observed at the GCP load balancer layer that is in front of the proxy machine. This means that the problem could be with GCP load balancer, proxy machine, Kibana, Elastic or any other component involved.
        runbook: docs/logging/troubleshooting/README.md
        title: log.gprd.gitlab.net is responding with 5xx errors
