groups:
- name: elastic.rules
  rules:
  - alert: Elasticsearch ILM errors in nonproduction
    expr: probe_success{instance="https://e8fabf53b73247e98df7c355d6a782fc.us-central1.gcp.cloud.es.io:9243/*/_ilm/explain",type="blackbox"} == 0
    for: 5m
    labels:
      severity: s4
      alert_type: cause
      environment: gstg
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: ILM errors have been detected in the nonproduction logging cluster!
  - alert: Elasticsearch ILM stopped in nonproduction
    expr: probe_success{instance="https://e8fabf53b73247e98df7c355d6a782fc.us-central1.gcp.cloud.es.io:9243/_ilm/status",type="blackbox"} == 0
    for: 15m
    labels:
      severity: s4
      alert_type: cause
      environment: gstg
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: ILM is no longer running in the nonproduction logging cluster!
  - alert: Elasticsearch ILM errors in production
    expr: probe_success{instance="https://92c87c26b16049b0a30af16b94105528.us-central1.gcp.cloud.es.io:9243/*/_ilm/explain",type="blackbox"} == 0
    for: 15m
    labels:
      severity: s3
      alert_type: cause
      environment: gprd
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: ILM errors have been detected in the logging cluster!
  - alert: Elasticsearch ILM stopped in production
    expr: probe_success{instance="https://92c87c26b16049b0a30af16b94105528.us-central1.gcp.cloud.es.io:9243/_ilm/status",type="blackbox"} == 0
    for: 15m
    labels:
      severity: s3
      alert_type: cause
      environment: gprd
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: ILM is no longer running in the logging cluster!
  - alert: Elasticsearch production logging cluster unhealthy
    expr: probe_success{instance="https://92c87c26b16049b0a30af16b94105528.us-central1.gcp.cloud.es.io:9243/_cluster/health",type="blackbox"} == 0
    for: 5m
    labels:
      severity: s3
      alert_type: cause
      environment: gprd
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: Production logging cluster is unhealthy
  - alert: Elasticsearch ILM errors in monitoring cluster
    expr: probe_success{instance="https://0ea4e34a81444a95a1adeb1f90ed9dfa.us-central1.gcp.cloud.es.io:9243/*/_ilm/explain",type="blackbox"} == 0
    for: 5m
    labels:
      severity: s3
      alert_type: cause
      environment: gprd
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: ILM errors have been detected in the monitoring cluster!
  - alert: Elasticsearch ILM stopped in monitoring cluster
    expr: probe_success{instance="https://0ea4e34a81444a95a1adeb1f90ed9dfa.us-central1.gcp.cloud.es.io:9243/_ilm/status",type="blackbox"} == 0
    for: 15m
    labels:
      severity: s3
      alert_type: cause
      environment: gprd
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: ILM is no longer running in the monitoring cluster!
  - alert: Elasticsearch monitoring cluster unhealthy
    expr: probe_success{instance="https://0ea4e34a81444a95a1adeb1f90ed9dfa.us-central1.gcp.cloud.es.io:9243/_cluster/health",type="blackbox"} == 0
    for: 5m
    labels:
      severity: s3
      alert_type: cause
      environment: gprd
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: Monitoring cluster is unhealthy
  - alert: Elasticsearch thread pool rejections growing
    expr: deriv(elasticsearch_thread_pool_rejected_count{exported_type!="write"}[5m]) > 0.001
    for: 5m
    labels:
      severity: s3
      alert_type: cause
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: Elasticsearch thread pool rejections growing
  - alert: Elasticsearch write thread pool rejections growing
    expr: deriv(elasticsearch_thread_pool_rejected_count{exported_type="write"}[5m]) > 0.001
    for: 3m
    labels:
      severity: s3
      alert_type: cause
    annotations:
      runbook: docs/elastic/troubleshooting/README.md
      title: Elasticsearch thread pool rejections growing
  - alert: Elasticsearch is saturated and unable to process tasks real-time
    expr: elasticsearch_cluster_health_number_of_pending_tasks > 0
    for: 15m
    labels:
      severity: s3
      alert_type: symptom
    annotations:
      description: Elasticsearch is saturated and unable to process tasks real-time
      runbook: docs/elastic/troubleshooting/README.md
      title: Elasticsearch has a lot of pending tasks
