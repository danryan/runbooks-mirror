# WARNING. DO NOT EDIT THIS FILE BY HAND. RUN ./scripts/generate-all-reference-architecture-configs.sh TO GENERATE IT. YOUR CHANGES WILL BE OVERRIDDEN
groups:
- interval: 1m
  name: 'Component-Level SLIs: consul - 5m burn-rate'
  rules: []
- interval: 2m
  name: 'Component-Level SLIs: consul - 30m burn-rate'
  rules: []
- interval: 1m
  name: 'Component-Level SLIs: consul - 1h burn-rate'
  rules: []
- interval: 2m
  name: 'Component-Level SLIs: consul - 6h burn-rate'
  rules: []
- interval: 1m
  name: 'Component mapping: consul'
  rules: []
- interval: 1m
  name: 'Component-Level SLIs: gitaly - 5m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="0.5"}[5m])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="1"}[5m])
        )
      )
      /
      2
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="+Inf"}[5m])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service!="gitaly.OperationService",job="gitaly"}[5m])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          label_replace(rate(gitaly_service_client_requests_total{grpc_code!~"AlreadyExists|Canceled|DeadlineExceeded|FailedPrecondition|InvalidArgument|NotFound|OK|PermissionDenied|ResourceExhausted|Unauthenticated",grpc_service!="gitaly.OperationService",job="gitaly"}[5m]), "_c", "0", "", "")
          or
          label_replace(rate(gitaly_service_client_requests_total{deadline_type!="limited",grpc_code="DeadlineExceeded",grpc_service!="gitaly.OperationService",job="gitaly"}[5m]), "_c", "1", "", "")
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="goserver",tier="stor",type="gitaly"}
        )
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_errors:rate_5m
- interval: 2m
  name: 'Component-Level SLIs: gitaly - 30m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="0.5"}[30m])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="1"}[30m])
        )
      )
      /
      2
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="+Inf"}[30m])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service!="gitaly.OperationService",job="gitaly"}[30m])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          label_replace(rate(gitaly_service_client_requests_total{grpc_code!~"AlreadyExists|Canceled|DeadlineExceeded|FailedPrecondition|InvalidArgument|NotFound|OK|PermissionDenied|ResourceExhausted|Unauthenticated",grpc_service!="gitaly.OperationService",job="gitaly"}[30m]), "_c", "0", "", "")
          or
          label_replace(rate(gitaly_service_client_requests_total{deadline_type!="limited",grpc_code="DeadlineExceeded",grpc_service!="gitaly.OperationService",job="gitaly"}[30m]), "_c", "1", "", "")
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="goserver",tier="stor",type="gitaly"}
        )
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_errors:rate_30m
- interval: 1m
  name: 'Component-Level SLIs: gitaly - 1h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="0.5"}[1h])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="1"}[1h])
        )
      )
      /
      2
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="+Inf"}[1h])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service!="gitaly.OperationService",job="gitaly"}[1h])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          label_replace(rate(gitaly_service_client_requests_total{grpc_code!~"AlreadyExists|Canceled|DeadlineExceeded|FailedPrecondition|InvalidArgument|NotFound|OK|PermissionDenied|ResourceExhausted|Unauthenticated",grpc_service!="gitaly.OperationService",job="gitaly"}[1h]), "_c", "0", "", "")
          or
          label_replace(rate(gitaly_service_client_requests_total{deadline_type!="limited",grpc_code="DeadlineExceeded",grpc_service!="gitaly.OperationService",job="gitaly"}[1h]), "_c", "1", "", "")
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="goserver",tier="stor",type="gitaly"}
        )
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_errors:rate_1h
- interval: 2m
  name: 'Component-Level SLIs: gitaly - 6h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="0.5"}[6h])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="1"}[6h])
        )
      )
      /
      2
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly",le="+Inf"}[6h])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service!="gitaly.OperationService",job="gitaly"}[6h])
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          label_replace(rate(gitaly_service_client_requests_total{grpc_code!~"AlreadyExists|Canceled|DeadlineExceeded|FailedPrecondition|InvalidArgument|NotFound|OK|PermissionDenied|ResourceExhausted|Unauthenticated",grpc_service!="gitaly.OperationService",job="gitaly"}[6h]), "_c", "0", "", "")
          or
          label_replace(rate(gitaly_service_client_requests_total{deadline_type!="limited",grpc_code="DeadlineExceeded",grpc_service!="gitaly.OperationService",job="gitaly"}[6h]), "_c", "1", "", "")
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="goserver",tier="stor",type="gitaly"}
        )
      )
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: gitlab_component_errors:rate_6h
- interval: 1m
  name: 'Component mapping: gitaly'
  rules:
  - expr: "1"
    labels:
      component: goserver
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: stor
      type: gitaly
    record: gitlab_component_service:mapping
- interval: 1m
  name: 'Component-Level SLIs: gitlab-shell - 5m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="30"}[5m])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="60"}[5m])
        )
      )
      /
      2
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="+Inf"}[5m])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service="gitaly.SSHService",job="gitaly"}[5m])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!="OK",grpc_service="gitaly.SSHService",job="gitaly"}[5m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="grpc_requests",tier="sv",type="gitlab-shell"}
        )
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_errors:rate_5m
- interval: 2m
  name: 'Component-Level SLIs: gitlab-shell - 30m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="30"}[30m])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="60"}[30m])
        )
      )
      /
      2
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="+Inf"}[30m])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service="gitaly.SSHService",job="gitaly"}[30m])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!="OK",grpc_service="gitaly.SSHService",job="gitaly"}[30m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="grpc_requests",tier="sv",type="gitlab-shell"}
        )
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_errors:rate_30m
- interval: 1m
  name: 'Component-Level SLIs: gitlab-shell - 1h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="30"}[1h])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="60"}[1h])
        )
      )
      /
      2
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="+Inf"}[1h])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service="gitaly.SSHService",job="gitaly"}[1h])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!="OK",grpc_service="gitaly.SSHService",job="gitaly"}[1h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="grpc_requests",tier="sv",type="gitlab-shell"}
        )
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_errors:rate_1h
- interval: 2m
  name: 'Component-Level SLIs: gitlab-shell - 6h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="30"}[6h])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="60"}[6h])
        )
      )
      /
      2
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly",le="+Inf"}[6h])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(gitaly_service_client_requests_total{grpc_service="gitaly.SSHService",job="gitaly"}[6h])
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!="OK",grpc_service="gitaly.SSHService",job="gitaly"}[6h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="grpc_requests",tier="sv",type="gitlab-shell"}
        )
      )
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: gitlab_component_errors:rate_6h
- interval: 1m
  name: 'Component mapping: gitlab-shell'
  rules:
  - expr: "1"
    labels:
      component: grpc_requests
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: sv
      type: gitlab-shell
    record: gitlab_component_service:mapping
- interval: 1m
  name: 'Component-Level SLIs: praefect - 5m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="0.5"}[5m])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="1"}[5m])
        )
      )
      /
      2
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="+Inf"}[5m])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(grpc_server_handled_total{job="praefect"}[5m])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!~"^(OK|NotFound|Unauthenticated|AlreadyExists|FailedPrecondition|Canceled)$",job="praefect"}[5m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="proxy",tier="stor",type="praefect"}
        )
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_errors:rate_5m
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="300"}[5m])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[5m])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[5m])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_5m
- interval: 2m
  name: 'Component-Level SLIs: praefect - 30m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="0.5"}[30m])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="1"}[30m])
        )
      )
      /
      2
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="+Inf"}[30m])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(grpc_server_handled_total{job="praefect"}[30m])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!~"^(OK|NotFound|Unauthenticated|AlreadyExists|FailedPrecondition|Canceled)$",job="praefect"}[30m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="proxy",tier="stor",type="praefect"}
        )
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_errors:rate_30m
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="300"}[30m])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[30m])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[30m])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_30m
- interval: 1m
  name: 'Component-Level SLIs: praefect - 1h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="0.5"}[1h])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="1"}[1h])
        )
      )
      /
      2
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="+Inf"}[1h])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(grpc_server_handled_total{job="praefect"}[1h])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!~"^(OK|NotFound|Unauthenticated|AlreadyExists|FailedPrecondition|Canceled)$",job="praefect"}[1h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="proxy",tier="stor",type="praefect"}
        )
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_errors:rate_1h
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="300"}[1h])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[1h])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[1h])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_1h
- interval: 2m
  name: 'Component-Level SLIs: praefect - 6h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="0.5"}[6h])
        )
        +
        sum by () (
          rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="1"}[6h])
        )
      )
      /
      2
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect",le="+Inf"}[6h])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(grpc_server_handled_total{job="praefect"}[6h])
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          rate(grpc_server_handled_total{grpc_code!~"^(OK|NotFound|Unauthenticated|AlreadyExists|FailedPrecondition|Canceled)$",job="praefect"}[6h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="proxy",tier="stor",type="praefect"}
        )
      )
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: gitlab_component_errors:rate_6h
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="300"}[6h])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[6h])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[6h])
      )
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: gitlab_component_ops:rate_6h
- interval: 1m
  name: 'Component mapping: praefect'
  rules:
  - expr: "1"
    labels:
      component: proxy
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: stor
      type: praefect
    record: gitlab_component_service:mapping
  - expr: "1"
    labels:
      component: replicator_queue
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: stor
      type: praefect
    record: gitlab_component_service:mapping
- interval: 1m
  name: 'Component-Level SLIs: registry - 5m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="2.5"}[5m])
        )
        +
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="25"}[5m])
        )
      )
      /
      2
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(registry_http_request_duration_seconds_bucket{le="+Inf"}[5m])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(registry_http_requests_total{}[5m])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          rate(registry_http_requests_total{code=~"5.."}[5m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="server",tier="sv",type="registry"}
        )
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_errors:rate_5m
- interval: 2m
  name: 'Component-Level SLIs: registry - 30m burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="2.5"}[30m])
        )
        +
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="25"}[30m])
        )
      )
      /
      2
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(registry_http_request_duration_seconds_bucket{le="+Inf"}[30m])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(registry_http_requests_total{}[30m])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          rate(registry_http_requests_total{code=~"5.."}[30m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="server",tier="sv",type="registry"}
        )
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_errors:rate_30m
- interval: 1m
  name: 'Component-Level SLIs: registry - 1h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="2.5"}[1h])
        )
        +
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="25"}[1h])
        )
      )
      /
      2
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(registry_http_request_duration_seconds_bucket{le="+Inf"}[1h])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(registry_http_requests_total{}[1h])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          rate(registry_http_requests_total{code=~"5.."}[1h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="server",tier="sv",type="registry"}
        )
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_errors:rate_1h
- interval: 2m
  name: 'Component-Level SLIs: registry - 6h burn-rate'
  rules:
  - expr: |
      (
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="2.5"}[6h])
        )
        +
        sum by () (
          rate(registry_http_request_duration_seconds_bucket{le="25"}[6h])
        )
      )
      /
      2
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(registry_http_request_duration_seconds_bucket{le="+Inf"}[6h])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(registry_http_requests_total{}[6h])
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          rate(registry_http_requests_total{code=~"5.."}[6h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="server",tier="sv",type="registry"}
        )
      )
    labels:
      component: server
      tier: sv
      type: registry
    record: gitlab_component_errors:rate_6h
- interval: 1m
  name: 'Component mapping: registry'
  rules:
  - expr: "1"
    labels:
      component: server
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: sv
      type: registry
    record: gitlab_component_service:mapping
- interval: 1m
  name: 'Component-Level SLIs: sidekiq - 5m burn-rate'
  rules:
  - expr: |
      sum by (environment,feature_category,le,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_completion_seconds_bucket[5m])
      )
    record: sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m
  - expr: |
      sum by (environment,feature_category,le,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_queue_duration_seconds_bucket[5m])
      )
    record: sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m
  - expr: |
      sum by (environment,feature_category,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_failed_total[5m])
      )
    record: sli_aggregations:sidekiq_jobs_failed_total_rate5m
  - expr: |
      sum by () (
        rate(sidekiq_jobs_completion_seconds_count{worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          rate(gitlab_transaction_event_email_receiver_error_total{error!="Gitlab::Email::AutoGeneratedEmailError"}[5m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="email_receiver",tier="sv",type="sidekiq"}
        )
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_errors:rate_5m
  - expr: |
      sum by () (
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="10",urgency="high"}
        )
        , "_c", "0", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{le="10",urgency="high"}
        )
        , "_c", "1", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="300",urgency="low"}
        )
        , "_c", "2", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{le="60",urgency="low"}
        )
        , "_c", "3", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="300",urgency="throttled"}
        )
        , "_c", "4", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="300",urgency=""}
        )
        , "_c", "5", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{le="60",urgency=""}
        )
        , "_c", "6", "", "")
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="+Inf",urgency="high"}
        )
        , "_c", "0", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{le="+Inf",urgency="high"}
        )
        , "_c", "1", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="+Inf",urgency="low"}
        )
        , "_c", "2", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{le="+Inf",urgency="low"}
        )
        , "_c", "3", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="+Inf",urgency="throttled"}
        )
        , "_c", "4", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="+Inf",urgency=""}
        )
        , "_c", "5", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{le="+Inf",urgency=""}
        )
        , "_c", "6", "", "")
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="+Inf"}
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          sli_aggregations:sidekiq_jobs_failed_total_rate5m{}
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="shard_catchall",tier="sv",type="sidekiq"}
        )
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_errors:rate_5m
- interval: 2m
  name: 'Component-Level SLIs: sidekiq - 30m burn-rate'
  rules:
  - expr: |
      sum by (environment,feature_category,le,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_completion_seconds_bucket[30m])
      )
    record: sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m
  - expr: |
      sum by (environment,feature_category,le,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_queue_duration_seconds_bucket[30m])
      )
    record: sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate30m
  - expr: |
      sum by (environment,feature_category,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_failed_total[30m])
      )
    record: sli_aggregations:sidekiq_jobs_failed_total_rate30m
  - expr: |
      sum by () (
        rate(sidekiq_jobs_completion_seconds_count{worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[30m])
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          rate(gitlab_transaction_event_email_receiver_error_total{error!="Gitlab::Email::AutoGeneratedEmailError"}[30m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="email_receiver",tier="sv",type="sidekiq"}
        )
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_errors:rate_30m
  - expr: |
      sum by () (
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="10",urgency="high"}
        )
        , "_c", "0", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate30m{le="10",urgency="high"}
        )
        , "_c", "1", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="300",urgency="low"}
        )
        , "_c", "2", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate30m{le="60",urgency="low"}
        )
        , "_c", "3", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="300",urgency="throttled"}
        )
        , "_c", "4", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="300",urgency=""}
        )
        , "_c", "5", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate30m{le="60",urgency=""}
        )
        , "_c", "6", "", "")
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="+Inf",urgency="high"}
        )
        , "_c", "0", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate30m{le="+Inf",urgency="high"}
        )
        , "_c", "1", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="+Inf",urgency="low"}
        )
        , "_c", "2", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate30m{le="+Inf",urgency="low"}
        )
        , "_c", "3", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="+Inf",urgency="throttled"}
        )
        , "_c", "4", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="+Inf",urgency=""}
        )
        , "_c", "5", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate30m{le="+Inf",urgency=""}
        )
        , "_c", "6", "", "")
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate30m{le="+Inf"}
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          sli_aggregations:sidekiq_jobs_failed_total_rate30m{}
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="shard_catchall",tier="sv",type="sidekiq"}
        )
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: gitlab_component_errors:rate_30m
- interval: 1m
  name: 'Component-Level SLIs: sidekiq - 1h burn-rate'
  rules:
  - expr: |
      sum by (environment,feature_category,le,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_completion_seconds_bucket[1h])
      )
    record: sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h
  - expr: |
      sum by (environment,feature_category,le,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_queue_duration_seconds_bucket[1h])
      )
    record: sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate1h
  - expr: |
      sum by (environment,feature_category,queue,shard,stage,tier,type,urgency,worker) (
        rate(sidekiq_jobs_failed_total[1h])
      )
    record: sli_aggregations:sidekiq_jobs_failed_total_rate1h
  - expr: |
      sum by () (
        rate(sidekiq_jobs_completion_seconds_count{worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[1h])
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          rate(gitlab_transaction_event_email_receiver_error_total{error!="Gitlab::Email::AutoGeneratedEmailError"}[1h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="email_receiver",tier="sv",type="sidekiq"}
        )
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_errors:rate_1h
  - expr: |
      sum by () (
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="10",urgency="high"}
        )
        , "_c", "0", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate1h{le="10",urgency="high"}
        )
        , "_c", "1", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="300",urgency="low"}
        )
        , "_c", "2", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate1h{le="60",urgency="low"}
        )
        , "_c", "3", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="300",urgency="throttled"}
        )
        , "_c", "4", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="300",urgency=""}
        )
        , "_c", "5", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate1h{le="60",urgency=""}
        )
        , "_c", "6", "", "")
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
      upscale_source: "yes"
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="+Inf",urgency="high"}
        )
        , "_c", "0", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate1h{le="+Inf",urgency="high"}
        )
        , "_c", "1", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="+Inf",urgency="low"}
        )
        , "_c", "2", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate1h{le="+Inf",urgency="low"}
        )
        , "_c", "3", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="+Inf",urgency="throttled"}
        )
        , "_c", "4", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="+Inf",urgency=""}
        )
        , "_c", "5", "", "")
        or
        label_replace(sum by () (
          sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate1h{le="+Inf",urgency=""}
        )
        , "_c", "6", "", "")
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
      upscale_source: "yes"
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate1h{le="+Inf"}
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
      upscale_source: "yes"
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          sli_aggregations:sidekiq_jobs_failed_total_rate1h{}
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="shard_catchall",tier="sv",type="sidekiq",upscale_source="yes"}
        )
      )
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
      upscale_source: "yes"
    record: gitlab_component_errors:rate_1h
- interval: 2m
  name: 'Component-Level SLIs: sidekiq - 6h burn-rate'
  rules:
  - expr: |
      sum by () (
        rate(sidekiq_jobs_completion_seconds_count{worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[6h])
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          rate(gitlab_transaction_event_email_receiver_error_total{error!="Gitlab::Email::AutoGeneratedEmailError"}[6h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="email_receiver",tier="sv",type="sidekiq"}
        )
      )
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: gitlab_component_errors:rate_6h
- interval: 1m
  name: 'Component mapping: sidekiq'
  rules:
  - expr: "1"
    labels:
      component: email_receiver
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: sv
      type: sidekiq
    record: gitlab_component_service:mapping
  - expr: "1"
    labels:
      component: shard_catchall
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: sv
      type: sidekiq
    record: gitlab_component_service:mapping
- interval: 1m
  name: 'Component-Level SLIs: webservice - 5m burn-rate'
  rules:
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_success_total{job="gitlab-rails"}[5m])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_total{job="gitlab-rails"}[5m])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(http_requests_total{job="gitlab-rails"}[5m])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          rate(http_requests_total{job="gitlab-rails",status=~"5.."}[5m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="puma",tier="sv",type="webservice"}
        )
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_5m
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="1",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[5m])
        )
        +
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[5m])
        )
      )
      /
      2
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[5m])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[5m])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[5m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="workhorse",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_5m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_5m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_5m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_5m
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_5m{component="workhorse_api",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_5m
- interval: 2m
  name: 'Component-Level SLIs: webservice - 30m burn-rate'
  rules:
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_success_total{job="gitlab-rails"}[30m])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_total{job="gitlab-rails"}[30m])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(http_requests_total{job="gitlab-rails"}[30m])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          rate(http_requests_total{job="gitlab-rails",status=~"5.."}[30m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="puma",tier="sv",type="webservice"}
        )
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_30m
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="1",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[30m])
        )
        +
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[30m])
        )
      )
      /
      2
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[30m])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[30m])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[30m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="workhorse",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_30m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[30m])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_30m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[30m])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_30m
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[30m])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_30m
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[30m])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_30m{component="workhorse_api",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_30m
- interval: 1m
  name: 'Component-Level SLIs: webservice - 1h burn-rate'
  rules:
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_success_total{job="gitlab-rails"}[1h])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_total{job="gitlab-rails"}[1h])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(http_requests_total{job="gitlab-rails"}[1h])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          rate(http_requests_total{job="gitlab-rails",status=~"5.."}[1h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="puma",tier="sv",type="webservice"}
        )
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_1h
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="1",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[1h])
        )
        +
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[1h])
        )
      )
      /
      2
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[1h])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[1h])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[1h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="workhorse",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_1h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[1h])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_1h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[1h])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_1h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[1h])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_1h
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[1h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_1h{component="workhorse_api",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_1h
- interval: 2m
  name: 'Component-Level SLIs: webservice - 6h burn-rate'
  rules:
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_success_total{job="gitlab-rails"}[6h])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(gitlab_sli_rails_request_apdex_total{job="gitlab-rails"}[6h])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(http_requests_total{job="gitlab-rails"}[6h])
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          rate(http_requests_total{job="gitlab-rails",status=~"5.."}[6h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="puma",tier="sv",type="webservice"}
        )
      )
    labels:
      component: puma
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_6h
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="1",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[6h])
        )
        +
        sum by () (
          rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[6h])
        )
      )
      /
      2
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[6h])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[6h])
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[6h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="workhorse",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_6h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="10",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[6h])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:success:rate_6h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_request_duration_seconds_bucket{le="+Inf",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[6h])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_apdex:weight:score_6h
  - expr: |
      sum by () (
        rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[6h])
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_ops:rate_6h
  - expr: |
      (
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[6h])
        )
      )
      or
      (
        0 * group by() (
          gitlab_component_ops:rate_6h{component="workhorse_api",tier="sv",type="webservice"}
        )
      )
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: gitlab_component_errors:rate_6h
- interval: 1m
  name: 'Component mapping: webservice'
  rules:
  - expr: "1"
    labels:
      component: puma
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: sv
      type: webservice
    record: gitlab_component_service:mapping
  - expr: "1"
    labels:
      component: workhorse
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: sv
      type: webservice
    record: gitlab_component_service:mapping
  - expr: "1"
    labels:
      component: workhorse_api
      regional_aggregation: "no"
      service_aggregation: "yes"
      tier: sv
      type: webservice
    record: gitlab_component_service:mapping
- interval: 1m
  name: Global Service-Aggregated Metrics (fast burn)
  rules:
  - expr: |
      sum by (type) (
        (gitlab_component_errors:rate_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_errors:rate_5m
  - expr: |
      sum by (type) (
        (gitlab_component_ops:rate_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_ops:rate_5m
  - expr: |
      sum by (type)(
        (gitlab_component_errors:rate_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
      /
      sum by (type)(
        (gitlab_component_ops:rate_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        and
        (gitlab_component_errors:rate_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_errors:ratio_5m
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:weight:score_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:weight:score_5m
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:success:rate_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:success:rate_5m
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:success:rate_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
      /
      sum by (type) (
        (gitlab_component_apdex:weight:score_5m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:ratio_5m
  - expr: |
      sum by (type) (
        (gitlab_component_errors:rate_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_errors:rate_1h
  - expr: |
      sum by (type) (
        (gitlab_component_ops:rate_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_ops:rate_1h
  - expr: |
      sum by (type)(
        (gitlab_component_errors:rate_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
      /
      sum by (type)(
        (gitlab_component_ops:rate_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        and
        (gitlab_component_errors:rate_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_errors:ratio_1h
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:weight:score_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:weight:score_1h
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:success:rate_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:success:rate_1h
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:success:rate_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
      /
      sum by (type) (
        (gitlab_component_apdex:weight:score_1h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:ratio_1h
- interval: 2m
  name: Global Service-Aggregated Metrics (slow burn)
  rules:
  - expr: |
      sum by (type) (
        (gitlab_component_errors:rate_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_errors:rate_30m
  - expr: |
      sum by (type) (
        (gitlab_component_ops:rate_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_ops:rate_30m
  - expr: |
      sum by (type)(
        (gitlab_component_errors:rate_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
      /
      sum by (type)(
        (gitlab_component_ops:rate_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        and
        (gitlab_component_errors:rate_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_errors:ratio_30m
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:weight:score_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:weight:score_30m
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:success:rate_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:success:rate_30m
  - expr: |
      sum by (type) (
        (gitlab_component_apdex:success:rate_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
      /
      sum by (type) (
        (gitlab_component_apdex:weight:score_30m{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
      )
    record: gitlab_service_apdex:ratio_30m
  - expr: |
      (
        sum by (type) (
          (gitlab_component_errors:rate_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
      or
      (
        sum by (type) (
          avg_over_time(gitlab_component_errors:rate_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
    record: gitlab_service_errors:rate_6h
  - expr: |
      (
        sum by (type) (
          (gitlab_component_ops:rate_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
      or
      (
        sum by (type) (
          avg_over_time(gitlab_component_ops:rate_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
    record: gitlab_service_ops:rate_6h
  - expr: |
      (
        sum by (type)(
          (gitlab_component_errors:rate_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
        /
        sum by (type)(
          (gitlab_component_ops:rate_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
          and
          (gitlab_component_errors:rate_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
      or
      (
        sum by (type) (
          sum_over_time(gitlab_component_errors:rate_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
        /
        sum by (type) (
          sum_over_time(gitlab_component_ops:rate_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
          and
          gitlab_component_errors:rate_1h{upscale_source="yes"} >= 0
        )
      )
    record: gitlab_service_errors:ratio_6h
  - expr: |
      (
        sum by (type) (
          (gitlab_component_apdex:weight:score_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
      or
      (
        sum by (type) (
          avg_over_time(gitlab_component_apdex:weight:score_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
    record: gitlab_service_apdex:weight:score_6h
  - expr: |
      (
        sum by (type) (
          (gitlab_component_apdex:success:rate_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
      or
      (
        sum by (type) (
          avg_over_time(gitlab_component_apdex:success:rate_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
    record: gitlab_service_apdex:success:rate_6h
  - expr: |
      (
        sum by (type) (
          (gitlab_component_apdex:success:rate_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
        /
        sum by (type) (
          (gitlab_component_apdex:weight:score_6h{} >= 0) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
      or
      (
        sum by (type) (
          sum_over_time(gitlab_component_apdex:success:rate_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
        /
        sum by (type) (
          sum_over_time(gitlab_component_apdex:weight:score_1h{upscale_source="yes"}[6h]) and on(component, type) (gitlab_component_service:mapping{service_aggregation="yes"})
        )
      )
    record: gitlab_service_apdex:ratio_6h
- interval: 1m
  name: Global Component SLI Metrics (fast burn)
  rules:
  - expr: |
      sum by (type,component) (
        gitlab_component_errors:rate_5m{}
      )
      /
      sum by (type,component) (
        gitlab_component_ops:rate_5m{}
      )
    record: gitlab_component_errors:ratio_5m
  - expr: |
      sum by (type,component) (
        gitlab_component_apdex:success:rate_5m{}
      )
      /
      sum by (type,component) (
        gitlab_component_apdex:weight:score_5m{}
      )
    record: gitlab_component_apdex:ratio_5m
  - expr: |
      sum by (type,component) (
        gitlab_component_errors:rate_1h{}
      )
      /
      sum by (type,component) (
        gitlab_component_ops:rate_1h{}
      )
    record: gitlab_component_errors:ratio_1h
  - expr: |
      sum by (type,component) (
        gitlab_component_apdex:success:rate_1h{}
      )
      /
      sum by (type,component) (
        gitlab_component_apdex:weight:score_1h{}
      )
    record: gitlab_component_apdex:ratio_1h
- interval: 2m
  name: Global Component SLI Metrics (slow burn)
  rules:
  - expr: |
      sum by (type,component) (
        gitlab_component_errors:rate_30m{}
      )
      /
      sum by (type,component) (
        gitlab_component_ops:rate_30m{}
      )
    record: gitlab_component_errors:ratio_30m
  - expr: |
      sum by (type,component) (
        gitlab_component_apdex:success:rate_30m{}
      )
      /
      sum by (type,component) (
        gitlab_component_apdex:weight:score_30m{}
      )
    record: gitlab_component_apdex:ratio_30m
  - expr: |
      sum by (type,component) (
        gitlab_component_errors:rate_6h{}
      )
      /
      sum by (type,component) (
        gitlab_component_ops:rate_6h{}
      )
    record: gitlab_component_errors:ratio_6h
  - expr: |
      sum by (type,component) (
        gitlab_component_apdex:success:rate_6h{}
      )
      /
      sum by (type,component) (
        gitlab_component_apdex:weight:score_6h{}
      )
    record: gitlab_component_apdex:ratio_6h
- interval: 5m
  name: Autogenerated Service SLOs
  rules:
  - expr: "0.999000"
    labels:
      tier: stor
      type: gitaly
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000500"
    labels:
      tier: stor
      type: gitaly
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.999000"
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000500"
    labels:
      component: goserver
      tier: stor
      type: gitaly
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.999000"
    labels:
      tier: sv
      type: gitlab-shell
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.001000"
    labels:
      tier: sv
      type: gitlab-shell
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.999000"
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.001000"
    labels:
      component: grpc_requests
      tier: sv
      type: gitlab-shell
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.995000"
    labels:
      tier: stor
      type: praefect
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000500"
    labels:
      tier: stor
      type: praefect
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.995000"
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000500"
    labels:
      component: proxy
      tier: stor
      type: praefect
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.995000"
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000500"
    labels:
      component: replicator_queue
      tier: stor
      type: praefect
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.997000"
    labels:
      tier: sv
      type: registry
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000100"
    labels:
      tier: sv
      type: registry
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.997000"
    labels:
      component: server
      tier: sv
      type: registry
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000100"
    labels:
      component: server
      tier: sv
      type: registry
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.995000"
    labels:
      tier: sv
      type: sidekiq
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.005000"
    labels:
      tier: sv
      type: sidekiq
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.995000"
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.300000"
    labels:
      component: email_receiver
      tier: sv
      type: sidekiq
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.995000"
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.005000"
    labels:
      component: shard_catchall
      tier: sv
      type: sidekiq
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.998000"
    labels:
      tier: sv
      type: webservice
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000100"
    labels:
      tier: sv
      type: webservice
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.998000"
    labels:
      component: puma
      tier: sv
      type: webservice
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000100"
    labels:
      component: puma
      tier: sv
      type: webservice
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.998000"
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000100"
    labels:
      component: workhorse
      tier: sv
      type: webservice
    record: slo:max:events:gitlab_service_errors:ratio
  - expr: "0.998000"
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: slo:min:events:gitlab_service_apdex:ratio
  - expr: "0.000100"
    labels:
      component: workhorse_api
      tier: sv
      type: webservice
    record: slo:max:events:gitlab_service_errors:ratio
- interval: 1m
  name: Saturation Rules (autogenerated)
  rules:
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            1 - avg by (type) (
              rate(node_cpu_seconds_total{mode="idle", type=~"gitaly|consul|praefect"}[5m])
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            1 - (
              node_filesystem_files_free{fstype=~"(ext.|xfs)", type=~"gitaly|consul|praefect"}
              /
              node_filesystem_files{fstype=~"(ext.|xfs)", type=~"gitaly|consul|praefect"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: disk_inodes
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            (
              1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", type=~"gitaly|consul|praefect"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", type=~"gitaly|consul|praefect"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: disk_space
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            sum by (type, fqdn) (
              go_memstats_alloc_bytes{type=~"gitaly|praefect"}
            )
            /
            sum by (type, fqdn) (
              node_memory_MemTotal_bytes{type=~"gitaly|praefect"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: go_memory
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            sum by (type, pod, container) (
              rate(container_cpu_usage_seconds_total:labeled{container!="", container!="POD", type=~"consul|gitlab-shell|registry|sidekiq|webservice"}[5m])
            )
            /
            sum by(type, pod, container) (
              container_spec_cpu_quota:labeled{container!="", container!="POD", type=~"consul|gitlab-shell|registry|sidekiq|webservice"}
              /
              container_spec_cpu_period:labeled{container!="", container!="POD", type=~"consul|gitlab-shell|registry|sidekiq|webservice"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_container_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            container_memory_working_set_bytes:labeled{container!="", container!="POD", type=~"consul|gitlab-shell|registry|sidekiq|webservice"}
            /
            (container_spec_memory_limit_bytes:labeled{container!="", container!="POD", type=~"consul|gitlab-shell|registry|sidekiq|webservice"} > 0)
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_container_memory
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            1 - avg by (type) (
              rate(node_cpu_seconds_total:labeled{mode="idle", type=~"sidekiq|webservice"}[5m])
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_pool_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            instance:node_memory_utilization:ratio{type=~"gitaly|consul|praefect"} or instance:node_memory_utilisation:ratio{type=~"gitaly|consul|praefect"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: memory
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            avg without (cpu) (rate(node_schedstat_waiting_seconds_total{type=~"consul|gitaly|praefect"}[1h]))
            ,
            1)
        ,
        0)
      )
    labels:
      component: node_schedstat_waiting
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(type) (
        clamp_min(
          clamp_max(
            avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", type=~"gitaly|consul|praefect"}[5m]))
            ,
            1)
        ,
        0)
      )
    labels:
      component: single_node_cpu
    record: gitlab_component_saturation:ratio
- interval: 5m
  name: GitLab Component Saturation Max SLOs
  rules:
  - expr: "0.8"
    labels:
      component: cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.75"
    labels:
      component: disk_inodes
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: disk_inodes
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: disk_space
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: disk_space
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: go_memory
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.98"
    labels:
      component: go_memory
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_container_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.99"
    labels:
      component: kube_container_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: kube_container_memory
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_container_memory
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: kube_pool_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_pool_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: memory
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.98"
    labels:
      component: memory
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: memory_redis_cache
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.98"
    labels:
      component: memory_redis_cache
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.1"
    labels:
      component: node_schedstat_waiting
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.15"
    labels:
      component: node_schedstat_waiting
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.65"
    labels:
      component: opensearch_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: opensearch_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.6"
    labels:
      component: opensearch_disk_space
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.75"
    labels:
      component: opensearch_disk_space
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: single_node_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: single_node_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
- interval: 5m
  name: GitLab Component Saturation Metadata
  rules:
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_inodes
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: disk_space
      horiz_scaling: "yes"
      quantile: max
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: go_memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_container_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_container_memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: kube_pool_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: memory
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: exclude
      component: memory_redis_cache
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: node_schedstat_waiting
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: opensearch_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: opensearch_disk_space
      horiz_scaling: "yes"
      quantile: max
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      capacity_planning_strategy: quantile95_1h
      component: single_node_cpu
      horiz_scaling: "yes"
      quantile: max
      severity: s4
    record: gitlab_component_saturation_info
- interval: 5m
  name: GitLab Component Saturation Statistics
  rules:
  - expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{}[1w])
    record: gitlab_component_saturation:ratio_quantile95_1w
  - expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{}[1w])
    record: gitlab_component_saturation:ratio_quantile99_1w
  - expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{}[1h])
    record: gitlab_component_saturation:ratio_quantile95_1h
  - expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{}[1h])
    record: gitlab_component_saturation:ratio_quantile99_1h
  - expr: avg_over_time(gitlab_component_saturation:ratio{}[1h])
    record: gitlab_component_saturation:ratio_avg_1h
- interval: 1m
  name: GitLab Saturation Alerts
  rules:
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average Service CPU Utilization resource:

        This resource measures average CPU utilization across an all cores in a service fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling.

      grafana_dashboard_id: alerts-sat_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cpu?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1465724101"
      grafana_variables: type
      promql_query: |
        max by(type) (
          clamp_min(
            clamp_max(
              1 - avg by (type) (
                rate(node_cpu_seconds_total{mode="idle", type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Average Service CPU Utilization resource of the {{ $labels.type }}
        service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cpu"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk inode Utilization per Device per Node resource:

        Disk inode utilization per device per node.

        If this is too high, its possible that a directory is filling up with files. Consider logging in an checking temp directories for large numbers of files

      grafana_dashboard_id: alerts-sat_disk_inodes
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_inodes?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "39965907"
      grafana_variables: type
      promql_query: |
        max by(type, fqdn, device) (
          clamp_min(
            clamp_max(
              1 - (
                node_filesystem_files_free{fstype=~"(ext.|xfs)", type="{{ $labels.type }}"}
                /
                node_filesystem_files{fstype=~"(ext.|xfs)", type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Disk inode Utilization per Device per Node resource of the {{ $labels.type
        }} service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="disk_inodes"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_inodes"}
    for: 15m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Space Utilization per Device per Node resource:

        Disk space utilization per device per node.

      grafana_dashboard_id: alerts-sat_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_space?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2661375984"
      grafana_variables: type
      promql_query: |
        max by(type, node, device) (
          clamp_min(
            clamp_max(
              (
                1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", type="{{ $labels.type }}"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Disk Space Utilization per Device per Node resource of the {{ $labels.type
        }} service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_space"}
    for: 15m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Go Memory Utilization per Node resource:

        Go's memory allocation strategy can make it look like a Go process is saturating memory when measured using RSS, when in fact the process is not at risk of memory saturation. For this reason, we measure Go processes using the `go_memstat_alloc_bytes` metric instead of RSS.

      grafana_dashboard_id: alerts-sat_go_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_go_memory?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3631721613"
      grafana_variables: type
      promql_query: |
        max by(type, fqdn) (
          clamp_min(
            clamp_max(
              sum by (type, fqdn) (
                go_memstats_alloc_bytes{type="{{ $labels.type }}"}
              )
              /
              sum by (type, fqdn) (
                node_memory_MemTotal_bytes{type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Go Memory Utilization per Node resource of the {{ $labels.type }}
        service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="go_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="go_memory"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Container CPU Utilization resource:

        Kubernetes containers are allocated a share of CPU. When this is exhausted, the container may be thottled.

      grafana_dashboard_id: alerts-sat_kube_container_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_container_cpu?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2713861591"
      grafana_variables: type
      promql_query: |
        max by(type, pod, container) (
          clamp_min(
            clamp_max(
              sum by (type, pod, container) (
                rate(container_cpu_usage_seconds_total:labeled{container!="", container!="POD", type="{{ $labels.type }}"}[5m])
              )
              /
              sum by(type, pod, container) (
                container_spec_cpu_quota:labeled{container!="", container!="POD", type="{{ $labels.type }}"}
                /
                container_spec_cpu_period:labeled{container!="", container!="POD", type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Kube Container CPU Utilization resource of the {{ $labels.type }}
        service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_container_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_container_cpu"}
    for: 15m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Container Memory Utilization resource:

        This uses the working set size from cAdvisor for the cgroup's memory usage. That may not be a good measure as it includes filesystem cache pages that are not necessarily attributable to the application inside the cgroup, and are permitted to be evicted instead of being OOM killed.

      grafana_dashboard_id: alerts-sat_kube_container_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_container_memory?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "172578411"
      grafana_variables: type
      promql_query: |
        max by(type) (
          clamp_min(
            clamp_max(
              container_memory_working_set_bytes:labeled{container!="", container!="POD", type="{{ $labels.type }}"}
              /
              (container_spec_memory_limit_bytes:labeled{container!="", container!="POD", type="{{ $labels.type }}"} > 0)
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Kube Container Memory Utilization resource of the {{ $labels.type
        }} service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_container_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_container_memory"}
    for: 15m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average Node Pool CPU Utilization resource:

        This resource measures average CPU utilization across an all cores in the node pool for a service fleet.

        If it is becoming saturated, it may indicate that the fleet needs horizontal scaling.

      grafana_dashboard_id: alerts-sat_kube_pool_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pool_cpu?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1839360107"
      grafana_variables: type
      promql_query: |
        max by(type) (
          clamp_min(
            clamp_max(
              1 - avg by (type) (
                rate(node_cpu_seconds_total:labeled{mode="idle", type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Average Node Pool CPU Utilization resource of the {{ $labels.type
        }} service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_pool_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_pool_cpu"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Memory Utilization per Node resource:

        Memory utilization per device per node.

      grafana_dashboard_id: alerts-sat_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_memory?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1955556769"
      grafana_variables: type
      promql_query: |
        max by(type, node) (
          clamp_min(
            clamp_max(
              instance:node_memory_utilization:ratio{type="{{ $labels.type }}"} or instance:node_memory_utilisation:ratio{type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Memory Utilization per Node resource of the {{ $labels.type }} service
        has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="memory"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Memory Utilization per Node resource:

        Memory utilization per device per node.


        redis-cache has a separate saturation point for this to exclude it from capacity planning calculations.

      grafana_dashboard_id: alerts-sat_memory_redis_cache
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_memory_redis_cache?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2178235391"
      grafana_variables: type
      promql_query: |
        max by(type, node) (
          clamp_min(
            clamp_max(
              instance:node_memory_utilization:ratio{type="{{ $labels.type }}"} or instance:node_memory_utilisation:ratio{type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Memory Utilization per Node resource of the {{ $labels.type }} service
        has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="memory_redis_cache"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="memory_redis_cache"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Node Scheduler Waiting Time resource:

        Measures the amount of scheduler waiting time that processes are waiting to be scheduled, according to [`CPU Scheduling Metrics`](https://www.robustperception.io/cpu-scheduling-metrics-from-the-node-exporter).

        A high value indicates that a node has more processes to be run than CPU time available to handle them, and may lead to degraded responsiveness and performance from the application.

        Additionally, it may indicate that the fleet is under-provisioned.

      grafana_dashboard_id: alerts-sat_node_schedstat_waiting
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_node_schedstat_waiting?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1415313189"
      grafana_variables: type
      promql_query: |
        max by(type, fqdn, shard) (
          clamp_min(
            clamp_max(
              avg without (cpu) (rate(node_schedstat_waiting_seconds_total{type="{{ $labels.type }}"}[1h]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Node Scheduler Waiting Time resource of the {{ $labels.type }} service
        has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="node_schedstat_waiting"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="node_schedstat_waiting"}
    for: 90m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization for Opensearch resource:

        Average CPU utilization.

        This resource measures the CPU utilization for the selected cluster or domain. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling. The metrics are coming from cloudwatch_exporter.

      grafana_dashboard_id: alerts-sat_opensearch_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_opensearch_cpu?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "761924359"
      grafana_variables: type
      promql_query: |
        max by(type) (
          clamp_min(
            clamp_max(
              avg_over_time(aws_es_cpuutilization_average[1m])/100
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Average CPU Utilization for Opensearch resource of the {{ $labels.type
        }} service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="opensearch_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="opensearch_cpu"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Utilization Overall resource:

        Disk utilization for Opensearch

      grafana_dashboard_id: alerts-sat_opensearch_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_opensearch_disk_space?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1859424869"
      grafana_variables: type
      promql_query: |
        max by(type) (
          clamp_min(
            clamp_max(
              aws_es_cluster_used_space_average/(aws_es_free_storage_space_average+aws_es_cluster_used_space_average)
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Disk Utilization Overall resource of the {{ $labels.type }} service
        has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="opensearch_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="opensearch_disk_space"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |+
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU utilization per Node.

        If average CPU is saturated, it may indicate that a fleet is in need to horizontal or vertical scaling. It may also indicate imbalances in load in a fleet.

      grafana_dashboard_id: alerts-sat_single_node_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_single_node_cpu?from=now-6h/m&to=now-1m/m&var-type={{
        $labels.type }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3372411356"
      grafana_variables: type
      promql_query: |
        max by(type, node) (
          clamp_min(
            clamp_max(
              avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", type="{{ $labels.type }}"}[5m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Average CPU Utilization per Node resource of the {{ $labels.type
        }} service has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="single_node_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="single_node_cpu"}
    for: 10m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
- interval: 1m
  name: 'kube-state-metrics-recording-rules: consul'
  rules:
  - expr: |
      group without(label_deployment) (
        label_replace(
          topk by(cluster,pod) (1, kube_pod_labels{namespace="consul"}),
          "deployment", "$0", "label_deployment", ".*"
        )
      )
    labels:
      tier: inf
      type: consul
    record: kube_pod_labels:labeled
- interval: 1m
  name: 'kube-state-metrics-recording-rules: gitlab-shell'
  rules:
  - expr: |
      group without(label_deployment) (
        label_replace(
          topk by(cluster,pod) (1, kube_pod_labels{label_app="gitlab-shell"}),
          "deployment", "$0", "label_deployment", ".*"
        )
      )
    labels:
      tier: sv
      type: gitlab-shell
    record: kube_pod_labels:labeled
  - expr: topk by(cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels{horizontalpodautoscaler="gitlab-gitlab-shell"})
    labels:
      tier: sv
      type: gitlab-shell
    record: kube_horizontalpodautoscaler_labels:labeled
  - expr: topk by(cluster,deployment) (1, kube_deployment_labels{label_app="gitlab-shell"})
    labels:
      tier: sv
      type: gitlab-shell
    record: kube_deployment_labels:labeled
- interval: 1m
  name: 'kube-state-metrics-recording-rules: registry'
  rules:
  - expr: |
      group without(label_deployment) (
        label_replace(
          topk by(cluster,pod) (1, kube_pod_labels{label_app="registry"}),
          "deployment", "$0", "label_deployment", ".*"
        )
      )
    labels:
      tier: sv
      type: registry
    record: kube_pod_labels:labeled
  - expr: topk by(cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels{horizontalpodautoscaler="gitlab-registry"})
    labels:
      tier: sv
      type: registry
    record: kube_horizontalpodautoscaler_labels:labeled
  - expr: topk by(cluster,ingress) (1, kube_ingress_labels{label_app="registry"})
    labels:
      tier: sv
      type: registry
    record: kube_ingress_labels:labeled
  - expr: topk by(cluster,deployment) (1, kube_deployment_labels{label_app="registry"})
    labels:
      tier: sv
      type: registry
    record: kube_deployment_labels:labeled
- interval: 1m
  name: 'kube-state-metrics-recording-rules: sidekiq'
  rules:
  - expr: |
      group without(label_deployment) (
        label_replace(
          topk by(cluster,pod) (1, kube_pod_labels{label_app="sidekiq"}),
          "deployment", "$0", "label_deployment", ".*"
        )
      )
    labels:
      tier: sv
      type: sidekiq
    record: kube_pod_labels:labeled
  - expr: topk by(cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels{horizontalpodautoscaler="gitlab-sidekiq-all-in-1-v2"})
    labels:
      tier: sv
      type: sidekiq
    record: kube_horizontalpodautoscaler_labels:labeled
  - expr: topk by(cluster,node) (1, kube_node_labels{label_workload="sidekiq"})
    labels:
      tier: sv
      type: sidekiq
    record: kube_node_labels:labeled
  - expr: topk by(cluster,deployment) (1, kube_deployment_labels{label_app="sidekiq"})
    labels:
      tier: sv
      type: sidekiq
    record: kube_deployment_labels:labeled
- interval: 1m
  name: 'kube-state-metrics-recording-rules: webservice'
  rules:
  - expr: |
      group without(label_deployment) (
        label_replace(
          topk by(cluster,pod) (1, kube_pod_labels{label_app="webservice"}),
          "deployment", "$0", "label_deployment", ".*"
        )
      )
    labels:
      tier: sv
      type: webservice
    record: kube_pod_labels:labeled
  - expr: topk by(cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels{label_app="webservice"})
    labels:
      tier: sv
      type: webservice
    record: kube_horizontalpodautoscaler_labels:labeled
  - expr: topk by(cluster,node) (1, kube_node_labels{label_eks_amazonaws_com_nodegroup="gitlab_webservice_pool"})
    labels:
      tier: sv
      type: webservice
    record: kube_node_labels:labeled
  - expr: topk by(cluster,ingress) (1, kube_ingress_labels{label_app="webservice"})
    labels:
      tier: sv
      type: webservice
    record: kube_ingress_labels:labeled
  - expr: topk by(cluster,deployment) (1, kube_deployment_labels{label_app="webservice"})
    labels:
      tier: sv
      type: webservice
    record: kube_deployment_labels:labeled
- interval: 1m
  name: 'kube-state-metrics-recording-rules: enriched label recording rules'
  rules:
  - expr: |
      container_start_time_seconds{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_start_time_seconds:labeled
  - expr: |
      container_cpu_cfs_periods_total{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_cpu_cfs_periods_total:labeled
  - expr: |
      container_cpu_cfs_throttled_periods_total{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_cpu_cfs_throttled_periods_total:labeled
  - expr: |
      container_cpu_usage_seconds_total{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_cpu_usage_seconds_total:labeled
  - expr: |
      container_memory_cache{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_memory_cache:labeled
  - expr: |
      container_memory_rss{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_memory_rss:labeled
  - expr: |
      container_memory_swap{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_memory_swap:labeled
  - expr: |
      container_memory_usage_bytes{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_memory_usage_bytes:labeled
  - expr: |
      container_memory_working_set_bytes{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_memory_working_set_bytes:labeled
  - expr: |
      container_network_receive_bytes_total{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_network_receive_bytes_total:labeled
  - expr: |
      container_network_transmit_bytes_total{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_network_transmit_bytes_total:labeled
  - expr: |
      container_spec_cpu_period{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_spec_cpu_period:labeled
  - expr: |
      container_spec_cpu_quota{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_spec_cpu_quota:labeled
  - expr: |
      container_spec_cpu_shares{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_spec_cpu_shares:labeled
  - expr: |
      container_spec_memory_limit_bytes{metrics_path="/metrics/cadvisor"}
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: container_spec_memory_limit_bytes:labeled
  - expr: |
      kube_pod_container_status_running
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_running:labeled
  - expr: |
      kube_pod_container_resource_limits
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_resource_limits:labeled
  - expr: |
      kube_pod_container_resource_requests
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_resource_requests:labeled
  - expr: |
      kube_pod_container_status_last_terminated_reason
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_last_terminated_reason:labeled
  - expr: |
      kube_pod_container_status_ready
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_ready:labeled
  - expr: |
      kube_pod_container_status_restarts_total
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_restarts_total:labeled
  - expr: |
      kube_pod_container_status_running
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_running:labeled
  - expr: |
      kube_pod_container_status_terminated
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_terminated:labeled
  - expr: |
      kube_pod_container_status_terminated_reason
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_terminated_reason:labeled
  - expr: |
      kube_pod_container_status_waiting
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_waiting:labeled
  - expr: |
      kube_pod_container_status_waiting_reason
      *
      on(cluster,pod) group_left(type,deployment)
      topk by (cluster,pod) (1, kube_pod_labels:labeled{type!=""})
    record: kube_pod_container_status_waiting_reason:labeled
  - expr: |
      kube_horizontalpodautoscaler_spec_target_metric
      *
      on(cluster,horizontalpodautoscaler) group_left(type)
      topk by (cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels:labeled{type!=""})
    record: kube_horizontalpodautoscaler_spec_target_metric:labeled
  - expr: |
      kube_horizontalpodautoscaler_status_condition
      *
      on(cluster,horizontalpodautoscaler) group_left(type)
      topk by (cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels:labeled{type!=""})
    record: kube_horizontalpodautoscaler_status_condition:labeled
  - expr: |
      kube_horizontalpodautoscaler_status_current_replicas
      *
      on(cluster,horizontalpodautoscaler) group_left(type)
      topk by (cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels:labeled{type!=""})
    record: kube_horizontalpodautoscaler_status_current_replicas:labeled
  - expr: |
      kube_horizontalpodautoscaler_status_desired_replicas
      *
      on(cluster,horizontalpodautoscaler) group_left(type)
      topk by (cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels:labeled{type!=""})
    record: kube_horizontalpodautoscaler_status_desired_replicas:labeled
  - expr: |
      kube_horizontalpodautoscaler_metadata_generation
      *
      on(cluster,horizontalpodautoscaler) group_left(type)
      topk by (cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels:labeled{type!=""})
    record: kube_horizontalpodautoscaler_metadata_generation:labeled
  - expr: |
      kube_horizontalpodautoscaler_spec_max_replicas
      *
      on(cluster,horizontalpodautoscaler) group_left(type)
      topk by (cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels:labeled{type!=""})
    record: kube_horizontalpodautoscaler_spec_max_replicas:labeled
  - expr: |
      kube_horizontalpodautoscaler_spec_min_replicas
      *
      on(cluster,horizontalpodautoscaler) group_left(type)
      topk by (cluster,horizontalpodautoscaler) (1, kube_horizontalpodautoscaler_labels:labeled{type!=""})
    record: kube_horizontalpodautoscaler_spec_min_replicas:labeled
  - expr: |
      kube_node_status_capacity
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: kube_node_status_capacity:labeled
  - expr: |
      kube_node_status_allocatable
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: kube_node_status_allocatable:labeled
  - expr: |
      kube_node_status_condition
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: kube_node_status_condition:labeled
  - expr: |
      node_schedstat_waiting_seconds_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_schedstat_waiting_seconds_total:labeled
  - expr: |
      node_cpu_seconds_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_cpu_seconds_total:labeled
  - expr: |
      node_network_transmit_bytes_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_network_transmit_bytes_total:labeled
  - expr: |
      node_network_receive_bytes_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_network_receive_bytes_total:labeled
  - expr: |
      node_disk_reads_completed_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_disk_reads_completed_total:labeled
  - expr: |
      node_disk_writes_completed_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_disk_writes_completed_total:labeled
  - expr: |
      node_disk_read_bytes_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_disk_read_bytes_total:labeled
  - expr: |
      node_disk_written_bytes_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_disk_written_bytes_total:labeled
  - expr: |
      node_disk_read_time_seconds_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_disk_read_time_seconds_total:labeled
  - expr: |
      node_disk_write_time_seconds_total
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_disk_write_time_seconds_total:labeled
  - expr: |
      node_load1
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_load1:labeled
  - expr: |
      node_load5
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_load5:labeled
  - expr: |
      node_load15
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_load15:labeled
  - expr: |
      node_vmstat_oom_kill
      *
      on(cluster,node) group_left(type)
      topk by (cluster,node) (1, kube_node_labels:labeled{type!=""})
    record: node_vmstat_oom_kill:labeled
  - expr: |
      nginx_ingress_controller_bytes_sent_count
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_bytes_sent_count:labeled
  - expr: |
      nginx_ingress_controller_request_duration_seconds_bucket
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_request_duration_seconds_bucket:labeled
  - expr: |
      nginx_ingress_controller_request_duration_seconds_sum
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_request_duration_seconds_sum:labeled
  - expr: |
      nginx_ingress_controller_response_size_count
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_response_size_count:labeled
  - expr: |
      nginx_ingress_controller_ingress_upstream_latency_seconds
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_ingress_upstream_latency_seconds:labeled
  - expr: |
      nginx_ingress_controller_ingress_upstream_latency_seconds_count
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_ingress_upstream_latency_seconds_count:labeled
  - expr: |
      nginx_ingress_controller_ingress_upstream_latency_seconds_sum
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_ingress_upstream_latency_seconds_sum:labeled
  - expr: |
      nginx_ingress_controller_request_duration_seconds_count
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_request_duration_seconds_count:labeled
  - expr: |
      nginx_ingress_controller_request_size_bucket
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_request_size_bucket:labeled
  - expr: |
      nginx_ingress_controller_response_duration_seconds_bucket
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_response_duration_seconds_bucket:labeled
  - expr: |
      nginx_ingress_controller_bytes_sent_bucket
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_bytes_sent_bucket:labeled
  - expr: |
      nginx_ingress_controller_bytes_sent_sum
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_bytes_sent_sum:labeled
  - expr: |
      nginx_ingress_controller_request_size_count
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_request_size_count:labeled
  - expr: |
      nginx_ingress_controller_response_duration_seconds_sum
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_response_duration_seconds_sum:labeled
  - expr: |
      nginx_ingress_controller_request_size_sum
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_request_size_sum:labeled
  - expr: |
      nginx_ingress_controller_requests
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_requests:labeled
  - expr: |
      nginx_ingress_controller_response_duration_seconds_count
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_response_duration_seconds_count:labeled
  - expr: |
      nginx_ingress_controller_response_size_bucket
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_response_size_bucket:labeled
  - expr: |
      nginx_ingress_controller_response_size_sum
      *
      on(cluster,ingress) group_left(type)
      topk by (cluster,ingress) (1, kube_ingress_labels:labeled{type!=""})
    record: nginx_ingress_controller_response_size_sum:labeled
  - expr: |
      kube_deployment_status_replicas_unavailable
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_status_replicas_unavailable:labeled
  - expr: |
      kube_deployment_status_replicas_updated
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_status_replicas_updated:labeled
  - expr: |
      kube_deployment_spec_paused
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_spec_paused:labeled
  - expr: |
      kube_deployment_spec_replicas
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_spec_replicas:labeled
  - expr: |
      kube_deployment_spec_strategy_rollingupdate_max_surge
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_spec_strategy_rollingupdate_max_surge:labeled
  - expr: |
      kube_deployment_spec_strategy_rollingupdate_max_unavailable
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_spec_strategy_rollingupdate_max_unavailable:labeled
  - expr: |
      kube_deployment_status_condition
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_status_condition:labeled
  - expr: |
      kube_deployment_status_replicas_available
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_status_replicas_available:labeled
  - expr: |
      kube_deployment_created
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_created:labeled
  - expr: |
      kube_deployment_metadata_generation
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_metadata_generation:labeled
  - expr: |
      kube_deployment_status_observed_generation
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_status_observed_generation:labeled
  - expr: |
      kube_deployment_status_replicas
      *
      on(cluster,deployment) group_left(type)
      topk by (cluster,deployment) (1, kube_deployment_labels:labeled{type!=""})
    record: kube_deployment_status_replicas:labeled
- interval: 1m
  name: 'Service Component Alerts: consul'
  rules: []
- interval: 1m
  name: 'Service Component Alerts: gitaly'
  rules:
  - alert: GitalyServiceGoserverApdexSLOViolation
    annotations:
      description: |
        This SLI monitors all Gitaly GRPC requests in aggregate, excluding the OperationService. GRPC failures which are considered to be the "server's fault" are counted as errors. The apdex score is based on a subset of GRPC methods which are expected to be fast.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitaly-main/gitaly-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitaly-main/gitaly-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "877804374"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly"}[5m])
          )
        )
      runbook: docs/gitaly/README.md
      title: The goserver SLI of the gitaly service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="goserver",type="gitaly"}
          < (1 - 14.4 * 0.001000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="goserver",type="gitaly"}
          < (1 - 14.4 * 0.001000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="goserver",type="gitaly"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: GitalyServiceGoserverApdexSLOViolation
    annotations:
      description: |
        This SLI monitors all Gitaly GRPC requests in aggregate, excluding the OperationService. GRPC failures which are considered to be the "server's fault" are counted as errors. The apdex score is based on a subset of GRPC methods which are expected to be fast.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitaly-main/gitaly-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitaly-main/gitaly-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "877804374"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(grpc_server_handling_seconds_bucket{grpc_method!~"CalculateChecksum|CommitLanguages|CommitStats|CreateFork|CreateRepositoryFromURL|FetchInternalRemote|FetchIntoObjectPool|FetchRemote|FetchSourceBranch|FindRemoteRepository|FindRemoteRootRef|Fsck|GarbageCollect|OptimizeRepository|PackObjectsHookWithSidechannel|PostReceiveHook|PostUploadPackWithSidechannel|PreReceiveHook|RepackFull|RepackIncremental|ReplicateRepository|RepositorySize|SSHUploadPackWithSidechannel|UpdateHook",grpc_service!="gitaly.OperationService",grpc_type="unary",job="gitaly"}[5m])
          )
        )
      runbook: docs/gitaly/README.md
      title: The goserver SLI of the gitaly service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="goserver",type="gitaly"}
          < (1 - 6 * 0.001000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="goserver",type="gitaly"}
          < (1 - 6 * 0.001000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="goserver",type="gitaly"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: GitalyServiceGoserverErrorSLOViolation
    annotations:
      description: |
        This SLI monitors all Gitaly GRPC requests in aggregate, excluding the OperationService. GRPC failures which are considered to be the "server's fault" are counted as errors. The apdex score is based on a subset of GRPC methods which are expected to be fast.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitaly-main/gitaly-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitaly-main/gitaly-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "594670537"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          label_replace(rate(gitaly_service_client_requests_total{grpc_code!~"AlreadyExists|Canceled|DeadlineExceeded|FailedPrecondition|InvalidArgument|NotFound|OK|PermissionDenied|ResourceExhausted|Unauthenticated",grpc_service!="gitaly.OperationService",job="gitaly"}[5m]), "_c", "0", "", "")
          or
          label_replace(rate(gitaly_service_client_requests_total{deadline_type!="limited",grpc_code="DeadlineExceeded",grpc_service!="gitaly.OperationService",job="gitaly"}[5m]), "_c", "1", "", "")
        )
      runbook: docs/gitaly/README.md
      title: The goserver SLI of the gitaly service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="goserver",type="gitaly"}
          > (14.4 * 0.000500)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="goserver",type="gitaly"}
          > (14.4 * 0.000500)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="goserver",type="gitaly"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: GitalyServiceGoserverErrorSLOViolation
    annotations:
      description: |
        This SLI monitors all Gitaly GRPC requests in aggregate, excluding the OperationService. GRPC failures which are considered to be the "server's fault" are counted as errors. The apdex score is based on a subset of GRPC methods which are expected to be fast.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitaly-main/gitaly-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitaly-main/gitaly-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "594670537"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          label_replace(rate(gitaly_service_client_requests_total{grpc_code!~"AlreadyExists|Canceled|DeadlineExceeded|FailedPrecondition|InvalidArgument|NotFound|OK|PermissionDenied|ResourceExhausted|Unauthenticated",grpc_service!="gitaly.OperationService",job="gitaly"}[5m]), "_c", "0", "", "")
          or
          label_replace(rate(gitaly_service_client_requests_total{deadline_type!="limited",grpc_code="DeadlineExceeded",grpc_service!="gitaly.OperationService",job="gitaly"}[5m]), "_c", "1", "", "")
        )
      runbook: docs/gitaly/README.md
      title: The goserver SLI of the gitaly service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="goserver",type="gitaly"}
          > (6 * 0.000500)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="goserver",type="gitaly"}
          > (6 * 0.000500)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="goserver",type="gitaly"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: GitalyServiceGoserverTrafficCessation
    annotations:
      description: |
        This SLI monitors all Gitaly GRPC requests in aggregate, excluding the OperationService. GRPC failures which are considered to be the "server's fault" are counted as errors. The apdex score is based on a subset of GRPC methods which are expected to be fast.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: gitaly-main/gitaly-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitaly-main/gitaly-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1687078843"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitaly_service_client_requests_total{grpc_service!="gitaly.OperationService",job="gitaly"}[5m])
        )
      runbook: docs/gitaly/README.md
      title: The goserver SLI of the gitaly service has not received any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="goserver",type="gitaly"} == 0
      and
      gitlab_component_ops:rate_30m{component="goserver",type="gitaly"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: GitalyServiceGoserverTrafficAbsent
    annotations:
      description: |
        This SLI monitors all Gitaly GRPC requests in aggregate, excluding the OperationService. GRPC failures which are considered to be the "server's fault" are counted as errors. The apdex score is based on a subset of GRPC methods which are expected to be fast.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: gitaly-main/gitaly-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitaly-main/gitaly-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1687078843"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitaly_service_client_requests_total{grpc_service!="gitaly.OperationService",job="gitaly"}[5m])
        )
      runbook: docs/gitaly/README.md
      title: The goserver SLI of the gitaly service has not reported any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="goserver",type="gitaly"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="goserver",type="gitaly"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
- interval: 1m
  name: 'Service Component Alerts: gitlab-shell'
  rules:
  - alert: GitlabShellServiceGrpcRequestsApdexSLOViolation
    annotations:
      description: |
        A proxy measurement of the number of GRPC SSH service requests made to Gitaly and Praefect.

        Since we are unable to measure gitlab-shell directly at present, this is the best substitute we can provide.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitlab-shell-main/gitlab-shell-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitlab-shell-main/gitlab-shell-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2041855155"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly"}[5m])
          )
        )
      runbook: docs/gitlab-shell/README.md
      title: The grpc_requests SLI of the gitlab-shell service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="grpc_requests",type="gitlab-shell"}
          < (1 - 14.4 * 0.001000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="grpc_requests",type="gitlab-shell"}
          < (1 - 14.4 * 0.001000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="grpc_requests",type="gitlab-shell"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: GitlabShellServiceGrpcRequestsApdexSLOViolation
    annotations:
      description: |
        A proxy measurement of the number of GRPC SSH service requests made to Gitaly and Praefect.

        Since we are unable to measure gitlab-shell directly at present, this is the best substitute we can provide.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitlab-shell-main/gitlab-shell-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitlab-shell-main/gitlab-shell-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2041855155"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(grpc_server_handling_seconds_bucket{grpc_service="gitaly.SSHService",grpc_type="unary",job="gitaly"}[5m])
          )
        )
      runbook: docs/gitlab-shell/README.md
      title: The grpc_requests SLI of the gitlab-shell service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="grpc_requests",type="gitlab-shell"}
          < (1 - 6 * 0.001000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="grpc_requests",type="gitlab-shell"}
          < (1 - 6 * 0.001000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="grpc_requests",type="gitlab-shell"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: GitlabShellServiceGrpcRequestsErrorSLOViolation
    annotations:
      description: |
        A proxy measurement of the number of GRPC SSH service requests made to Gitaly and Praefect.

        Since we are unable to measure gitlab-shell directly at present, this is the best substitute we can provide.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitlab-shell-main/gitlab-shell-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitlab-shell-main/gitlab-shell-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "928307072"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(grpc_server_handled_total{grpc_code!="OK",grpc_service="gitaly.SSHService",job="gitaly"}[5m])
        )
      runbook: docs/gitlab-shell/README.md
      title: The grpc_requests SLI of the gitlab-shell service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="grpc_requests",type="gitlab-shell"}
          > (14.4 * 0.001000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="grpc_requests",type="gitlab-shell"}
          > (14.4 * 0.001000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="grpc_requests",type="gitlab-shell"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: GitlabShellServiceGrpcRequestsErrorSLOViolation
    annotations:
      description: |
        A proxy measurement of the number of GRPC SSH service requests made to Gitaly and Praefect.

        Since we are unable to measure gitlab-shell directly at present, this is the best substitute we can provide.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: gitlab-shell-main/gitlab-shell-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitlab-shell-main/gitlab-shell-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "928307072"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(grpc_server_handled_total{grpc_code!="OK",grpc_service="gitaly.SSHService",job="gitaly"}[5m])
        )
      runbook: docs/gitlab-shell/README.md
      title: The grpc_requests SLI of the gitlab-shell service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="grpc_requests",type="gitlab-shell"}
          > (6 * 0.001000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="grpc_requests",type="gitlab-shell"}
          > (6 * 0.001000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="grpc_requests",type="gitlab-shell"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: GitlabShellServiceGrpcRequestsTrafficCessation
    annotations:
      description: |
        A proxy measurement of the number of GRPC SSH service requests made to Gitaly and Praefect.

        Since we are unable to measure gitlab-shell directly at present, this is the best substitute we can provide.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: gitlab-shell-main/gitlab-shell-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitlab-shell-main/gitlab-shell-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3837654202"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitaly_service_client_requests_total{grpc_service="gitaly.SSHService",job="gitaly"}[5m])
        )
      runbook: docs/gitlab-shell/README.md
      title: The grpc_requests SLI of the gitlab-shell service has not received any
        traffic in the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="grpc_requests",type="gitlab-shell"} == 0
      and
      gitlab_component_ops:rate_30m{component="grpc_requests",type="gitlab-shell"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: GitlabShellServiceGrpcRequestsTrafficAbsent
    annotations:
      description: |
        A proxy measurement of the number of GRPC SSH service requests made to Gitaly and Praefect.

        Since we are unable to measure gitlab-shell directly at present, this is the best substitute we can provide.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: gitlab-shell-main/gitlab-shell-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/gitlab-shell-main/gitlab-shell-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3837654202"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitaly_service_client_requests_total{grpc_service="gitaly.SSHService",job="gitaly"}[5m])
        )
      runbook: docs/gitlab-shell/README.md
      title: The grpc_requests SLI of the gitlab-shell service has not reported any
        traffic in the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="grpc_requests",type="gitlab-shell"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="grpc_requests",type="gitlab-shell"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
- interval: 1m
  name: 'Service Component Alerts: praefect'
  rules:
  - alert: PraefectServiceProxyApdexSLOViolation
    annotations:
      description: |
        All Gitaly operations pass through the Praefect proxy on the way to a Gitaly instance. This SLI monitors those operations in aggregate.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2100325234"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect"}[5m])
          )
        )
      runbook: docs/praefect/README.md
      title: The proxy SLI of the praefect service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="proxy",type="praefect"}
          < (1 - 14.4 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="proxy",type="praefect"}
          < (1 - 14.4 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="proxy",type="praefect"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: PraefectServiceProxyApdexSLOViolation
    annotations:
      description: |
        All Gitaly operations pass through the Praefect proxy on the way to a Gitaly instance. This SLI monitors those operations in aggregate.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2100325234"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(grpc_server_handling_seconds_bucket{grpc_type="unary",job="praefect"}[5m])
          )
        )
      runbook: docs/praefect/README.md
      title: The proxy SLI of the praefect service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="proxy",type="praefect"}
          < (1 - 6 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="proxy",type="praefect"}
          < (1 - 6 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="proxy",type="praefect"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: PraefectServiceProxyErrorSLOViolation
    annotations:
      description: |
        All Gitaly operations pass through the Praefect proxy on the way to a Gitaly instance. This SLI monitors those operations in aggregate.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1178914866"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(grpc_server_handled_total{grpc_code!~"^(OK|NotFound|Unauthenticated|AlreadyExists|FailedPrecondition|Canceled)$",job="praefect"}[5m])
        )
      runbook: docs/praefect/README.md
      title: The proxy SLI of the praefect service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="proxy",type="praefect"}
          > (14.4 * 0.000500)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="proxy",type="praefect"}
          > (14.4 * 0.000500)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="proxy",type="praefect"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: PraefectServiceProxyErrorSLOViolation
    annotations:
      description: |
        All Gitaly operations pass through the Praefect proxy on the way to a Gitaly instance. This SLI monitors those operations in aggregate.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1178914866"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(grpc_server_handled_total{grpc_code!~"^(OK|NotFound|Unauthenticated|AlreadyExists|FailedPrecondition|Canceled)$",job="praefect"}[5m])
        )
      runbook: docs/praefect/README.md
      title: The proxy SLI of the praefect service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="proxy",type="praefect"}
          > (6 * 0.000500)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="proxy",type="praefect"}
          > (6 * 0.000500)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="proxy",type="praefect"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: PraefectServiceProxyTrafficCessation
    annotations:
      description: |
        All Gitaly operations pass through the Praefect proxy on the way to a Gitaly instance. This SLI monitors those operations in aggregate.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2797965992"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(grpc_server_handled_total{job="praefect"}[5m])
        )
      runbook: docs/praefect/README.md
      title: The proxy SLI of the praefect service has not received any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="proxy",type="praefect"} == 0
      and
      gitlab_component_ops:rate_30m{component="proxy",type="praefect"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: PraefectServiceProxyTrafficAbsent
    annotations:
      description: |
        All Gitaly operations pass through the Praefect proxy on the way to a Gitaly instance. This SLI monitors those operations in aggregate.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2797965992"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(grpc_server_handled_total{job="praefect"}[5m])
        )
      runbook: docs/praefect/README.md
      title: The proxy SLI of the praefect service has not reported any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="proxy",type="praefect"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="proxy",type="praefect"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: PraefectServiceReplicatorQueueApdexSLOViolation
    annotations:
      description: |
        Praefect replication operations. Latency represents the queuing delay before replication is carried out.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "374957850"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(gitaly_praefect_replication_delay_bucket{}[5m])
          )
        )
      runbook: docs/praefect/README.md
      title: The replicator_queue SLI of the praefect service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="replicator_queue",type="praefect"}
          < (1 - 14.4 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="replicator_queue",type="praefect"}
          < (1 - 14.4 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="replicator_queue",type="praefect"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "no"
      window: 1h
  - alert: PraefectServiceReplicatorQueueApdexSLOViolation
    annotations:
      description: |
        Praefect replication operations. Latency represents the queuing delay before replication is carried out.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "374957850"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(gitaly_praefect_replication_delay_bucket{}[5m])
          )
        )
      runbook: docs/praefect/README.md
      title: The replicator_queue SLI of the praefect service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="replicator_queue",type="praefect"}
          < (1 - 6 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="replicator_queue",type="praefect"}
          < (1 - 6 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="replicator_queue",type="praefect"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "no"
      window: 6h
  - alert: PraefectServiceReplicatorQueueTrafficCessation
    annotations:
      description: |
        Praefect replication operations. Latency represents the queuing delay before replication is carried out.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1815534001"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[5m])
        )
      runbook: docs/praefect/README.md
      title: The replicator_queue SLI of the praefect service has not received any
        traffic in the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="replicator_queue",type="praefect"} == 0
      and
      gitlab_component_ops:rate_30m{component="replicator_queue",type="praefect"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
  - alert: PraefectServiceReplicatorQueueTrafficAbsent
    annotations:
      description: |
        Praefect replication operations. Latency represents the queuing delay before replication is carried out.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: praefect-main/praefect-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/praefect-main/praefect-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1815534001"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitaly_praefect_replication_delay_bucket{le="+Inf"}[5m])
        )
      runbook: docs/praefect/README.md
      title: The replicator_queue SLI of the praefect service has not reported any
        traffic in the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="replicator_queue",type="praefect"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="replicator_queue",type="praefect"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
- interval: 1m
  name: 'Service Component Alerts: registry'
  rules:
  - alert: RegistryServiceServerApdexSLOViolation
    annotations:
      description: |
        Aggregation of all registry HTTP requests.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: registry-main/registry-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/registry-main/registry-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2863319079"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(registry_http_request_duration_seconds_bucket{}[5m])
          )
        )
      runbook: docs/registry/README.md
      title: The server SLI of the registry service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="server",type="registry"}
          < (1 - 14.4 * 0.003000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="server",type="registry"}
          < (1 - 14.4 * 0.003000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="server",type="registry"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: RegistryServiceServerApdexSLOViolation
    annotations:
      description: |
        Aggregation of all registry HTTP requests.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: registry-main/registry-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/registry-main/registry-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2863319079"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(registry_http_request_duration_seconds_bucket{}[5m])
          )
        )
      runbook: docs/registry/README.md
      title: The server SLI of the registry service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="server",type="registry"}
          < (1 - 6 * 0.003000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="server",type="registry"}
          < (1 - 6 * 0.003000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="server",type="registry"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: RegistryServiceServerErrorSLOViolation
    annotations:
      description: |
        Aggregation of all registry HTTP requests.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: registry-main/registry-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/registry-main/registry-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1631973137"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(registry_http_requests_total{code=~"5.."}[5m])
        )
      runbook: docs/registry/README.md
      title: The server SLI of the registry service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="server",type="registry"}
          > (14.4 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="server",type="registry"}
          > (14.4 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="server",type="registry"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: RegistryServiceServerErrorSLOViolation
    annotations:
      description: |
        Aggregation of all registry HTTP requests.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: registry-main/registry-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/registry-main/registry-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1631973137"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(registry_http_requests_total{code=~"5.."}[5m])
        )
      runbook: docs/registry/README.md
      title: The server SLI of the registry service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="server",type="registry"}
          > (6 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="server",type="registry"}
          > (6 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="server",type="registry"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: RegistryServiceServerTrafficCessation
    annotations:
      description: |
        Aggregation of all registry HTTP requests.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: registry-main/registry-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/registry-main/registry-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2414183688"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(registry_http_requests_total{}[5m])
        )
      runbook: docs/registry/README.md
      title: The server SLI of the registry service has not received any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="server",type="registry"} == 0
      and
      gitlab_component_ops:rate_30m{component="server",type="registry"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: RegistryServiceServerTrafficAbsent
    annotations:
      description: |
        Aggregation of all registry HTTP requests.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: registry-main/registry-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/registry-main/registry-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2414183688"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(registry_http_requests_total{}[5m])
        )
      runbook: docs/registry/README.md
      title: The server SLI of the registry service has not reported any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="server",type="registry"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="server",type="registry"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
- interval: 1m
  name: 'Service Component Alerts: sidekiq'
  rules:
  - alert: SidekiqServiceEmailReceiverErrorSLOViolation
    annotations:
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "212053046"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_transaction_event_email_receiver_error_total{error!="Gitlab::Email::AutoGeneratedEmailError"}[5m])
        )
      runbook: docs/sidekiq/README.md
      title: The email_receiver SLI of the sidekiq service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="email_receiver",type="sidekiq"}
          > (14.4 * 0.300000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="email_receiver",type="sidekiq"}
          > (14.4 * 0.300000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="email_receiver",type="sidekiq"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: SidekiqServiceEmailReceiverErrorSLOViolation
    annotations:
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "212053046"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_transaction_event_email_receiver_error_total{error!="Gitlab::Email::AutoGeneratedEmailError"}[5m])
        )
      runbook: docs/sidekiq/README.md
      title: The email_receiver SLI of the sidekiq service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="email_receiver",type="sidekiq"}
          > (6 * 0.300000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="email_receiver",type="sidekiq"}
          > (6 * 0.300000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="email_receiver",type="sidekiq"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: SidekiqServiceEmailReceiverTrafficCessation
    annotations:
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1545803555"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(sidekiq_jobs_completion_seconds_count{worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/sidekiq/README.md
      title: The email_receiver SLI of the sidekiq service has not received any traffic
        in the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="email_receiver",type="sidekiq"} == 0
      and
      gitlab_component_ops:rate_30m{component="email_receiver",type="sidekiq"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: SidekiqServiceEmailReceiverTrafficAbsent
    annotations:
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1545803555"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(sidekiq_jobs_completion_seconds_count{worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/sidekiq/README.md
      title: The email_receiver SLI of the sidekiq service has not reported any traffic
        in the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="email_receiver",type="sidekiq"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="email_receiver",type="sidekiq"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: SidekiqServiceShardCatchallApdexSLOViolation
    annotations:
      description: |
        All Sidekiq jobs

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4125397901"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency="throttled"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency=""}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{urgency=""}
          )
        )
      runbook: docs/sidekiq/README.md
      title: The shard_catchall SLI of the sidekiq service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="shard_catchall",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="shard_catchall",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="shard_catchall",type="sidekiq"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: SidekiqServiceShardCatchallApdexSLOViolation
    annotations:
      description: |
        All Sidekiq jobs

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4125397901"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency="throttled"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{urgency=""}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{urgency=""}
          )
        )
      runbook: docs/sidekiq/README.md
      title: The shard_catchall SLI of the sidekiq service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="shard_catchall",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="shard_catchall",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="shard_catchall",type="sidekiq"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: SidekiqServiceShardCatchallErrorSLOViolation
    annotations:
      description: |
        All Sidekiq jobs

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "532783926"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          sli_aggregations:sidekiq_jobs_failed_total_rate5m{}
        )
      runbook: docs/sidekiq/README.md
      title: The shard_catchall SLI of the sidekiq service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="shard_catchall",type="sidekiq"}
          > (14.4 * 0.005000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="shard_catchall",type="sidekiq"}
          > (14.4 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="shard_catchall",type="sidekiq"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: SidekiqServiceShardCatchallErrorSLOViolation
    annotations:
      description: |
        All Sidekiq jobs

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "532783926"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          sli_aggregations:sidekiq_jobs_failed_total_rate5m{}
        )
      runbook: docs/sidekiq/README.md
      title: The shard_catchall SLI of the sidekiq service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="shard_catchall",type="sidekiq"}
          > (6 * 0.005000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="shard_catchall",type="sidekiq"}
          > (6 * 0.005000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="shard_catchall",type="sidekiq"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: SidekiqServiceShardCatchallTrafficCessation
    annotations:
      description: |
        All Sidekiq jobs

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2518816313"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="+Inf"}
        )
      runbook: docs/sidekiq/README.md
      title: The shard_catchall SLI of the sidekiq service has not received any traffic
        in the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="shard_catchall",type="sidekiq"} == 0
      and
      gitlab_component_ops:rate_30m{component="shard_catchall",type="sidekiq"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: SidekiqServiceShardCatchallTrafficAbsent
    annotations:
      description: |
        All Sidekiq jobs

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2518816313"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{le="+Inf"}
        )
      runbook: docs/sidekiq/README.md
      title: The shard_catchall SLI of the sidekiq service has not reported any traffic
        in the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="shard_catchall",type="sidekiq"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="shard_catchall",type="sidekiq"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
- interval: 1m
  name: 'Service Component Alerts: webservice'
  rules:
  - alert: WebserviceServicePumaApdexSLOViolation
    annotations:
      description: |
        Aggregation of most web requests that pass through the puma to the GitLab rails monolith. Healthchecks are excluded.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "561966508"
      grafana_variables: environment,stage
      runbook: docs/webservice/README.md
      title: The puma SLI of the webservice service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="puma",type="webservice"}
          < (1 - 14.4 * 0.002000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="puma",type="webservice"}
          < (1 - 14.4 * 0.002000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="puma",type="webservice"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: WebserviceServicePumaApdexSLOViolation
    annotations:
      description: |
        Aggregation of most web requests that pass through the puma to the GitLab rails monolith. Healthchecks are excluded.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "561966508"
      grafana_variables: environment,stage
      runbook: docs/webservice/README.md
      title: The puma SLI of the webservice service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="puma",type="webservice"}
          < (1 - 6 * 0.002000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="puma",type="webservice"}
          < (1 - 6 * 0.002000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="puma",type="webservice"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: WebserviceServicePumaErrorSLOViolation
    annotations:
      description: |
        Aggregation of most web requests that pass through the puma to the GitLab rails monolith. Healthchecks are excluded.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2425637513"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(http_requests_total{job="gitlab-rails",status=~"5.."}[5m])
        )
      runbook: docs/webservice/README.md
      title: The puma SLI of the webservice service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="puma",type="webservice"}
          > (14.4 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="puma",type="webservice"}
          > (14.4 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="puma",type="webservice"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: WebserviceServicePumaErrorSLOViolation
    annotations:
      description: |
        Aggregation of most web requests that pass through the puma to the GitLab rails monolith. Healthchecks are excluded.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2425637513"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(http_requests_total{job="gitlab-rails",status=~"5.."}[5m])
        )
      runbook: docs/webservice/README.md
      title: The puma SLI of the webservice service has an error rate violating SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="puma",type="webservice"}
          > (6 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="puma",type="webservice"}
          > (6 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="puma",type="webservice"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: WebserviceServicePumaTrafficCessation
    annotations:
      description: |
        Aggregation of most web requests that pass through the puma to the GitLab rails monolith. Healthchecks are excluded.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "110019945"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(http_requests_total{job="gitlab-rails"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The puma SLI of the webservice service has not received any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="puma",type="webservice"} == 0
      and
      gitlab_component_ops:rate_30m{component="puma",type="webservice"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: WebserviceServicePumaTrafficAbsent
    annotations:
      description: |
        Aggregation of most web requests that pass through the puma to the GitLab rails monolith. Healthchecks are excluded.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "110019945"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(http_requests_total{job="gitlab-rails"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The puma SLI of the webservice service has not reported any traffic in
        the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="puma",type="webservice"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="puma",type="webservice"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: WebserviceServiceWorkhorseApdexSLOViolation
    annotations:
      description: |
        Aggregation of most rails requests that pass through workhorse, monitored via the HTTP interface. Excludes API requests health, readiness and liveness requests. Some known slow requests, such as HTTP uploads, are excluded from the apdex score.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2586818196"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(gitlab_workhorse_http_request_duration_seconds_bucket{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[5m])
          )
        )
      runbook: docs/webservice/README.md
      title: The workhorse SLI of the webservice service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="workhorse",type="webservice"}
          < (1 - 14.4 * 0.002000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="workhorse",type="webservice"}
          < (1 - 14.4 * 0.002000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="workhorse",type="webservice"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: WebserviceServiceWorkhorseApdexSLOViolation
    annotations:
      description: |
        Aggregation of most rails requests that pass through workhorse, monitored via the HTTP interface. Excludes API requests health, readiness and liveness requests. Some known slow requests, such as HTTP uploads, are excluded from the apdex score.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2586818196"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(gitlab_workhorse_http_request_duration_seconds_bucket{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!="^/([^/]+/){1,}[^/]+/uploads\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-receive-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/git-upload-pack\\z",route!="^/([^/]+/){1,}[^/]+\\.git/info/refs\\z",route!="^/([^/]+/){1,}[^/]+\\.git/gitlab-lfs/objects/([0-9a-f]{64})/([0-9]+)\\z",route!="^/-/cable\\z",route!~"^\\^/api/.*"}[5m])
          )
        )
      runbook: docs/webservice/README.md
      title: The workhorse SLI of the webservice service has an apdex violating SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="workhorse",type="webservice"}
          < (1 - 6 * 0.002000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="workhorse",type="webservice"}
          < (1 - 6 * 0.002000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="workhorse",type="webservice"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: WebserviceServiceWorkhorseErrorSLOViolation
    annotations:
      description: |
        Aggregation of most rails requests that pass through workhorse, monitored via the HTTP interface. Excludes API requests health, readiness and liveness requests. Some known slow requests, such as HTTP uploads, are excluded from the apdex score.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2047984749"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse SLI of the webservice service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="workhorse",type="webservice"}
          > (14.4 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="workhorse",type="webservice"}
          > (14.4 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="workhorse",type="webservice"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: WebserviceServiceWorkhorseErrorSLOViolation
    annotations:
      description: |
        Aggregation of most rails requests that pass through workhorse, monitored via the HTTP interface. Excludes API requests health, readiness and liveness requests. Some known slow requests, such as HTTP uploads, are excluded from the apdex score.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2047984749"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse SLI of the webservice service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="workhorse",type="webservice"}
          > (6 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="workhorse",type="webservice"}
          > (6 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="workhorse",type="webservice"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: WebserviceServiceWorkhorseTrafficCessation
    annotations:
      description: |
        Aggregation of most rails requests that pass through workhorse, monitored via the HTTP interface. Excludes API requests health, readiness and liveness requests. Some known slow requests, such as HTTP uploads, are excluded from the apdex score.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "831392945"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse SLI of the webservice service has not received any traffic
        in the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="workhorse",type="webservice"} == 0
      and
      gitlab_component_ops:rate_30m{component="workhorse",type="webservice"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: WebserviceServiceWorkhorseTrafficAbsent
    annotations:
      description: |
        Aggregation of most rails requests that pass through workhorse, monitored via the HTTP interface. Excludes API requests health, readiness and liveness requests. Some known slow requests, such as HTTP uploads, are excluded from the apdex score.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "831392945"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route!~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse SLI of the webservice service has not reported any traffic
        in the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="workhorse",type="webservice"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="workhorse",type="webservice"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: WebserviceServiceWorkhorseApiApdexSLOViolation
    annotations:
      description: |
        Aggregation of most API requests that pass through workhorse, monitored via the HTTP interface.

        The workhorse API apdex has a longer apdex latency than the web to allow for slow API requests.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1061500963"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(gitlab_workhorse_http_request_duration_seconds_bucket{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
          )
        )
      runbook: docs/webservice/README.md
      title: The workhorse_api SLI of the webservice service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="workhorse_api",type="webservice"}
          < (1 - 14.4 * 0.002000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="workhorse_api",type="webservice"}
          < (1 - 14.4 * 0.002000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="workhorse_api",type="webservice"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: WebserviceServiceWorkhorseApiApdexSLOViolation
    annotations:
      description: |
        Aggregation of most API requests that pass through workhorse, monitored via the HTTP interface.

        The workhorse API apdex has a longer apdex latency than the web to allow for slow API requests.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1061500963"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (le) (
            rate(gitlab_workhorse_http_request_duration_seconds_bucket{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
          )
        )
      runbook: docs/webservice/README.md
      title: The workhorse_api SLI of the webservice service has an apdex violating
        SLO
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="workhorse_api",type="webservice"}
          < (1 - 6 * 0.002000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="workhorse_api",type="webservice"}
          < (1 - 6 * 0.002000)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="workhorse_api",type="webservice"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: WebserviceServiceWorkhorseApiErrorSLOViolation
    annotations:
      description: |
        Aggregation of most API requests that pass through workhorse, monitored via the HTTP interface.

        The workhorse API apdex has a longer apdex latency than the web to allow for slow API requests.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1957610638"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse_api SLI of the webservice service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="workhorse_api",type="webservice"}
          > (14.4 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="workhorse_api",type="webservice"}
          > (14.4 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_1h{component="workhorse_api",type="webservice"}) >= 1
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
  - alert: WebserviceServiceWorkhorseApiErrorSLOViolation
    annotations:
      description: |
        Aggregation of most API requests that pass through workhorse, monitored via the HTTP interface.

        The workhorse API apdex has a longer apdex latency than the web to allow for slow API requests.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1957610638"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{code=~"^5.*",route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse_api SLI of the webservice service has an error rate violating
        SLO
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="workhorse_api",type="webservice"}
          > (6 * 0.000100)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="workhorse_api",type="webservice"}
          > (6 * 0.000100)
        )
      )
      and on(type,component)
      (
        sum by(type,component) (gitlab_component_ops:rate_6h{component="workhorse_api",type="webservice"}) >= 0.16667
      )
    for: 2m
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
  - alert: WebserviceServiceWorkhorseApiTrafficCessation
    annotations:
      description: |
        Aggregation of most API requests that pass through workhorse, monitored via the HTTP interface.

        The workhorse API apdex has a longer apdex latency than the web to allow for slow API requests.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3800674929"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse_api SLI of the webservice service has not received any
        traffic in the past 30m
    expr: |
      gitlab_component_ops:rate_30m{component="workhorse_api",type="webservice"} == 0
      and
      gitlab_component_ops:rate_30m{component="workhorse_api",type="webservice"} offset 1h >= 0.16666666666666666
    for: 5m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
  - alert: WebserviceServiceWorkhorseApiTrafficAbsent
    annotations:
      description: |
        Aggregation of most API requests that pass through workhorse, monitored via the HTTP interface.

        The workhorse API apdex has a longer apdex latency than the web to allow for slow API requests.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: webservice-main/webservice-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/webservice-main/webservice-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3800674929"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by () (
          rate(gitlab_workhorse_http_requests_total{route!="^/-/health$",route!="^/-/(readiness|liveness)$",route=~"^\\^/api/.*"}[5m])
        )
      runbook: docs/webservice/README.md
      title: The workhorse_api SLI of the webservice service has not reported any
        traffic in the past 30m
    expr: |
      gitlab_component_ops:rate_5m{component="workhorse_api",type="webservice"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="workhorse_api",type="webservice"}
    for: 30m
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
- interval: 5m
  name: Autogenerated Availability Rates
  rules:
  - expr: |
      sum by (type) (
        (
          sum by(type) (
            gitlab_service_ops:rate_1h{type=~"registry|webservice"}
          )
          +
          sum by (type) (
            gitlab_service_apdex:weight:score_1h{type=~"registry|webservice"}
          )
        )
      )
    record: gitlab:availability:ops:rate_1h
  - expr: |
      sum by (type) (
        (
          sum by(type) (
            gitlab_service_apdex:success:rate_1h{type=~"registry|webservice"}
          )
          +
          sum by (type)(
            gitlab_service_ops:rate_1h{type=~"registry|webservice"} - gitlab_service_errors:rate_1h{type=~"registry|webservice"}
          )
        )
      )
    record: gitlab:availability:success:rate_1h
