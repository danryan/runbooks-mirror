groups:
- name: node_alerts.rules
  rules:
  - alert: LowDiskSpace
    expr: node_filesystem_avail{fstype=~"(ext.|xfs)",job="node"} / node_filesystem_size{fstype=~"(ext.|xfs)",job="node"}
      * 100 <= 10
    for: 15m
    labels:
      severity: critical
    annotations:
      description: Consider sshing into the instance and removing old logs or clean
        temp files following the linked runbook. For status check http://performance.gitlab.net/dashboard/db/fleet-overview
      runbook: troubleshooting/filesystem_alerts.md
      title: 'Really low disk space left on {{ $labels.mountpoint }} on {{ if $labels.fqdn
        }}{{ $labels.fqdn }}{{ else }}{{ $labels.instance }}{{ end }}: {{ $value |
        humanize }}%'
  - alert: NoDiskSpace
    expr: node_filesystem_avail{fstype=~"(ext.|xfs)",job="node"} / node_filesystem_size{fstype=~"(ext.|xfs)",job="node"}
      * 100 <= 1
    for: 15m
    labels:
      pager: pagerduty
      severity: critical
    annotations:
      description: There's only 1% disk space left on host {{ if $labels.fqdn }}{{
        $labels.fqdn }}{{ else }}{{ $labels.instance }}{{ end }}
      runbook: troubleshooting/filesystem_alerts.md
      title: 'No disk space left on {{ $labels.mountpoint }} on {{ if $labels.fqdn
        }}{{ $labels.fqdn }}{{ else }}{{ $labels.instance }}{{ end }}: {{ $value |
        humanize }}%'
  - alert: HighInodeUsage
    expr: node_filesystem_files_free{fstype=~"(ext.|xfs)",job="node"} / node_filesystem_files{fstype=~"(ext.|xfs)",job="node"}
      * 100 <= 20
    for: 15m
    labels:
      severity: critical
    annotations:
      description: Consider ssh'ing into the instance and removing files or clean
        temp files following the linked runbook. For status check http://performance.gitlab.net/dashboard/db/fleet-overview
      runbook: troubleshooting/filesystem_alerts_inodes.md
      title: Free inodes on {{ if $labels.fqdn }}{{ $labels.fqdn }}{{ else }}{{ $labels.instance
        }}{{ end }} on mountpoint {{ $labels.mountpoint }} is at {{ $value | printf
        "%.2f" }}%
  - alert: ExtremelyHighCPU
    expr: instance:node_cpu_in_use:ratio{environment=~"prd|cny"} > 0.95
    for: 2h
    labels:
      pager: pagerduty
      severity: critical
    annotations:
      description: CPU use percent is extremely high on {{ if $labels.fqdn }}{{ $labels.fqdn
        }}{{ else }}{{ $labels.instance }}{{ end }} for the past 2 hours.
      runbook: troubleshooting
      title: CPU use percent is extremely high on {{ if $labels.fqdn }}{{ $labels.fqdn
        }}{{ else }}{{ $labels.instance }}{{ end }} for the past 2 hours.
  - alert: HighCPU
    expr: instance:node_cpu_in_use:ratio{environment=~"prd|cny"} > 0.8
    for: 2h
    labels:
      severity: critical
    annotations:
      description: CPU use percent is extremely high on {{ if $labels.fqdn }}{{ $labels.fqdn
        }}{{ else }}{{ $labels.instance }}{{ end }} for the past 2 hours.
      runbook: troubleshooting
      title: CPU use percent is high on {{ if $labels.fqdn }}{{ $labels.fqdn }}{{
        else }}{{ $labels.instance }}{{ end }} for the past 2 hours.
  - alert: CPUOutlierDetectionOnPrd
    expr: instance:node_cpu_in_use:percent5m{environment=~"prd|cny"} >= ON(job, fqdn,
      environment) GROUP_LEFT() (clamp_max(instance:node_cpu_in_use:percent1h + 2
      * instance:node_cpu_in_use:percent_stddev_over_time1h, 1))
    for: 10m
    labels:
      severity: warn
    annotations:
      description: The CPU usage on {{ if $labels.fqdn }}{{ $labels.fqdn }}{{ else
        }}{{ $labels.instance }}{{ end }} is outside normal values over a 1h period
      runbook: troubleshooting
      title: CPU use percent is unusually high compared with the rate of the last
        hour
  - alert: FleetSizeChanged
    expr: changes(instance:up:count{environment="prd"}[5m]) >= 1
    for: 15m
    labels:
      channel: production
      severity: warn
    annotations:
      description: The {{ $labels.type }} fleet has changed, this can be due to having
        more or less, if it's the latter it can be because nodes went down silently
      runbook: troubleshooting
      title: The fleet size has changed in the last 5 minutes
