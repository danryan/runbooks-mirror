# WARNING. DO NOT EDIT THIS FILE BY HAND. USE /Users/andrewn/code/gitlab/runbooks/metrics-topologies/get-hybrid/source/generate.jsonnet TO GENERATE IT. YOUR CHANGES WILL BE OVERRIDDEN
groups:
- interval: 1m
  name: Saturation Rules (autogenerated)
  rules:
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"} -
              container_memory_cache{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"} -
              container_memory_swap{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"}
            )
            /
            container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", type=~"gitaly|praefect"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: cgroup_memory
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - (
              sum by (environment, tier, type, stage, shard) (
                node_filesystem_avail_bytes{type="gitaly", device="/dev/sdb"}
              )
              /
              sum by (environment, tier, type, stage, shard) (
                node_filesystem_size_bytes{type="gitaly", device="/dev/sdb"}
              )
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: gitaly_total_disk_space
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, pod, container) (
              rate(container_cpu_usage_seconds_total:labeled{container!="", container!="POD", type="webservice"}[5m])
            )
            /
            sum by(environment, tier, type, stage, pod, container) (
              container_spec_cpu_quota:labeled{container!="", container!="POD", type="webservice"}
              /
              container_spec_cpu_period:labeled{container!="", container!="POD", type="webservice"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_container_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            container_memory_working_set_bytes:labeled{container!="", container!="POD", type="webservice"}
            /
            (container_spec_memory_limit_bytes:labeled{container!="", container!="POD", type="webservice"} > 0)
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_container_memory
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              go_memstats_alloc_bytes{type="webservice"}
              / on(environment, tier, type, stage, cluster, pod) group_left()
              topk by(environment, tier, type, stage, cluster, pod) (1,
                container_spec_memory_limit_bytes:labeled{container=~"gitlab-workhorse|kas|registry|thanos-store",type="webservice"}
              )
            )
            or
            (
              go_memstats_alloc_bytes{type="monitoring", type="webservice"}
              / on(environment, tier, type, cluster, pod) group_left()
              topk by (environment, tier, type, cluster, pod) (1,
                container_spec_memory_limit_bytes:labeled{type="monitoring", container=~"gitlab-workhorse|kas|registry|thanos-store"}
              )
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_go_memory
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            kubelet_volume_stats_used_bytes
            /
            kubelet_volume_stats_capacity_bytes
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_persistent_volume_claim_disk_space
      stage: main
      tier: inf
      type: kube
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            kubelet_volume_stats_inodes_used
            /
            kubelet_volume_stats_inodes
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_persistent_volume_claim_inodes
      stage: main
      tier: inf
      type: kube
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - avg by (environment, tier, type, stage) (
              rate(node_cpu_seconds_total:labeled{mode="idle", type=~"kube|git|registry|ci-runners|sidekiq|kas|api|websocket"}[5m])
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_pool_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(env, environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            count by (cluster, env, environment, label_pool, tier, type, stage, shard) (
              kube_node_labels:labeled{type=~"webservice|kube"}
            )
            / on(cluster, env, environment, label_pool) group_left() (
              label_replace(
                terraform_report_google_cluster_node_pool_max_node_count,
                "label_pool", "$0", "pool_name", ".*"
              )
              * on(cluster, env, environment) group_left()
              count by (cluster, env, environment) (
                group by (cluster, env, environment, label_topology_kubernetes_io_zone) (
                  kube_node_labels:labeled{type=~"webservice|kube"}
                )
              )
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: kube_pool_max_nodes
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              process_open_fds{type!="",type!~"nat|waf|kube"}
              /
              process_max_fds{type!="",type!~"nat|waf|kube"}
            )
            or
            (
              ruby_file_descriptors{type!="",type!~"nat|waf|kube"}
              /
              ruby_process_max_fds{type!="",type!~"nat|waf|kube"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: open_fds
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without (state) (
              pg_stat_activity_count{datname="gitlabhq_production", state!="idle", type="patroni"} unless on(instance) (pg_replication_is_replica == 1)
            )
            / on (environment, tier, type, stage, fqdn)
            pg_settings_max_connections{type="patroni"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_active_db_connections_primary
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without (state) (
              pg_stat_activity_count{datname="gitlabhq_production", state!="idle", type="patroni"} and on(instance) (pg_replication_is_replica == 1)
            )
            / on (environment, tier, type, stage, fqdn)
            pg_settings_max_connections{type="patroni"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_active_db_connections_replica
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_bloat_size{job="gitlab-monitor-database-bloat", type=~"patroni|postgres-archive"}[58m]))
            /
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_real_size{job="gitlab-monitor-database-bloat", type=~"patroni|postgres-archive"}[58m]))
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_btree_bloat
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max by (environment, tier, type, stage, table_name) (
              pg_integer_capacity_current{type="patroni"}
              /
              pg_integer_capacity_maximum{type="patroni"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_int4_id
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(env, environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg without(cpu, mode) (
              1
              -
              (
                rate(node_cpu_seconds_total{mode="idle", type="patroni"}[5m])
                and on(fqdn)
                pg_replication_is_replica{type="patroni"} == 0
              )
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_primary_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_bloat_size{job="gitlab-monitor-database-bloat", type=~"patroni|postgres-archive"}[58m]))
            /
            sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_real_size{job="gitlab-monitor-database-bloat", type=~"patroni|postgres-archive"}[58m]))
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_table_bloat
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              sum by (environment, tier, type, stage) (
                avg_over_time(pg_stat_activity_autovacuum_active_workers_count{type=~"patroni|sentry"}[1m])
                and on (instance, job) (pg_replication_is_replica{type=~"patroni|sentry"} == 0)
              )
              or
              clamp_max(
                group by (environment, tier, type, stage) (
                  pg_settings_autovacuum_max_workers{type=~"patroni|sentry"}
                  and on (instance, job) (pg_replication_is_replica{type=~"patroni|sentry"} == 0)
                ),
              0)
            )
            /
            avg by (environment, tier, type, stage) (
              pg_settings_autovacuum_max_workers{type=~"patroni|sentry"}
              and on (instance, job) (pg_replication_is_replica{type=~"patroni|sentry"} == 0)
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_vacuum_activity
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(env, environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (env, environment, tier, type, stage) (
              sum by(env, environment, tier, type, stage, fqdn) (
                rate(namedprocess_namegroup_cpu_seconds_total{type="patroni", groupname=~"pg.worker.walsender|pg.worker.walwriter|wal-g"}[5m])
                and on (fqdn) (pg_replication_is_replica{type="patroni"} == 0)
              )
              /
              count by (env, environment, tier, type, stage, fqdn) (
                node_cpu_seconds_total{type="patroni", mode="idle"} and on(fqdn) (pg_replication_is_replica{type="patroni"} == 0)
              )
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_walsender_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              max without (series) (
                label_replace(pg_database_wraparound_age_datfrozenxid{type="patroni"}, "series", "datfrozenxid", "", "")
                or
                label_replace(pg_database_wraparound_age_datminmxid{type="patroni"}, "series", "datminmxid", "", "")
              )
              and on (instance, job) (pg_replication_is_replica{type="patroni"} == 0)
            )
            /
            (2^31 - 10^6)
            ,
            1)
        ,
        0)
      )
    labels:
      component: pg_xid_wraparound
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="pgbouncer"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", type="pgbouncer"}[5m])
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pgbouncer_async_primary_pool
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", type="patroni"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", type="patroni"}[5m])
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pgbouncer_async_replica_pool
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg_over_time(pgbouncer_used_clients {type=~"patroni|pgbouncer"}[5m])
            /
            8192
            ,
            1)
        ,
        0)
      )
    labels:
      component: pgbouncer_client_conn
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without(cpu, mode) (
              rate(
                namedprocess_namegroup_cpu_seconds_total{groupname=~"pgbouncer.*", type=~"pgbouncer|patroni"}[5m]
              )
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pgbouncer_single_core
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", type="pgbouncer"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", type="pgbouncer"}[5m])
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pgbouncer_sync_primary_pool
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", type="patroni"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", type="patroni"}[5m])
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: pgbouncer_sync_replica_pool
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_cpu_utilization{database_id=~".+:praefect-db.+", }[5m])
            ,
            1)
        ,
        0)
      )
    labels:
      component: praefect_cloudsql_cpu
      stage: main
      tier: stor
      type: praefect
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state) (
              max_over_time(gitlab_runner_jobs{job="runners-manager",shard="private"}[1m])
            )
            /
            gitlab_runner_limit{job="runners-manager",shard="private"} > 0
            ,
            1)
        ,
        0)
      )
    labels:
      component: private_runners
      stage: main
      tier: runners
      type: ci-runners
    record: gitlab_component_saturation:ratio
  - expr: "max by(environment) (\n  clamp_min(\n    clamp_max(\n      sum by (environment,
      state) (\n        stackdriver_cloud_run_revision_run_googleapis_com_container_instance_count{\n
      \         configuration_name=\"pipeline-validation-service\",\n          \n
      \       }\n      )\n      /\n      100\n      ,\n      1)\n  ,\n  0)\n)\n"
    labels:
      component: pvs_cloudrun_container_instances
      stage: main
      tier: inf
      type: pvs
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(gitlab_database_connection_pool_busy{class="ActiveRecord::Base", type=~"web|api|git|sidekiq|websockets"}[5m])
              +
              avg_over_time(gitlab_database_connection_pool_dead{class="ActiveRecord::Base", type=~"web|api|git|sidekiq|websockets"}[5m])
            )
            /
            gitlab_database_connection_pool_size{class="ActiveRecord::Base", type=~"web|api|git|sidekiq|websockets"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: rails_db_connection_pool
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max_over_time(redis_connected_clients{type=~"redis|redis-sidekiq|redis-cache|redis-tracechunks"}[1m])
            /
            redis_config_maxclients{type=~"redis|redis-sidekiq|redis-cache|redis-tracechunks"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: redis_clients
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max by (environment, tier, type, stage, fqdn) (
              label_replace(redis_memory_used_rss_bytes{type=~"redis|redis-sidekiq|redis-cache"}, "memtype", "rss","","")
              or
              label_replace(redis_memory_used_bytes{type=~"redis|redis-sidekiq|redis-cache"}, "memtype", "used","","")
            )
            /
            avg by (environment, tier, type, stage, fqdn) (
              node_memory_MemTotal_bytes{type=~"redis|redis-sidekiq|redis-cache"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: redis_memory
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max by (environment, tier, type, stage, fqdn) (
              label_replace(redis_memory_used_rss_bytes{type="redis-tracechunks"}, "memtype", "rss","","")
              or
              label_replace(redis_memory_used_bytes{type="redis-tracechunks"}, "memtype", "used","","")
            )
            /
            avg by (environment, tier, type, stage, fqdn) (
              node_memory_MemTotal_bytes{type="redis-tracechunks"}
            )
            ,
            1)
        ,
        0)
      )
    labels:
      component: redis_memory_tracechunks
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, fqdn) (
              rate(
                namedprocess_namegroup_thread_cpu_seconds_total{type=~"redis|redis-sidekiq|redis-cache|redis-tracechunks", groupname="redis-server", threadname="redis-server"}[1m])
            )
            and on (fqdn) redis_instance_info{role="master"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: redis_primary_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              rate(redis_cpu_user_seconds_total{type=~"redis|redis-sidekiq|redis-cache|redis-tracechunks"}[1m])
              +
              rate(redis_cpu_sys_seconds_total{type=~"redis|redis-sidekiq|redis-cache|redis-tracechunks"}[1m])
            )
            and on (instance) redis_instance_info{role!="master"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: redis_secondary_cpu
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(ruby_process_cpu_seconds_total{type=~"web|sidekiq|api|git|websockets"}[10m])
            ,
            1)
        ,
        0)
      )
    labels:
      component: ruby_thread_contention
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state, runner) (
              max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared"}[1m])
            )
            /
            gitlab_runner_concurrent{job="runners-manager",shard="shared"} > 0
            ,
            1)
        ,
        0)
      )
    labels:
      component: shared_runners
      stage: main
      tier: runners
      type: ci-runners
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state) (
              max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared-gitlab-org"}[1m])
            )
            /
            gitlab_runner_limit{job="runners-manager",shard="shared-gitlab-org"} > 0
            ,
            1)
        ,
        0)
      )
    labels:
      component: shared_runners_gitlab
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by(environment, tier, type, stage, fqdn) (avg_over_time(instance:puma_active_connections:sum{type=~"web|api|git|sidekiq|websockets"}[1m]))
            /
            sum by(environment, tier, type, stage, fqdn) (instance:puma_max_threads:sum{type=~"web|api|git|sidekiq|websockets"})
            ,
            1)
        ,
        0)
      )
    labels:
      component: single_node_puma_workers
    record: gitlab_component_saturation:ratio
  - expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg_over_time(gitlab_workhorse_image_resize_processes{type="web"}[5m])
              /
            gitlab_workhorse_image_resize_max_processes{type="web"}
            ,
            1)
        ,
        0)
      )
    labels:
      component: workhorse_image_scaling
    record: gitlab_component_saturation:ratio
- interval: 5m
  name: GitLab Component Saturation Max SLOs
  rules:
  - expr: "0.8"
    labels:
      component: cgroup_memory
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: cgroup_memory
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.69"
    labels:
      component: gitaly_total_disk_space
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.7"
    labels:
      component: gitaly_total_disk_space
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_container_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.99"
    labels:
      component: kube_container_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_container_memory
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.99"
    labels:
      component: kube_container_memory
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_go_memory
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.98"
    labels:
      component: kube_go_memory
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: kube_persistent_volume_claim_disk_space
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_persistent_volume_claim_disk_space
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: kube_persistent_volume_claim_inodes
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_persistent_volume_claim_inodes
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: kube_pool_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_pool_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: kube_pool_max_nodes
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: kube_pool_max_nodes
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: open_fds
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: open_fds
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.7"
    labels:
      component: pg_active_db_connections_primary
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: pg_active_db_connections_primary
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: pg_active_db_connections_replica
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: pg_active_db_connections_replica
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.3"
    labels:
      component: pg_btree_bloat
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.4"
    labels:
      component: pg_btree_bloat
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.7"
    labels:
      component: pg_int4_id
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: pg_int4_id
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: pg_primary_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: pg_primary_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.3"
    labels:
      component: pg_table_bloat
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.4"
    labels:
      component: pg_table_bloat
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: pg_vacuum_activity
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "1"
    labels:
      component: pg_vacuum_activity
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.1"
    labels:
      component: pg_walsender_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.2"
    labels:
      component: pg_walsender_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.6"
    labels:
      component: pg_xid_wraparound
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.7"
    labels:
      component: pg_xid_wraparound
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: pgbouncer_async_primary_pool
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: pgbouncer_async_primary_pool
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: pgbouncer_async_replica_pool
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: pgbouncer_async_replica_pool
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: pgbouncer_client_conn
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: pgbouncer_client_conn
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: pgbouncer_single_core
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: pgbouncer_single_core
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: pgbouncer_sync_primary_pool
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: pgbouncer_sync_primary_pool
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: pgbouncer_sync_replica_pool
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: pgbouncer_sync_replica_pool
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: praefect_cloudsql_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: praefect_cloudsql_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: private_runners
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: private_runners
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: pvs_cloudrun_container_instances
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: pvs_cloudrun_container_instances
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: rails_db_connection_pool
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.99"
    labels:
      component: rails_db_connection_pool
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.8"
    labels:
      component: redis_clients
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: redis_clients
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.65"
    labels:
      component: redis_memory
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.7"
    labels:
      component: redis_memory
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.4"
    labels:
      component: redis_memory_tracechunks
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.5"
    labels:
      component: redis_memory_tracechunks
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.7"
    labels:
      component: redis_primary_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: redis_primary_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: redis_secondary_cpu
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: redis_secondary_cpu
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.7"
    labels:
      component: ruby_thread_contention
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.75"
    labels:
      component: ruby_thread_contention
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: shared_runners
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: shared_runners
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: shared_runners_gitlab
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: shared_runners_gitlab
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.85"
    labels:
      component: single_node_puma_workers
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: single_node_puma_workers
    record: slo:max:hard:gitlab_component_saturation:ratio
  - expr: "0.9"
    labels:
      component: workhorse_image_scaling
    record: slo:max:soft:gitlab_component_saturation:ratio
  - expr: "0.95"
    labels:
      component: workhorse_image_scaling
    record: slo:max:hard:gitlab_component_saturation:ratio
- interval: 5m
  name: GitLab Component Saturation Metadata
  rules:
  - expr: "1"
    labels:
      component: cgroup_memory
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: gitaly_total_disk_space
      horiz_scaling: "yes"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: kube_container_cpu
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: kube_container_memory
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: kube_go_memory
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: kube_persistent_volume_claim_disk_space
      horiz_scaling: "yes"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: kube_persistent_volume_claim_inodes
      horiz_scaling: "yes"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: kube_pool_cpu
      horiz_scaling: "yes"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: kube_pool_max_nodes
      horiz_scaling: "yes"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: open_fds
      horiz_scaling: "yes"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_active_db_connections_primary
      horiz_scaling: "no"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_active_db_connections_replica
      horiz_scaling: "yes"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_btree_bloat
      horiz_scaling: "no"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_int4_id
      horiz_scaling: "no"
      severity: s1
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_primary_cpu
      horiz_scaling: "no"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_table_bloat
      horiz_scaling: "no"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_vacuum_activity
      horiz_scaling: "yes"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_walsender_cpu
      horiz_scaling: "no"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pg_xid_wraparound
      horiz_scaling: "no"
      severity: s1
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pgbouncer_async_primary_pool
      horiz_scaling: "no"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pgbouncer_async_replica_pool
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pgbouncer_client_conn
      horiz_scaling: "yes"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pgbouncer_single_core
      horiz_scaling: "yes"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pgbouncer_sync_primary_pool
      horiz_scaling: "no"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pgbouncer_sync_replica_pool
      horiz_scaling: "yes"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: praefect_cloudsql_cpu
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: private_runners
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: pvs_cloudrun_container_instances
      horiz_scaling: "yes"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: rails_db_connection_pool
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: redis_clients
      horiz_scaling: "no"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: redis_memory
      horiz_scaling: "no"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: redis_memory_tracechunks
      horiz_scaling: "no"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: redis_primary_cpu
      horiz_scaling: "no"
      severity: s1
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: redis_secondary_cpu
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: ruby_thread_contention
      horiz_scaling: "yes"
      severity: s3
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: shared_runners
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: shared_runners_gitlab
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: single_node_puma_workers
      horiz_scaling: "yes"
      severity: s2
    record: gitlab_component_saturation_info
  - expr: "1"
    labels:
      component: workhorse_image_scaling
      horiz_scaling: "yes"
      severity: s4
    record: gitlab_component_saturation_info
- interval: 5m
  name: GitLab Component Saturation Statistics
  rules:
  - expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{monitor="global"}[1w])
    record: gitlab_component_saturation:ratio_quantile95_1w
  - expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{monitor="global"}[1w])
    record: gitlab_component_saturation:ratio_quantile99_1w
  - expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{monitor="global"}[1h])
    record: gitlab_component_saturation:ratio_quantile95_1h
  - expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{monitor="global"}[1h])
    record: gitlab_component_saturation:ratio_quantile99_1h
  - expr: avg_over_time(gitlab_component_saturation:ratio{monitor="global"}[1h])
    record: gitlab_component_saturation:ratio_avg_1h
- interval: 1m
  name: GitLab Saturation Alerts
  rules:
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cgroup Memory Utilization per Node resource:

        Cgroup memory utilization per node.

        Some services, notably Gitaly, are configured to run within a cgroup with a memory limit lower than the memory limit for the node. This ensures that a traffic spike to Gitaly does not affect other services on the node.

        If this resource is becoming saturated, this may indicate traffic spikes to Gitaly, abuse or possibly resource leaks in the application. Gitaly or other git processes may be killed by the OOM killer when this resource is saturated.
      grafana_dashboard_id: alerts-sat_cgroup_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cgroup_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2265664609"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_cache{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_swap{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Cgroup Memory Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="cgroup_memory",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cgroup_memory",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Gitaly Total Disk Utilization resource:

        Gitaly Total Disk Utilization.

        This saturation metric monitors the total available capacity across the entire Gitaly fleet. By ensuring that we keep sufficient headroom on the saturation resource, we are able to spread load across the fleet.

        When this alert fires, consider adding new Gitaly nodes. The [Gitaly Capacity Planner](https://dashboards.gitlab.net/d/alerts-gitaly_capacity_planner/alerts-gitaly-capacity-planner?orgId=1) dashboard can help determine how many new nodes will be needed.
      grafana_dashboard_id: alerts-sat_gitaly_total_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_gitaly_total_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "998219612"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, shard) (
          clamp_min(
            clamp_max(
              1 - (
                sum by (environment, tier, type, stage, shard) (
                  node_filesystem_avail_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", device="/dev/sdb"}
                )
                /
                sum by (environment, tier, type, stage, shard) (
                  node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", device="/dev/sdb"}
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Gitaly Total Disk Utilization resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="gitaly_total_disk_space",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gitaly_total_disk_space",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Container CPU Utilization resource:

        Kubernetes containers are allocated a share of CPU. When this is exhausted, the container may be thottled.
      grafana_dashboard_id: alerts-sat_kube_container_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_container_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2713861591"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, pod, container) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, pod, container) (
                rate(container_cpu_usage_seconds_total:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              /
              sum by(environment, tier, type, stage, pod, container) (
                container_spec_cpu_quota:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                container_spec_cpu_period:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Kube Container CPU Utilization resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_container_cpu",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_container_cpu",monitor="global"}
    for: 15m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Container Memory Utilization resource:

        Records the total memory utilization for containers for this service, as a percentage of the memory limit as configured through Kubernetes.
      grafana_dashboard_id: alerts-sat_kube_container_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_container_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "172578411"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, pod, container) (
          clamp_min(
            clamp_max(
              container_memory_working_set_bytes:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              /
              (container_spec_memory_limit_bytes:labeled{container!="", container!="POD", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} > 0)
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Kube Container Memory Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_container_memory",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_container_memory",monitor="global"}
    for: 15m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Go Memory Utilization per Node resource:

        Measures Go memory usage as a percentage of container memory limit
      grafana_dashboard_id: alerts-sat_kube_go_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_go_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4163523952"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, cluster, pod) (
          clamp_min(
            clamp_max(
              (
                go_memstats_alloc_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                / on(environment, tier, type, stage, cluster, pod) group_left()
                topk by(environment, tier, type, stage, cluster, pod) (1,
                  container_spec_memory_limit_bytes:labeled{container=~"gitlab-workhorse|kas|registry|thanos-store",environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                )
              )
              or
              (
                go_memstats_alloc_bytes{type="monitoring", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                / on(environment, tier, type, cluster, pod) group_left()
                topk by (environment, tier, type, cluster, pod) (1,
                  container_spec_memory_limit_bytes:labeled{type="monitoring", container=~"gitlab-workhorse|kas|registry|thanos-store"}
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Go Memory Utilization per Node resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_go_memory",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_go_memory",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Persistent Volume Claim Space Utilisation resource:

        disk space utilization on persistent volume claims.
      grafana_dashboard_id: alerts-sat_kube_pvc_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pvc_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4167694322"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, cluster, namespace, persistentvolumeclaim) (
          clamp_min(
            clamp_max(
              kubelet_volume_stats_used_bytes
              /
              kubelet_volume_stats_capacity_bytes
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Kube Persistent Volume Claim Space Utilisation resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage), component has a saturation
        exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_disk_space",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_disk_space",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Persistent Volume Claim inode Utilisation resource:

        inode utilization on persistent volume claims.
      grafana_dashboard_id: alerts-sat_kube_pvc_inodes
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pvc_inodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3153876074"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, persistentvolumeclaim) (
          clamp_min(
            clamp_max(
              kubelet_volume_stats_inodes_used
              /
              kubelet_volume_stats_inodes
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Kube Persistent Volume Claim inode Utilisation resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage), component has a saturation
        exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_inodes",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_inodes",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average Node Pool CPU Utilization resource:

        This resource measures average CPU utilization across an all cores in the node pool for a service fleet.

        If it is becoming saturated, it may indicate that the fleet needs horizontal scaling.
      grafana_dashboard_id: alerts-sat_kube_pool_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pool_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1839360107"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              1 - avg by (environment, tier, type, stage) (
                rate(node_cpu_seconds_total:labeled{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Average Node Pool CPU Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_pool_cpu",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_pool_cpu",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Pool Max Node Limit resource:

        A GKE kubernetes node pool is close to it's maximum number of nodes.

        The maximum is defined in terraform, via the `max_node_count` field of a node pool. The limit is per-zone, so for single zone clusters the number of nodes will match the limit, for regional clusters, the limit is multiplied by the number of zones the cluster is deployed over.
      grafana_dashboard_id: alerts-sat_kube_pool_max_nodes
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_kube_pool_max_nodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1686893332"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(env, environment, tier, type, stage, cluster, label_pool, shard) (
          clamp_min(
            clamp_max(
              count by (cluster, env, environment, label_pool, tier, type, stage, shard) (
                kube_node_labels:labeled{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              / on(cluster, env, environment, label_pool) group_left() (
                label_replace(
                  terraform_report_google_cluster_node_pool_max_node_count,
                  "label_pool", "$0", "pool_name", ".*"
                )
                * on(cluster, env, environment) group_left()
                count by (cluster, env, environment) (
                  group by (cluster, env, environment, label_topology_kubernetes_io_zone) (
                    kube_node_labels:labeled{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                  )
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Kube Pool Max Node Limit resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="kube_pool_max_nodes",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_pool_max_nodes",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Open file descriptor utilization per instance resource:

        Open file descriptor utilization per instance.

        Saturation on file descriptor limits may indicate a resource-descriptor leak in the application.

        As a temporary fix, you may want to consider restarting the affected process.
      grafana_dashboard_id: alerts-sat_open_fds
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_open_fds?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1001792825"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, job, instance) (
          clamp_min(
            clamp_max(
              (
                process_open_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              or
              (
                ruby_file_descriptors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                ruby_process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Open file descriptor utilization per instance resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage), component has a saturation
        exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="open_fds",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="open_fds",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Active Primary DB Connection Utilization resource:

        Active db connection utilization on the primary node.

        Postgres is configured to use a maximum number of connections. When this resource is saturated, connections may queue.
      grafana_dashboard_id: alerts-sat_active_db_connections_primary
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_active_db_connections_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1954311497"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum without (state) (
                pg_stat_activity_count{datname="gitlabhq_production", state!="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} unless on(instance) (pg_replication_is_replica == 1)
              )
              / on (environment, tier, type, stage, fqdn)
              pg_settings_max_connections{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Active Primary DB Connection Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_active_db_connections_primary",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_active_db_connections_primary",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Active Secondary DB Connection Utilization resource:

        Active db connection utilization per replica node

        Postgres is configured to use a maximum number of connections. When this resource is saturated, connections may queue.
      grafana_dashboard_id: alerts-sat_active_db_connections_replica
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_active_db_connections_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3266646533"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum without (state) (
                pg_stat_activity_count{datname="gitlabhq_production", state!="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} and on(instance) (pg_replication_is_replica == 1)
              )
              / on (environment, tier, type, stage, fqdn)
              pg_settings_max_connections{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Active Secondary DB Connection Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_active_db_connections_replica",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_active_db_connections_replica",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres btree bloat resource:

        This measures the total bloat in Postgres Btree indexes, as a percentage of total index size.

        The larger this measure, the more pages will unnecessarily be retrieved during index scans.
      grafana_dashboard_id: alerts-sat_pg_btree_bloat
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_btree_bloat?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2387842464"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_bloat_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              /
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_btree_real_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres btree bloat resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage), component has a saturation exceeding SLO and is close
        to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_btree_bloat",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_btree_bloat",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres int4 ID capacity resource:

        This measures used int4 primary key capacity in selected postgres tables. It is critically important that we do not reach saturation on this as GitLab will stop to work at this point.
      grafana_dashboard_id: alerts-sat_pg_int4_id
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_int4_id?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3254820333"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, table_name) (
          clamp_min(
            clamp_max(
              max by (environment, tier, type, stage, table_name) (
                pg_integer_capacity_current{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                pg_integer_capacity_maximum{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres int4 ID capacity resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_int4_id",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_int4_id",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization on Postgres Primary Instance resource:

        Average CPU utilization across all cores on the Postgres primary instance.
      grafana_dashboard_id: alerts-sat_pg_primary_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_primary_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3989464622"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(env, environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg without(cpu, mode) (
                1
                -
                (
                  rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                  and on(fqdn)
                  pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Average CPU Utilization on Postgres Primary Instance resource of
        the {{ $labels.type }} service ({{ $labels.stage }} stage), component has
        a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_primary_cpu",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_primary_cpu",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Table Bloat resource:

        This measures the total bloat in Postgres Table pages, as a percentage of total size. This includes bloat in TOAST tables, and excludes extra space reserved due to fillfactor.
      grafana_dashboard_id: alerts-sat_pg_table_bloat
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_table_bloat?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "773890326"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_bloat_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              /
              sum by (environment, tier, type, stage, fqdn) (avg_over_time(gitlab_database_bloat_table_real_size{job="gitlab-monitor-database-bloat", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[58m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres Table Bloat resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage), component has a saturation exceeding SLO and is close
        to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_table_bloat",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_table_bloat",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Autovacuum Activity resource:

        Measures the number of active autovacuum workers, as a percentage of the maximum, configured via the `autovacuum_max_workers` setting.

        If this is saturated for a sustained period, it may indicate that postgres is struggling to keep up with vacuum activity.

        This could ultimately lead to a transaction ID wraparound situation: see https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/patroni/pg_xid_wraparound_alert.md
      grafana_dashboard_id: alerts-sat_pg_vacuum_activity
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_vacuum_activity?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1494397745"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              (
                sum by (environment, tier, type, stage) (
                  avg_over_time(pg_stat_activity_autovacuum_active_workers_count{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
                  and on (instance, job) (pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0)
                )
                or
                clamp_max(
                  group by (environment, tier, type, stage) (
                    pg_settings_autovacuum_max_workers{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                    and on (instance, job) (pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0)
                  ),
                0)
              )
              /
              avg by (environment, tier, type, stage) (
                pg_settings_autovacuum_max_workers{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                and on (instance, job) (pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0)
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres Autovacuum Activity resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_vacuum_activity",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_vacuum_activity",monitor="global"}
    for: 60m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Walsender CPU Saturation resource:

        This saturation metric measures the total amount of time that the primary postgres instance is spending sending WAL segments to replicas. It is expressed as a percentage of all CPU available on the primary postgres instance.

        The more replicas connected, the higher this metric will be.

        Since it's expressed as a percentage of all CPU, this should always remain low, since the CPU primarily needs to be available for handling SQL statements.
      grafana_dashboard_id: alerts-sat_pg_walsender_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_walsender_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1879384722"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(env, environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              sum by (env, environment, tier, type, stage) (
                sum by(env, environment, tier, type, stage, fqdn) (
                  rate(namedprocess_namegroup_cpu_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", groupname=~"pg.worker.walsender|pg.worker.walwriter|wal-g"}[5m])
                  and on (fqdn) (pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0)
                )
                /
                count by (env, environment, tier, type, stage, fqdn) (
                  node_cpu_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", mode="idle"} and on(fqdn) (pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0)
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Walsender CPU Saturation resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_walsender_cpu",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_walsender_cpu",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Transaction ID Wraparound resource:

        Risk of DB shutdown in the near future, approaching transaction ID wraparound.

        This is a critical situation.

        This saturation metric measures how close the database is to Transaction ID wraparound.

        When wraparound occurs, the database will automatically shutdown to prevent data loss, causing a full outage.

        Recovery would require entering single-user mode to run vacuum, taking the site down for a potentially multi-hour maintenance session.

        To avoid reaching the db shutdown threshold, consider the following short-term actions:

        1. Escalate to the SRE Datastores team, and then,

        2. Find and terminate any very old transactions. The runbook for this alert has details.  Do this first.  It is the most critical step and may be all that is necessary to let autovacuum do its job.

        3. Run a manual vacuum on tables with oldest relfrozenxid.  Manual vacuums run faster than autovacuum.

        4. Add autovacuum workers or reduce autovacuum cost delay, if autovacuum is chronically unable to keep up with the transaction rate.

        Long running transaction dashboard: https://dashboards.gitlab.net/d/alerts-long_running_transactions/alerts-long-running-transactions?orgId=1
      grafana_dashboard_id: alerts-sat_pg_xid_wraparound
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pg_xid_wraparound?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3666116359"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, datname) (
          clamp_min(
            clamp_max(
              (
                max without (series) (
                  label_replace(pg_database_wraparound_age_datfrozenxid{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "series", "datfrozenxid", "", "")
                  or
                  label_replace(pg_database_wraparound_age_datminmxid{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "series", "datminmxid", "", "")
                )
                and on (instance, job) (pg_replication_is_replica{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} == 0)
              )
              /
              (2^31 - 10^6)
              ,
              1)
          ,
          0)
        )
      runbook: docs/patroni/pg_xid_wraparound_alert.md
      title: The Transaction ID Wraparound resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pg_xid_wraparound",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_xid_wraparound",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Async (Sidekiq) primary Connection Pool Utilization per Node resource:

        pgbouncer async connection pool utilization per database node, for primary database connections.

        Sidekiq maintains it's own pgbouncer connection pool. When this resource is saturated, database operations may queue, leading to additional latency in background processing.
      grafana_dashboard_id: alerts-sat_pgbouncer_async_pool_primary
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_async_pool_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1228921753"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres Async (Sidekiq) primary Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage),
        component has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_async_primary_pool",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_async_primary_pool",monitor="global"}
    for: 10m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Async (Sidekiq) replica Connection Pool Utilization per Node resource:

        pgbouncer async connection pool utilization per database node, for replica database connections.

        Sidekiq maintains it's own pgbouncer connection pool. When this resource is saturated, database operations may queue, leading to additional latency in background processing.
      grafana_dashboard_id: alerts-sat_pgbouncer_async_pool_replica
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_async_pool_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4069682945"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres Async (Sidekiq) replica Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage),
        component has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_async_replica_pool",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_async_replica_pool",monitor="global"}
    for: 10m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the PGBouncer Client Connections per Process resource:

        Client connections per pgbouncer process.

        pgbouncer is configured to use a `max_client_conn` setting. This limits the total number of client connections per pgbouncer.

        When this limit is reached, client connections may be refused, and `max_client_conn` errors may appear in the pgbouncer logs.

        This could affect users as Rails clients are left unable to connect to the database. Another potential knock-on effect is that Rails clients could fail their readiness checks for extended periods during a deployment, leading to saturation of the older nodes.
      grafana_dashboard_id: alerts-sat_pgbouncer_client_conn
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_client_conn?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1258049746"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg_over_time(pgbouncer_used_clients {environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              /
              8192
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The PGBouncer Client Connections per Process resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_client_conn",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_client_conn",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the PGBouncer Single Core per Node resource:

        PGBouncer single core CPU utilization per node.

        PGBouncer is a single threaded application. Under high volumes this resource may become saturated, and additional pgbouncer nodes may need to be provisioned.
      grafana_dashboard_id: alerts-sat_pgbouncer_single_core
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_single_core?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1214397558"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, groupname) (
          clamp_min(
            clamp_max(
              sum without(cpu, mode) (
                rate(
                  namedprocess_namegroup_cpu_seconds_total{groupname=~"pgbouncer.*", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The PGBouncer Single Core per Node resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_single_core",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_single_core",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Sync (Web/API/Git) primary Connection Pool Utilization per Node resource:

        pgbouncer sync connection pool Saturation per database node, for primary database connections.

        Web/api/git applications use a separate connection pool to sidekiq.

        When this resource is saturated, web/api database operations may queue, leading to rails worker saturation and 503 errors in the web.
      grafana_dashboard_id: alerts-sat_pgbouncer_sync_pool_primary
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_sync_pool_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4055772849"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres Sync (Web/API/Git) primary Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage),
        component has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_sync_primary_pool",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_sync_primary_pool",monitor="global"}
    for: 10m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Sync (Web/API/Git) replica Connection Pool Utilization per Node resource:

        pgbouncer sync connection pool Saturation per database node, for replica database connections.

        Web/api/git applications use a separate connection pool to sidekiq.

        When this resource is saturated, web/api database operations may queue, leading to rails worker saturation and 503 errors in the web.
      grafana_dashboard_id: alerts-sat_pgbouncer_sync_pool_replica
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_sync_pool_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2061891964"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Postgres Sync (Web/API/Git) replica Connection Pool Utilization per
        Node resource of the {{ $labels.type }} service ({{ $labels.stage }} stage),
        component has a saturation exceeding SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_sync_replica_pool",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_sync_replica_pool",monitor="global"}
    for: 10m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization resource:

        Average CPU utilization.

        See https://cloud.google.com/monitoring/api/metrics_gcp#gcp-cloudsql for more details
      grafana_dashboard_id: alerts-sat_praefect_cloudsql_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_praefect_cloudsql_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3679713436"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, database_id) (
          clamp_min(
            clamp_max(
              avg_over_time(stackdriver_cloudsql_database_cloudsql_googleapis_com_database_cpu_utilization{database_id=~".+:praefect-db.+", environment="{{ $labels.environment }}"}[5m])
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Average CPU Utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="praefect_cloudsql_cpu",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="praefect_cloudsql_cpu",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Private Runners utilization resource:

        Private runners utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_private_runners
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_private_runners?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "204635596"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state) (
                max_over_time(gitlab_runner_jobs{job="runners-manager",shard="private"}[1m])
              )
              /
              gitlab_runner_limit{job="runners-manager",shard="private"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Private Runners utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="private_runners",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="private_runners",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cloud Run Container Instance Utilization resource:

        Cloud Run is configured with a maximum number of container instances. When this is saturated, Google Cloud Run will no longer scale up.

        More information available at https://cloud.google.com/run/docs/configuring/max-instances.
      grafana_dashboard_id: alerts-sat_pvs_cloudrun_ctr_instances
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_pvs_cloudrun_ctr_instances?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "754592114"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, state) (
          clamp_min(
            clamp_max(
              sum by (environment, state) (
                stackdriver_cloud_run_revision_run_googleapis_com_container_instance_count{
                  configuration_name="pipeline-validation-service",
                  environment="{{ $labels.environment }}"
                }
              )
              /
              100
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Cloud Run Container Instance Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="pvs_cloudrun_container_instances",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pvs_cloudrun_container_instances",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Rails DB Connection Pool Utilization resource:

        Rails uses connection pools for its database connections. As each node may have multiple connection pools, this is by node and by database host.

        Read more about this resource in our [documentation](https://docs.gitlab.com/ee/development/database/client_side_connection_pool.html#client-side-connection-pool).

        If this resource is saturated, it may indicate that our connection pools are not correctly sized, perhaps because an unexpected application thread is using a database connection.
      grafana_dashboard_id: alerts-sat_rails_db_connection_pool
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_rails_db_connection_pool?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "391047339"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, instance, host, port) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(gitlab_database_connection_pool_busy{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                +
                avg_over_time(gitlab_database_connection_pool_dead{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              /
              gitlab_database_connection_pool_size{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Rails DB Connection Pool Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="rails_db_connection_pool",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="rails_db_connection_pool",monitor="global"}
    for: 15m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Client Utilization per Node resource:

        Redis client utilization per node.

        A redis server has a maximum number of clients that can connect. When this resource is saturated, new clients may fail to connect.

        More details at https://redis.io/topics/clients#maximum-number-of-clients
      grafana_dashboard_id: alerts-sat_redis_clients
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_clients?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "127397613"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max_over_time(redis_connected_clients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              /
              redis_config_maxclients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Redis Client Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="redis_clients",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_clients",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Memory Utilization per Node resource:

        Redis memory utilization per node.

        As Redis memory saturates node memory, the likelyhood of OOM kills, possibly to the Redis process, become more likely.

        For caches, consider lowering the `maxmemory` setting in Redis. For non-caching Redis instances, this has been caused in the past by credential stuffing, leading to large numbers of web sessions.

        This threshold is kept deliberately low, since Redis RDB snapshots could consume a significant amount of memory, especially when the rate of change in Redis is high, leading to copy-on-write consuming more memory than when the rate-of-change is low.
      grafana_dashboard_id: alerts-sat_redis_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1855027052"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max by (environment, tier, type, stage, fqdn) (
                label_replace(redis_memory_used_rss_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "rss","","")
                or
                label_replace(redis_memory_used_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "used","","")
              )
              /
              avg by (environment, tier, type, stage, fqdn) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Redis Memory Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="redis_memory",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_memory",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Memory Utilization per Node resource:

        Redis memory utilization per node.

        As Redis memory saturates node memory, the likelyhood of OOM kills, possibly to the Redis process, become more likely.

        Trace chunks should be extremely transient (written to redis, then offloaded to objectstorage nearly immediately) so any uncontrolled growth in memory saturation implies a potentially significant problem.  Short term mitigation is usually to upsize the instances to have more memory while the underlying problem is identified, but low thresholds give us more time to investigate first

        This threshold is kept deliberately very low; because we use C2 instances we are generally overprovisioned for RAM, and because of the transient nature of the data here, it is advantageous to know early if there is any non-trivial storage occurring
      grafana_dashboard_id: alerts-sat_redis_memory_tracechunks
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_memory_tracechunks?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3185191014"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max by (environment, tier, type, stage, fqdn) (
                label_replace(redis_memory_used_rss_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "rss","","")
                or
                label_replace(redis_memory_used_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "used","","")
              )
              /
              avg by (environment, tier, type, stage, fqdn) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Redis Memory Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="redis_memory_tracechunks",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_memory_tracechunks",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Primary CPU Utilization per Node resource:

        Redis Primary CPU Utilization per Node.

        The core server of redis is single-threaded; this thread is only able to scale to full use of a single CPU on a given server. When the primary Redis thread is saturated, major slowdowns should be expected across the application, so avoid if at all possible.
      grafana_dashboard_id: alerts-sat_redis_primary_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_primary_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4143300761"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, fqdn) (
                rate(
                  namedprocess_namegroup_thread_cpu_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", groupname="redis-server", threadname="redis-server"}[1m])
              )
              and on (fqdn) redis_instance_info{role="master"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Redis Primary CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="redis_primary_cpu",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_primary_cpu",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Secondary CPU Utilization per Node resource:

        Redis Secondary CPU Utilization per Node.

        Redis is single-threaded. A single Redis server is only able to scale as far as a single CPU on a single host. CPU saturation on a secondary is not as serious as critical as saturation on a primary, but could lead to replication delays.
      grafana_dashboard_id: alerts-sat_redis_secondary_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_redis_secondary_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "577905942"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                rate(redis_cpu_user_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
                +
                rate(redis_cpu_sys_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              )
              and on (instance) redis_instance_info{role!="master"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Redis Secondary CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="redis_secondary_cpu",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_secondary_cpu",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Ruby Thread Contention resource:

        Ruby (technically Ruby MRI), like some other scripting languages, uses a Global VM lock (GVL) also known as a Global Interpreter Lock (GIL) to ensure that multiple threads can execute safely. Ruby code is only allowed to execute in one thread in a process at a time. When calling out to c extensions, the thread can cede the lock to other thread while it continues to execute.

        This means that when CPU-bound workloads run in a multithreaded environment such as Puma or Sidekiq, contention with other Ruby worker threads running in the same process can occur, effectively slowing thoses threads down as they await GVL entry.

        Often the best fix for this situation is to add more workers by scaling up the fleet.
      grafana_dashboard_id: alerts-sat_ruby_thread_contention
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_ruby_thread_contention?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2359646072"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, pod) (
          clamp_min(
            clamp_max(
              rate(ruby_process_cpu_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m])
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Ruby Thread Contention resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="ruby_thread_contention",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="ruby_thread_contention",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Shared Runner utilization resource:

        Shared runner utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_shared_runners
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_shared_runners?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2853615952"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state, runner) (
                max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared"}[1m])
              )
              /
              gitlab_runner_concurrent{job="runners-manager",shard="shared"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Shared Runner utilization resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and
        is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="shared_runners",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shared_runners",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Shared Runner GitLab Utilization resource:

        Shared runners utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_shared_runners_gitlab
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_shared_runners_gitlab?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3295582630"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state) (
                max_over_time(gitlab_runner_jobs{job="runners-manager",shard="shared-gitlab-org"}[1m])
              )
              /
              gitlab_runner_limit{job="runners-manager",shard="shared-gitlab-org"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Shared Runner GitLab Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="shared_runners_gitlab",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shared_runners_gitlab",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Puma Worker Saturation per Node resource:

        Puma thread utilization per node.

        Puma uses a fixed size thread pool to handle HTTP requests. This metric shows how many threads are busy handling requests. When this resource is saturated, we will see puma queuing taking place. Leading to slowdowns across the application.

        Puma saturation is usually caused by latency problems in downstream services: usually Gitaly or Postgres, but possibly also Redis. Puma saturation can also be caused by traffic spikes.
      grafana_dashboard_id: alerts-sat_single_node_puma_workers
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_single_node_puma_workers?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2677029523"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by(environment, tier, type, stage, fqdn) (avg_over_time(instance:puma_active_connections:sum{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m]))
              /
              sum by(environment, tier, type, stage, fqdn) (instance:puma_max_threads:sum{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"})
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Puma Worker Saturation per Node resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="single_node_puma_workers",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="single_node_puma_workers",monitor="global"}
    for: 5m
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
  - alert: component_saturation_slo_out_of_bounds
    annotations:
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Workhorse Image Scaler Exhaustion per Node resource:

        Workhorse can scale images on-the-fly as requested. Since the actual work will be performed by dedicated processes, we currently define a hard cap for how many such requests are allowed to be in the system concurrently.

        If this resource is fully saturated, Workhorse will start ignoring image scaling requests and serve the original image instead, which will ensure continued operation, but comes at the cost of additional client latency and GCS egress traffic.
      grafana_dashboard_id: alerts-sat_wh_image_scaling
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_wh_image_scaling?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3379320113"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg_over_time(gitlab_workhorse_image_resize_processes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                /
              gitlab_workhorse_image_resize_max_processes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
      title: The Workhorse Image Scaler Exhaustion per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding
        SLO and is close to its capacity limit.
    expr: |
      gitlab_component_saturation:ratio{component="workhorse_image_scaling",monitor="global"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="workhorse_image_scaling",monitor="global"}
    for: 15m
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
