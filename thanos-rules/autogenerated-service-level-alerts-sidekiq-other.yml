# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./thanos-rules-jsonnet/service-component-alerts.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: 'Service Component Alerts: sidekiq'
  interval: 1m
  partial_response_strategy: warn
  rules:
  - alert: SidekiqServiceEmailReceiverErrorSLOViolation
    for: 2m
    annotations:
      title: The email_receiver SLI of the sidekiq service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "212053046"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_transaction_event_email_receiver_error_total{environment="{{ $labels.environment }}",error!="Gitlab::Email::AutoGeneratedEmailError",stage="{{ $labels.stage }}",type="sidekiq"}[5m])
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="email_receiver",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (14.4 * 0.300000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="email_receiver",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (14.4 * 0.300000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="email_receiver",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 1
      )
  - alert: SidekiqServiceEmailReceiverErrorSLOViolation
    for: 2m
    annotations:
      title: The email_receiver SLI of the sidekiq service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "212053046"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_transaction_event_email_receiver_error_total{environment="{{ $labels.environment }}",error!="Gitlab::Email::AutoGeneratedEmailError",stage="{{ $labels.stage }}",type="sidekiq"}[5m])
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="email_receiver",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (6 * 0.300000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="email_receiver",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (6 * 0.300000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="email_receiver",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 0.16667
      )
  - alert: SidekiqServiceEmailReceiverTrafficCessation
    for: 5m
    annotations:
      title: The email_receiver SLI of the sidekiq service (`{{ $labels.stage }}`
        stage) has not received any traffic in the past 30m
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1545803555"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(sidekiq_jobs_completion_seconds_count{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="sidekiq",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_30m{component="email_receiver",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} == 0
      and
      gitlab_component_ops:rate_30m{component="email_receiver",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} offset 1h >= 0.16666666666666666
  - alert: SidekiqServiceEmailReceiverTrafficAbsent
    for: 30m
    annotations:
      title: The email_receiver SLI of the sidekiq service (`{{ $labels.stage }}`
        stage) has not reported any traffic in the past 30m
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1545803555"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(sidekiq_jobs_completion_seconds_count{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="sidekiq",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_5m{component="email_receiver",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="email_receiver",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"}
  - alert: SidekiqServiceExternalDependencyApdexSLOViolation
    for: 2m
    annotations:
      title: The external_dependency SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        Jobs with external dependencies across all shards.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1721761175"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="throttled"}
          )
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 1
      )
  - alert: SidekiqServiceExternalDependencyApdexSLOViolation
    for: 2m
    annotations:
      title: The external_dependency SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        Jobs with external dependencies across all shards.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1721761175"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="high"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_queue_duration_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="low"}
            or
            sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq",urgency="throttled"}
          )
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 0.16667
      )
  - alert: SidekiqServiceExternalDependencyErrorSLOViolation
    for: 2m
    annotations:
      title: The external_dependency SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has an error rate violating SLO
      description: |
        Jobs with external dependencies across all shards.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "415398530"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          sli_aggregations:sidekiq_jobs_failed_total_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (14.4 * 0.100000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (14.4 * 0.100000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 1
      )
  - alert: SidekiqServiceExternalDependencyErrorSLOViolation
    for: 2m
    annotations:
      title: The external_dependency SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has an error rate violating SLO
      description: |
        Jobs with external dependencies across all shards.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "415398530"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          sli_aggregations:sidekiq_jobs_failed_total_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (6 * 0.100000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (6 * 0.100000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="external_dependency",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 0.16667
      )
  - alert: SidekiqServiceExternalDependencyTrafficCessation
    for: 5m
    annotations:
      title: The external_dependency SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has not received any traffic in the past 30m
      description: |
        Jobs with external dependencies across all shards.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "705339951"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",le="+Inf",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_30m{component="external_dependency",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} == 0
      and
      gitlab_component_ops:rate_30m{component="external_dependency",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} offset 1h >= 0.16666666666666666
  - alert: SidekiqServiceExternalDependencyTrafficAbsent
    for: 30m
    annotations:
      title: The external_dependency SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has not reported any traffic in the past 30m
      description: |
        Jobs with external dependencies across all shards.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "705339951"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          sli_aggregations:sidekiq_jobs_completion_seconds_bucket_rate5m{environment="{{ $labels.environment }}",external_dependencies="yes",le="+Inf",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_5m{component="external_dependency",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="external_dependency",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"}
  - alert: SidekiqServiceGlobalSearchIndexingApdexSLOViolation
    for: 2m
    annotations:
      title: The global_search_indexing SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        The number of Global Search indexing calls meeting their duration target based on the 99.95th percentile of indexing. This indicates the duration between when an item was changed and when it became available in Elasticsearch.

        The target duration can be found here: https://gitlab.com/gitlab-org/gitlab/-/blob/master/ee/lib/gitlab/metrics/global_search_indexing_slis.rb#L14-L15

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4092777115"
      grafana_variables: environment,stage
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: global_search
      rules_domain: general
      severity: s3
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="global_search_indexing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_5m{component="global_search_indexing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="global_search_indexing",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 1
      )
  - alert: SidekiqServiceGlobalSearchIndexingApdexSLOViolation
    for: 2m
    annotations:
      title: The global_search_indexing SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        The number of Global Search indexing calls meeting their duration target based on the 99.95th percentile of indexing. This indicates the duration between when an item was changed and when it became available in Elasticsearch.

        The target duration can be found here: https://gitlab.com/gitlab-org/gitlab/-/blob/master/ee/lib/gitlab/metrics/global_search_indexing_slis.rb#L14-L15

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4092777115"
      grafana_variables: environment,stage
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: global_search
      rules_domain: general
      severity: s3
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="global_search_indexing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
        and
        (
          gitlab_component_apdex:ratio_30m{component="global_search_indexing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="global_search_indexing",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 0.16667
      )
  - alert: SidekiqServiceGlobalSearchIndexingTrafficCessation
    for: 5m
    annotations:
      title: The global_search_indexing SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has not received any traffic in the past 30m
      description: |
        The number of Global Search indexing calls meeting their duration target based on the 99.95th percentile of indexing. This indicates the duration between when an item was changed and when it became available in Elasticsearch.

        The target duration can be found here: https://gitlab.com/gitlab-org/gitlab/-/blob/master/ee/lib/gitlab/metrics/global_search_indexing_slis.rb#L14-L15

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2184528438"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_global_search_indexing_apdex_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="sidekiq"}[5m])
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: global_search
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_30m{component="global_search_indexing",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} == 0
      and
      gitlab_component_ops:rate_30m{component="global_search_indexing",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} offset 1h >= 0.16666666666666666
  - alert: SidekiqServiceGlobalSearchIndexingTrafficAbsent
    for: 30m
    annotations:
      title: The global_search_indexing SLI of the sidekiq service (`{{ $labels.stage
        }}` stage) has not reported any traffic in the past 30m
      description: |
        The number of Global Search indexing calls meeting their duration target based on the 99.95th percentile of indexing. This indicates the duration between when an item was changed and when it became available in Elasticsearch.

        The target duration can be found here: https://gitlab.com/gitlab-org/gitlab/-/blob/master/ee/lib/gitlab/metrics/global_search_indexing_slis.rb#L14-L15

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2184528438"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_global_search_indexing_apdex_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="sidekiq"}[5m])
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: global_search
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_5m{component="global_search_indexing",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="global_search_indexing",env!~"gprd|ops",monitor="global",stage="main",type="sidekiq"}
  - alert: SidekiqServiceSidekiqExecutionApdexSLOViolationSingleShard
    for: 10m
    annotations:
      title: The sidekiq_execution SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has an apdex violating SLO
      description: |
        The number of Sidekiq jobs meeting their execution duration target based on the urgency of the worker. By default, execution of a job should take no more than 300 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1200908149"
      grafana_variables: environment,stage,shard
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: slo_violation
      alert_type: symptom
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_shard_apdex:ratio_1h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
        and
        (
          gitlab_component_shard_apdex:ratio_5m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,shard,component)
      (
        sum by(env,environment,tier,type,stage,shard,component) (gitlab_component_shard_ops:rate_1h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 1
      )
  - alert: SidekiqServiceSidekiqExecutionApdexSLOViolationSingleShard
    for: 10m
    annotations:
      title: The sidekiq_execution SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has an apdex violating SLO
      description: |
        The number of Sidekiq jobs meeting their execution duration target based on the urgency of the worker. By default, execution of a job should take no more than 300 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1200908149"
      grafana_variables: environment,stage,shard
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: slo_violation
      alert_type: symptom
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_shard_apdex:ratio_6h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
        and
        (
          gitlab_component_shard_apdex:ratio_30m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,shard,component)
      (
        sum by(env,environment,tier,type,stage,shard,component) (gitlab_component_shard_ops:rate_6h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 0.16667
      )
  - alert: SidekiqServiceSidekiqExecutionErrorSLOViolationSingleShard
    for: 10m
    annotations:
      title: The sidekiq_execution SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has an error rate violating SLO
      description: |
        The number of Sidekiq jobs meeting their execution duration target based on the urgency of the worker. By default, execution of a job should take no more than 300 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4267233911"
      grafana_variables: environment,stage,shard
      promql_template_1: |
        sum by (env,environment,tier,stage,shard) (
          sli_aggregations:gitlab_sli_sidekiq_execution_error_total_rate5m{environment="{{ $labels.environment }}",external_dependencies!="yes",shard="{{ $labels.shard }}",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: slo_violation
      alert_type: symptom
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_shard_errors:ratio_1h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (14.4 * 0.005000)
        )
        and
        (
          gitlab_component_shard_errors:ratio_5m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (14.4 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,shard,component)
      (
        sum by(env,environment,tier,type,stage,shard,component) (gitlab_component_shard_ops:rate_1h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 1
      )
  - alert: SidekiqServiceSidekiqExecutionErrorSLOViolationSingleShard
    for: 10m
    annotations:
      title: The sidekiq_execution SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has an error rate violating SLO
      description: |
        The number of Sidekiq jobs meeting their execution duration target based on the urgency of the worker. By default, execution of a job should take no more than 300 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4267233911"
      grafana_variables: environment,stage,shard
      promql_template_1: |
        sum by (env,environment,tier,stage,shard) (
          sli_aggregations:gitlab_sli_sidekiq_execution_error_total_rate5m{environment="{{ $labels.environment }}",external_dependencies!="yes",shard="{{ $labels.shard }}",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: slo_violation
      alert_type: symptom
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_shard_errors:ratio_6h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (6 * 0.005000)
        )
        and
        (
          gitlab_component_shard_errors:ratio_30m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
          > (6 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,shard,component)
      (
        sum by(env,environment,tier,type,stage,shard,component) (gitlab_component_shard_ops:rate_6h{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 0.16667
      )
  - alert: SidekiqServiceSidekiqExecutionTrafficCessationSingleShard
    for: 5m
    annotations:
      title: The sidekiq_execution SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has not received any traffic in the past 30m
      description: |
        The number of Sidekiq jobs meeting their execution duration target based on the urgency of the worker. By default, execution of a job should take no more than 300 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "597131258"
      grafana_variables: environment,stage,shard
      promql_template_1: |
        sum by (env,environment,tier,stage,shard) (
          sli_aggregations:gitlab_sli_sidekiq_execution_total_rate5m{environment="{{ $labels.environment }}",external_dependencies!="yes",shard="{{ $labels.shard }}",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_shard_ops:rate_30m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"} == 0
      and
      gitlab_component_shard_ops:rate_30m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"} offset 1h >= 0.16666666666666666
  - alert: SidekiqServiceSidekiqExecutionTrafficAbsentSingleShard
    for: 30m
    annotations:
      title: The sidekiq_execution SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has not reported any traffic in the past 30m
      description: |
        The number of Sidekiq jobs meeting their execution duration target based on the urgency of the worker. By default, execution of a job should take no more than 300 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "597131258"
      grafana_variables: environment,stage,shard
      promql_template_1: |
        sum by (env,environment,tier,stage,shard) (
          sli_aggregations:gitlab_sli_sidekiq_execution_total_rate5m{environment="{{ $labels.environment }}",external_dependencies!="yes",shard="{{ $labels.shard }}",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_shard_ops:rate_5m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"} offset 1h
      unless
      gitlab_component_shard_ops:rate_5m{component="sidekiq_execution",env!~"gprd|ops",monitor="global",type="sidekiq"}
  - alert: SidekiqServiceSidekiqQueueingApdexSLOViolationSingleShard
    for: 10m
    annotations:
      title: The sidekiq_queueing SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has an apdex violating SLO
      description: |
        The number of Sidekiq jobs meeting their queueing duration target based on the urgency of the worker. By default, queueing of a job should take no more than 60 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3643825112"
      grafana_variables: environment,stage,shard
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: slo_violation
      alert_type: symptom
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_shard_apdex:ratio_1h{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
        and
        (
          gitlab_component_shard_apdex:ratio_5m{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 14.4 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,shard,component)
      (
        sum by(env,environment,tier,type,stage,shard,component) (gitlab_component_shard_ops:rate_1h{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 1
      )
  - alert: SidekiqServiceSidekiqQueueingApdexSLOViolationSingleShard
    for: 10m
    annotations:
      title: The sidekiq_queueing SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has an apdex violating SLO
      description: |
        The number of Sidekiq jobs meeting their queueing duration target based on the urgency of the worker. By default, queueing of a job should take no more than 60 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3643825112"
      grafana_variables: environment,stage,shard
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: slo_violation
      alert_type: symptom
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_shard_apdex:ratio_6h{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
        and
        (
          gitlab_component_shard_apdex:ratio_30m{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"}
          < (1 - 6 * 0.005000)
        )
      )
      and on(env,environment,tier,type,stage,shard,component)
      (
        sum by(env,environment,tier,type,stage,shard,component) (gitlab_component_shard_ops:rate_6h{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"}) >= 0.16667
      )
  - alert: SidekiqServiceSidekiqQueueingTrafficCessationSingleShard
    for: 5m
    annotations:
      title: The sidekiq_queueing SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has not received any traffic in the past 30m
      description: |
        The number of Sidekiq jobs meeting their queueing duration target based on the urgency of the worker. By default, queueing of a job should take no more than 60 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "330011744"
      grafana_variables: environment,stage,shard
      promql_template_1: |
        sum by (env,environment,tier,stage,shard) (
          sli_aggregations:gitlab_sli_sidekiq_queueing_apdex_total_rate5m{environment="{{ $labels.environment }}",external_dependencies!="yes",shard="{{ $labels.shard }}",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_shard_ops:rate_30m{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"} == 0
      and
      gitlab_component_shard_ops:rate_30m{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"} offset 1h >= 0.16666666666666666
  - alert: SidekiqServiceSidekiqQueueingTrafficAbsentSingleShard
    for: 30m
    annotations:
      title: The sidekiq_queueing SLI of the sidekiq service on shard `{{ $labels.shard
        }}` has not reported any traffic in the past 30m
      description: |
        The number of Sidekiq jobs meeting their queueing duration target based on the urgency of the worker. By default, queueing of a job should take no more than 60 seconds. But this can be adjusted by the urgency of the worker.

        Read more about this in the [runbooks doc](https://gitlab.com/gitlab-com/runbooks/-/blob/master/docs/sidekiq/sidekiq-slis.md).

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.

        Since the `{{ $labels.type }}` service is not fully redundant, SLI violations on a single shard may represent a user-impacting service degradation.
      grafana_dashboard_id: sidekiq-main/sidekiq-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/sidekiq-main/sidekiq-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}&var-shard={{ $labels.shard
        }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "330011744"
      grafana_variables: environment,stage,shard
      promql_template_1: |
        sum by (env,environment,tier,stage,shard) (
          sli_aggregations:gitlab_sli_sidekiq_queueing_apdex_total_rate5m{environment="{{ $labels.environment }}",external_dependencies!="yes",shard="{{ $labels.shard }}",stage="{{ $labels.stage }}",type="sidekiq"}
        )
      runbook: docs/sidekiq/README.md
    labels:
      aggregation: component_shard
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: in_source_metrics
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_shard_ops:rate_5m{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"} offset 1h
      unless
      gitlab_component_shard_ops:rate_5m{component="sidekiq_queueing",env!~"gprd|ops",monitor="global",type="sidekiq"}
