# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./thanos-rules-jsonnet/service-component-alerts.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: 'Service Component Alerts: waf'
  interval: 1m
  partial_response_strategy: warn
  rules:
  - alert: WafServiceGitlabNetZoneTrafficCessation
    for: 5m
    annotations:
      title: The gitlab_net_zone SLI of the waf service (`{{ $labels.stage }}` stage)
        has not received any traffic in the past 30 minutes
      description: |
        Aggregation of all GitLab.net (non-pulic) traffic passing through the WAF.

        Errors on this SLI may indicate that the WAF has detected malicious traffic and is blocking it.

        This alert signifies that the SLI is reporting a cessation of traffic, but the signal is not absent.
      grafana_dashboard_id: waf-main/waf-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/waf-main/waf-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3342493164"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cloudflare_zones_http_responses_total{zone="gitlab.net", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/waf/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{type="waf", component="gitlab_net_zone", stage="main", monitor="global"} == 0
  - alert: WafServiceGitlabNetZoneTrafficAbsent
    for: 30m
    annotations:
      title: The gitlab_net_zone SLI of the waf service (`{{ $labels.stage }}` stage)
        has not reported any traffic in the past 30 minutes
      description: |
        Aggregation of all GitLab.net (non-pulic) traffic passing through the WAF.

        Errors on this SLI may indicate that the WAF has detected malicious traffic and is blocking it.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: waf-main/waf-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/waf-main/waf-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3342493164"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cloudflare_zones_http_responses_total{zone="gitlab.net", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/waf/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{type="waf", component="gitlab_net_zone", stage="main", monitor="global"} offset 1h
      unless
      gitlab_component_ops:rate_5m{type="waf", component="gitlab_net_zone", stage="main", monitor="global"}
  - alert: WafServiceGitlabZoneTrafficCessation
    for: 5m
    annotations:
      title: The gitlab_zone SLI of the waf service (`{{ $labels.stage }}` stage)
        has not received any traffic in the past 30 minutes
      description: |
        Aggregation of all public traffic for GitLab.com passing through the WAF.

        Errors on this SLI may indicate that the WAF has detected malicious traffic and is blocking it. It may also indicate serious upstream failures on GitLab.com.

        This alert signifies that the SLI is reporting a cessation of traffic, but the signal is not absent.
      grafana_dashboard_id: waf-main/waf-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/waf-main/waf-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "443878888"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cloudflare_zones_http_responses_total{zone=~"gitlab.com|staging.gitlab.com", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/waf/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{type="waf", component="gitlab_zone", stage="main", monitor="global"} == 0
  - alert: WafServiceGitlabZoneTrafficAbsent
    for: 30m
    annotations:
      title: The gitlab_zone SLI of the waf service (`{{ $labels.stage }}` stage)
        has not reported any traffic in the past 30 minutes
      description: |
        Aggregation of all public traffic for GitLab.com passing through the WAF.

        Errors on this SLI may indicate that the WAF has detected malicious traffic and is blocking it. It may also indicate serious upstream failures on GitLab.com.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: waf-main/waf-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/waf-main/waf-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "443878888"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cloudflare_zones_http_responses_total{zone=~"gitlab.com|staging.gitlab.com", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/waf/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{type="waf", component="gitlab_zone", stage="main", monitor="global"} offset 1h
      unless
      gitlab_component_ops:rate_5m{type="waf", component="gitlab_zone", stage="main", monitor="global"}
