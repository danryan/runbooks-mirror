# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./thanos-rules-jsonnet/service-component-alerts.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: 'Service Component Alerts: logging'
  interval: 1m
  partial_response_strategy: warn
  rules:
  - alert: LoggingServiceElasticsearchIndexingTrafficCessation
    for: 5m
    annotations:
      title: >-
        The elasticsearch_indexing SLI of the logging service (`{{ $labels.stage }}` stage) has not received
        any traffic in the past 30 minutes
      description: |
        This SLI monitors log index operations to GitLab's logging ELK instance.

        This alert signifies that the SLI is reporting a cessation of traffic, but the signal is not absent.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '1156496897'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          clamp_min(deriv(elasticsearch_indices_indexing_index_total{type="logging", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m]), 0)
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      incident_project: gitlab.com/gitlab-com/gl-infra/production
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: >
      gitlab_component_ops:rate_30m{type="logging", component="elasticsearch_indexing", stage="main",
      monitor="global"} == 0
  - alert: LoggingServiceElasticsearchIndexingTrafficAbsent
    for: 30m
    annotations:
      title: >-
        The elasticsearch_indexing SLI of the logging service (`{{ $labels.stage }}` stage) has not reported
        any traffic in the past 30 minutes
      description: |
        This SLI monitors log index operations to GitLab's logging ELK instance.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '1156496897'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          clamp_min(deriv(elasticsearch_indices_indexing_index_total{type="logging", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m]), 0)
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      incident_project: gitlab.com/gitlab-com/gl-infra/production
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: |
      gitlab_component_ops:rate_5m{type="logging", component="elasticsearch_indexing", stage="main", monitor="global"} offset 1h
      unless
      gitlab_component_ops:rate_5m{type="logging", component="elasticsearch_indexing", stage="main", monitor="global"}
  - alert: LoggingServiceElasticsearchSearchingTrafficCessation
    for: 5m
    annotations:
      title: >-
        The elasticsearch_searching SLI of the logging service (`{{ $labels.stage }}` stage) has not received
        any traffic in the past 30 minutes
      description: |
        This SLI monitors searches issued to GitLab's logging ELK instance.

        This alert signifies that the SLI is reporting a cessation of traffic, but the signal is not absent.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '1015871477'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          clamp_min(deriv(elasticsearch_indices_search_query_total{type="logging", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m]), 0)
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      incident_project: gitlab.com/gitlab-com/gl-infra/production
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: >
      gitlab_component_ops:rate_30m{type="logging", component="elasticsearch_searching", stage="main",
      monitor="global"} == 0
  - alert: LoggingServiceElasticsearchSearchingTrafficAbsent
    for: 30m
    annotations:
      title: >-
        The elasticsearch_searching SLI of the logging service (`{{ $labels.stage }}` stage) has not reported
        any traffic in the past 30 minutes
      description: |
        This SLI monitors searches issued to GitLab's logging ELK instance.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '1015871477'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          clamp_min(deriv(elasticsearch_indices_search_query_total{type="logging", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m]), 0)
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      incident_project: gitlab.com/gitlab-com/gl-infra/production
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: |
      gitlab_component_ops:rate_5m{type="logging", component="elasticsearch_searching", stage="main", monitor="global"} offset 1h
      unless
      gitlab_component_ops:rate_5m{type="logging", component="elasticsearch_searching", stage="main", monitor="global"}
  - alert: LoggingServiceFluentdLogOutputErrorSLOViolation
    for: 2m
    annotations:
      title: >-
        The fluentd_log_output SLI of the logging service (`{{ $labels.stage }}` stage) has an error rate
        violating SLO
      description: |
        This SLI monitors fluentd log output and the number of output errors in fluentd.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '3405007546'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(fluentd_output_status_num_errors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: symptom
      feature_category: not_owned
      incident_project: gitlab.com/gitlab-com/gl-infra/production
      pager: pagerduty
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: 'yes'
      user_impacting: 'no'
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="fluentd_log_output",monitor="global",type="logging"}
          > (14.4 * 0.001000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="fluentd_log_output",monitor="global",type="logging"}
          > (14.4 * 0.001000)
        )
        or
        (
          gitlab_component_errors:ratio_6h{component="fluentd_log_output",monitor="global",type="logging"}
          > (6 * 0.001000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="fluentd_log_output",monitor="global",type="logging"}
          > (6 * 0.001000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="fluentd_log_output",monitor="global",type="logging"}) >= 1
      )
  - alert: LoggingServiceFluentdLogOutputTrafficCessation
    for: 5m
    annotations:
      title: >-
        The fluentd_log_output SLI of the logging service (`{{ $labels.stage }}` stage) has not received
        any traffic in the past 30 minutes
      description: |
        This SLI monitors fluentd log output and the number of output errors in fluentd.

        This alert signifies that the SLI is reporting a cessation of traffic, but the signal is not absent.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '3827296992'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(fluentd_output_status_write_count{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      incident_project: gitlab.com/gitlab-com/gl-infra/production
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: >
      gitlab_component_ops:rate_30m{type="logging", component="fluentd_log_output", stage="main", monitor="global"}
      == 0
  - alert: LoggingServiceFluentdLogOutputTrafficAbsent
    for: 30m
    annotations:
      title: >-
        The fluentd_log_output SLI of the logging service (`{{ $labels.stage }}` stage) has not reported
        any traffic in the past 30 minutes
      description: |
        This SLI monitors fluentd log output and the number of output errors in fluentd.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '3827296992'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(fluentd_output_status_write_count{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      incident_project: gitlab.com/gitlab-com/gl-infra/production
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: |
      gitlab_component_ops:rate_5m{type="logging", component="fluentd_log_output", stage="main", monitor="global"} offset 1h
      unless
      gitlab_component_ops:rate_5m{type="logging", component="fluentd_log_output", stage="main", monitor="global"}
  - alert: LoggingServiceKibanaGooglelbErrorSLOViolation
    for: 2m
    annotations:
      title: >-
        The kibana_googlelb SLI of the logging service (`{{ $labels.stage }}` stage) has an error rate
        violating SLO
      description: |2


        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '1918266605'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(stackdriver_https_lb_rule_loadbalancing_googleapis_com_https_request_count{environment="{{ $labels.environment }}",project_id="gitlab-ops",response_code_class="500",stage="{{ $labels.stage }}",target_proxy_name="ops-prod-proxy"}[5m])
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: 'yes'
      user_impacting: 'no'
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="kibana_googlelb",monitor="global",type="logging"}
          > (14.4 * 0.001000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="kibana_googlelb",monitor="global",type="logging"}
          > (14.4 * 0.001000)
        )
        or
        (
          gitlab_component_errors:ratio_6h{component="kibana_googlelb",monitor="global",type="logging"}
          > (6 * 0.001000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="kibana_googlelb",monitor="global",type="logging"}
          > (6 * 0.001000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="kibana_googlelb",monitor="global",type="logging"}) >= 1
      )
  - alert: LoggingServiceKibanaGooglelbTrafficCessation
    for: 5m
    annotations:
      title: >-
        The kibana_googlelb SLI of the logging service (`{{ $labels.stage }}` stage) has not received
        any traffic in the past 30 minutes
      description: |2


        This alert signifies that the SLI is reporting a cessation of traffic, but the signal is not absent.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '2363504950'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(stackdriver_https_lb_rule_loadbalancing_googleapis_com_https_request_count{environment="{{ $labels.environment }}",project_id="gitlab-ops",stage="{{ $labels.stage }}",target_proxy_name="ops-prod-proxy"}[5m])
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: >
      gitlab_component_ops:rate_30m{type="logging", component="kibana_googlelb", stage="main", monitor="global"}
      == 0
  - alert: LoggingServiceKibanaGooglelbTrafficAbsent
    for: 30m
    annotations:
      title: >-
        The kibana_googlelb SLI of the logging service (`{{ $labels.stage }}` stage) has not reported
        any traffic in the past 30 minutes
      description: |2


        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: logging-main/logging-overview
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/logging-main/logging-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '2363504950'
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(stackdriver_https_lb_rule_loadbalancing_googleapis_com_https_request_count{environment="{{ $labels.environment }}",project_id="gitlab-ops",stage="{{ $labels.stage }}",target_proxy_name="ops-prod-proxy"}[5m])
        )
      runbook: docs/logging/README.md
    labels:
      aggregation: component
      alert_type: cause
      feature_category: not_owned
      product_stage: not_owned
      product_stage_group: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: 'no'
      user_impacting: 'no'
    expr: |
      gitlab_component_ops:rate_5m{type="logging", component="kibana_googlelb", stage="main", monitor="global"} offset 1h
      unless
      gitlab_component_ops:rate_5m{type="logging", component="kibana_googlelb", stage="main", monitor="global"}
